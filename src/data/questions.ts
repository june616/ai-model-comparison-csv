import { Question } from '@/types/evaluation'

// Version tracking for dynamic updates
export const QUESTIONS_VERSION = '1.0.0'
export const QUESTIONS_LAST_UPDATED = new Date().toISOString()

export const SAMPLE_QUESTIONS: Omit<Question, 'ratings' | 'knowledgeLevel'>[] = [
  {
    id: 'q1',
    query: "How would you mitigate the following issue?\n\nOur instances in the Prod ring were created, but they had a capacity allocation issue that was resolved yesterday. When I attempted a deployment in the Prod ring, I encountered the following error:\n\n\"ErrorString\":\"ReleaseDefinitonNotFound\",\n\n\"ErrorCode\":4007,\"ErrorMessage\":\"No Cosmic release definition found for the namespace: 'substrate-3scopilot-3scopilotodinml'.\n\nPlease make sure that the namespace metadata is published to Griffin data service\"\n\nCould you help us investigate if the root cause is \"Onboarded namespace is not yet deployed to the synced to backend yet.\"? If so, could you provide an estimate for when the service will be ready for deployment?",
    modelA: {
      id: 'a1',
      model: 'Model A',
      response: "The error \"ReleaseDefinitionNotFound | 4007\" typically indicates that the namespace metadata has not yet been fully published and synchronized with Griffin Data Service. Below is how to investigate the root cause and mitigate the issue.\n\n**Common Causes**\n\n * Namespace metadata not fully published or synchronized to Griffin Data Service.\n\n * Misconfiguration or delays in namespace provisioning or capacity allocation.\n\n * Inventory issue where namespace or partition details are not updated correctly.\n\n * * \n\n**Steps to Investigate**\n\n1.- **Verify Namespace Metadata**: Run the following command to check metadata and provisioning status:\n\n ```bash\n\n cc get partition substrate-3scopilot-3scopilotodinml --region <region_name> --output yaml\n\n ```\n\n This will display the namespace and its provisioning details.\n\n2.- **Check Griffin Data Service**: Use the logging or dashboard mentioned in the error message (<https://aka.ms/cosmicappdeploymenttsg>) to ensure the namespace exists and is synchronized.\n\n3.- **Review Past Incidents**: Look for patterns or similar issues in [ICM#676732500](https://portal.microsofticm.com/imp/v5/incidents/details/676732500), [ICM#588520639](https://portal.microsofticm.com/imp/v5/incidents/details/588520639), and [GitHub Issue#7520](https://github.com/substrate-platform/COSMIC/issues/7520). These indicate potential resolution paths, including retries or metadata corrections.\n\n4.- **Retry Deployment**: As seen in prior cases, reattempt the deployment after confirming provisioning and metadata synchronization.\n\n * * \n\n**Mitigation Suggestions**\n\n1.- **Ensure Namespace Metadata Publishing**: Confirm that the namespace metadata has been published into Griffin Data Service. If not, request the COSMIC team to synchronize it.\n\n2.- **Retry Deployment**: Based on prior cases (e.g., ICM#676732500), a retry, after ensuring no errors in provisioning, often resolves this transient issue.\n\n3.- **Update Namespace Configuration**: If the namespace details seem incomplete or inconsistent, update the required metadata (e.g., Torus team, partition details) via a Pull Request (ref GitHub Issue#7520).\n\n4.- **Reach Out for Assistance**: If the issue persists, escalate to Microsoft COSMIC's App Deployment team or the Capacity and Topologies team for manual synchronization or investigation.\n\n * * \n\nFor further troubleshooting or reporting issues, please visit [COSMIC Troubleshooting Guide](https://aka.ms/cosmic911).\n\n**References**\n\n * [App-Deployment-General Troubleshooting](https://aka.ms/cosmicappdeploymenttsg)\n\n * [Create OneBranch Release Pipeline](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/onboarding/prepare-and-test-deployment/Create-OneBranch-release-pipeline)\n\n**Similar GitHub Issues and ICMs**\n\n * [ICM#676732500 - Failed deployment due to ReleaseDefinitionNotFound](https://portal.microsofticm.com/imp/v5/incidents/details/676732500)\n\n * * **Resolution**: Synchronize Griffin Data Service metadata; retry resolved issue.\n\n * [Issue#7520 - Namespace metadata synchronization issue](https://github.com/substrate-platform/COSMIC/issues/7520)\n\n * * **Resolution**: Retrying and ensuring correct namespace team fixed issue.\n\n * [ICM#588520639 - Deployment failing with similar error](https://portal.microsofticm.com/imp/v5/incidents/details/588520639)\n\n * * **Resolution**: Correct namespace mapping to Torus team; retry succeeded."
    },
    modelB: {
      id: 'b1', 
      model: 'Model B',
      response: "To address the issue you're encountering with the `ReleaseDefinitionNotFound` error (ErrorCode: 4007), we need to investigate the root cause and confirm whether the namespace has been fully onboarded and synchronized to the backend. Below is a structured approach to investigate and mitigate the issue:\n\n---\n\n**Common Causes**\n\n1.- **Incomplete Namespace Provisioning**: The namespace may not have been fully provisioned or onboarded in the COSMIC environment.\n\n2.- **Backend Synchronization Delay**: The namespace metadata might not yet be synced to the GriffinD2 data service, which is required for deployment readiness.\n\n3.- **Deployment Timing**: Deployment may have been attempted before the namespace was fully operational in the backend.\n\n4.- **Configuration Issues**: Missing or incorrect namespace metadata, such as the `namespaceresources-metadata.json` file, could prevent the namespace from being recognized.\n\n---\n\n**Steps to Investigate**\n\n1.- **Verify Namespace Status**:\n\n * Use the `cc` command to check if the namespace exists and is active:\n\n ```bash\n\n cc get namespaces <namespace-name>\n\n ```\n\n * Alternatively, you can use the COSMIC Operation Portal (COP) to list namespaces and confirm the status of `substrate-3scopilot-3scopilotodinml`.\n\n2.- **Check Backend Synchronization**:\n\n * Query the GriffinD2 data service to confirm whether the namespace metadata has been published:\n\n ```bash\n\n curl -X GET https://<cosmic-backend-endpoint>/api/v1/namespaces/<namespace-name>\n\n ```\n\n * Look for a response indicating that the namespace is fully provisioned and operational.\n\n3.- **Review Namespace Metadata**:\n\n * Ensure that the `namespaceresources-metadata.json` file is present and correctly configured for the PROD ring. This file should include the necessary ring overrides for each region [Data: Entities (9407); Relationships (16739)].\n\n4.- **Check Deployment Pipeline Logs**:\n\n * Review the deployment logs in the Ev2 Portal or the COSMIC Deployment Dashboard to identify any additional error messages or warnings related to the namespace.\n\n5.- **Retry Deployment**:\n\n * If the namespace is now provisioned and synced, retry the deployment:\n\n ```bash\n\n cc apply -f <deployment-file.yaml>\n\n ```\n\n---\n\n**Mitigation Suggestions**\n\n1.- **Wait for Backend Synchronization**:\n\n * If the namespace is not yet synced to the backend, allow some time for the synchronization process to complete. This typically takes 20-30 minutes after the namespace is onboarded and metadata is published.\n\n2.- **Force Metadata Publication**:\n\n * If the namespace metadata is missing or incomplete, update the GriffinD2 repository with the correct configuration. Submit a pull request (PR) for the namespace metadata and ensure it is approved and processed:\n\n * * Example PR: https://o365exchange.visualstudio.com/O365%20Core/_git/GriffinD2/pullrequest/2587141\n\n * After the PR is approved, track the release in the GriffinD2 pipeline and ensure the \"Deploy: Copy inventory files to Prod blob storage\" stage is completed [Data: Entities (8016); Sources (3398)].\n\n3.- **Escalate to GriffinD2 Team**:\n\n * If the issue persists despite verifying the namespace and metadata, escalate to the GriffinD2 team for further investigation. Provide the following details:\n\n * * Namespace name: `substrate-3scopilot-3scopilotodinml`\n\n * * Deployment logs\n\n * * Backend API response\n\n * * Error code: `ReleaseDefinitionNotFound-4007`\n\n4.- **Monitor Deployment Readiness**:\n\n * Use the COSMIC monitoring tools or the PlatformAgent Dashboard to track the deployment readiness of the namespace. Ensure all dependencies and configurations are in place before retrying the deployment [Data: Reports (20)].\n\n---\n\n**Estimate for Service Readiness**\n\nIf the root cause is indeed a delay in backend synchronization, the namespace should be ready for deployment within 20-30 minutes after the metadata is published and processed. However, if additional configuration or manual intervention is required, the timeline may extend depending on the complexity of the issue and the approval process for metadata updates.\n\n---\n\n**References**\n\n * [JIT Elevation](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/tools/cosmic-cli/securely-access-app-jit)\n\n * [COSMIC CLI (cc)](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/tools/cosmic-cli/access-clusters-with-cc)\n\n * [COSMIC Operation Portal (COP)](https://aka.ms/cop)\n\nBy following these steps, you should be able to confirm the root cause and resolve the issue, enabling successful deployment in the PROD ring. Let me know if you need further assistance!\n\n**Date:** 2025-09-16"
    }
  },
  {
    id: 'q2',
    query: "What could cause and how can we fix the ICM described at\nhttps://portal.microsofticm.com/imp/v5/incidents/details/666146192\nProvide the cc commands to investigate and fix the situation.",
    modelA: {
      id: 'a2',
      model: 'Model A',
      response: "The issue described in [ICM 666146192](https://portal.microsofticm.com/imp/v5/incidents/details/666146192) appears to involve a **Cosmic App Deployment pipeline issue** where deployments are not reaching the clusters. Key details for this incident reveal that no errors occur in the deployment validation stages, but key deployment steps are skipped, preventing the updates from being propagated.\n\n---\n\n**Common Causes**\n\n1.- **Skipped Deployment Steps**:\n\n -- Critical deployment steps like `SubmitCosmicDeployment` or `ValidatePartitions` might be marked as skipped in the EV2 pipeline.\n2.- **Unhealthy Pipeline**:\n\n -- Nightwatch detection of unhealthy deployment pipelines across clusters or rings could block rollouts.\n3.- **Misconfiguration of Deployment Artifacts**:\n\n -- Artifacts (like container images) not being properly propagated to expected clusters or partitions.\n4.- **Authentication/Authorization Failures**:\n\n -- Issues with permissions in EV2 or partition credentials may prevent the continuation of deployment.\n\n---\n\n**Steps to Investigate**\n\n1.- **Check Deployment Logs in the EV2 Portal**:\n\n -- Review the logs for the skipping behavior of key steps such as `SubmitCosmicDeployment`.\n -- Access the logs via the EV2 Deployment Dashboard ([link](https://aka.ms/cosmicdeploymentdashboard)).\n2.- **Review the Deployment Pipeline in COSMIC**:\n\n ```\n cc get namespaces\n cc get deployments -n <namespace>\n ```\n\n3.- **Ensure Proper Partition Configuration**:\n\n -- Verify the partition:\n ```\n cc get partitions\n cc describe partitions <partition-name>\n ```\n\n4.- **Network Connectivity Check**:\n\n -- Simulate connections from pods to confirm that they can pull images or reach dependent services:\n ```\n cc exec <pod-name> -- curl <service-endpoint>\n ```\n\n---\n\n**Mitigation Suggestions**\n\n1.- **Retrigger Deployment**:\n\n -- As advised in the ICM, manually retrigger the deployment in EV2.\n2.- **Fix Deployment Pipeline Skips**:\n\n -- Address skipped steps in the pipeline via EV2 setup corrections and ensure all validations (like `ValidatePartitions` and `SubmitCosmicDeployment`) are run.\n3.- **Check Cluster/Partition Health**:\n\n -- Ensure the partitions/clusters showing issues are healthy before attempting redeployment.\n4.- **Contact COSMIC Support**:\n\n -- If deployment remains stuck or skips persist, work with COSMIC support via [COSMIC911](https://aka.ms/cosmic911).\n\n---\n\n**Commands to Investigate and Fix**\n\n1.- **List Current Namespaces**:\n\n ```\n cc get namespaces\n\n ```\n\n2.- **Investigate Deployment Rollout Status**:\n\n ```\n cc rollout status deployment <deployment-name> -n <namespace>\n ```\n\n3.- **Check Deployment Pipeline Logs**:\n\n -- Get details for all deployments:\n ```\n cc get deployments -n <namespace>\n cc describe deployment <deployment-name> -n <namespace>\n ```\n\n4.- **Validate Partition and Resources Health**:\n\n ```\n cc get partitions\n cc describe partitions <partition-name>\n cc get pods -n <namespace>\n cc logs <pod-name> -n <namespace>\n ```\n\n5.- **Trigger Redeployment**:\n\n -- Use the EV2 portal to manually retrigger the pipeline [here](https://aka.ms/cosmicdeploymentdashboard).\n\n---\n\n**References**\n\n-- [ICM 666146192](https://portal.microsofticm.com/imp/v5/incidents/details/666146192)\n-- [COSMIC CLI Documentation](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/tools/cosmic-cli/access-clusters-with-cc)\n-- [COSMIC Deployment Troubleshooting Tips](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/troubleshooting/application-deployment/App-Deployment-General-Troubleshooting)"
    },
    modelB: {
      id: 'b2',
      model: 'Model B',
      response: "I cannot directly access the ICM portal or view the specific details of the incident at the provided link. However, I can guide you on general troubleshooting steps for COSMIC-related incidents and provide relevant `cc` commands to investigate and resolve common issues. If you can share more details about the incident (e.g., symptoms, affected components, or error messages), I can tailor the response further.\n\n---\n\n**General Causes of COSMIC Incidents**\nBased on the COSMIC platform's architecture, common causes of incidents include:\n1.- **Nodepool Issues**: Problems with node capacity, scaling, or configuration can lead to pod scheduling failures or degraded performance.\n2.- **Load Balancer Misconfigurations**: Issues like SNAT port exhaustion, health probe failures, or incorrect IP settings can disrupt traffic distribution.\n3.- **Cluster-Level Problems**: API server unresponsiveness, pod scheduling conflicts, or resource exhaustion can impact overall cluster health.\n4.- **Pod-Level Failures**: Pods may fail due to image pull errors, misconfigured environment variables, or insufficient resources.\n5.- **Network Issues**: Misconfigured Network Security Groups (NSGs), DNS resolution failures, or CNI plugin errors can cause connectivity problems.\n\n---\n\n**Steps to Investigate**\nHere are the steps to investigate the issue, along with the corresponding `cc` commands:\n\n1.- **Check Pod Status**:\n -- Use the following command to list all pods and their statuses:\n ```bash\n cc get pods -A\n ```\n -- Look for pods in `Pending`, `CrashLoopBackOff`, or `Error` states.\n\n2.- **Describe Affected Pods**:\n -- If specific pods are failing, describe them to gather more details:\n ```bash\n cc describe pod <pod-name> -n <namespace>\n ```\n\n3.- **Inspect Node Health**:\n -- Check the status of nodes in the cluster:\n ```bash\n cc get nodes\n ```\n -- Look for nodes in `NotReady` or `Unknown` states.\n\n4.- **View Logs**:\n -- Retrieve logs from affected pods to identify errors:\n ```bash\n cc logs <pod-name> -n <namespace>\n ```\n\n5.- **Check Load Balancer Configuration**:\n -- If the issue involves traffic distribution, inspect the service and load balancer configurations:\n ```bash\n cc describe service <service-name> -n <namespace>\n ```\n\n6.- **Monitor Resource Usage**:\n -- Check resource usage at the node and pod levels:\n ```bash\n cc top nodes\n cc top pods -n <namespace>\n ```\n\n7.- **Network Troubleshooting**:\n -- Use the `cc netcapture` command to capture network traffic and identify connectivity issues:\n ```bash\n cc netcapture pod <pod-name> -n <namespace>\n ```\n\n8.- **Cluster-Wide Diagnostics**:\n -- Run the COSMIC troubleshooting tool for a high-level diagnostic:\n ```bash\n cc troubleshoot\n ```\n\n---\n\n**Mitigation Suggestions**\nOnce the root cause is identified, apply the following fixes based on the issue:\n\n1.- **Nodepool Issues**:\n -- Scale the nodepool if capacity is insufficient:\n ```bash\n cc scale deployment <deployment-name> --replicas=<number>\n ```\n -- Drain and cordon problematic nodes for maintenance:\n ```bash\n cc drain <node-name>\n cc cordon <node-name>\n ```\n\n2.- **Load Balancer Misconfigurations**:\n -- Update the service manifest to correct IP settings or health probes.\n -- Restart the affected service to reinitialize the load balancer:\n ```bash\n cc rollout restart deployment <deployment-name> -n <namespace>\n ```\n\n3.- **Cluster-Level Problems**:\n -- Restart the API server or other critical components if unresponsive (requires COSMIC team intervention).\n -- Verify cluster configurations using:\n ```bash\n cc get configmaps -A\n ```\n\n4.- **Pod-Level Failures**:\n -- Redeploy the affected pods or deployments:\n ```bash\n cc rollout restart deployment <deployment-name> -n <namespace>\n ```\n\n5.- **Network Issues**:\n -- Verify NSG rules and DNS configurations.\n -- Use `cc netcapture` to identify and resolve connectivity issues.\n\n---\n\n**Escalation and Additional Support**\nIf the issue persists after applying the above steps, escalate the incident through the ICM portal or contact the COSMIC support team. You can also use the COSMIC Operations Portal (COP) to create or manage ICMs and access additional troubleshooting tools.\n\nFor more information on `cc` commands and JIT elevation, refer to the following resources:\n-- [JIT Elevation](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/tools/cosmic-cli/securely-access-app-jit)\n-- [COSMIC CLI (cc)](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/tools/cosmic-cli/access-clusters-with-cc)\n-- [COSMIC Operation Portal (COP)](https://aka.ms/cop)\n\nIf you can provide more details about the incident, I can refine these steps further.\n\n**Date:** 2025-09-16"
    }
  },
  {
    id: 'q3',
    query: "How would you mitigate the following issue? \n\n-- Title: Error while deploying to new DEV ring \n\n-- Current Behavior: Getting the error when triggering a deployment on Cosmic: \n\nThe activity function \'CosmicTorusTeamValidationTrigger\' failed: \"DataServiceClient API failed to get Microsoft.Office.Substrate.D2Services.CosmicAppDeployment.DataServiceClient.CosmicReleaseDefinition with error response: \". See the function execution logs for additional details. \n\n-- Link: https://ev2portal.azure.net/#/Rollout/CosmicNpeResources/66b2e54c-d5ce-4231-916b-6571f795d9bd?RolloutInfra=Test \n\n-- Expected Behavior: The release is submitted to Cosmic. \n\n-- Ring: dev \n\n-- Region Name: eastus-2 \n\n-- Namespace Name: ic3-auth-runtimeapi \n\n-- Service: Runtime API \n\n-- Container Type: Windows \n\n-- Container Image: Cosmic Base Image",
    modelA: {
      id: 'a3',
      model: 'Model A',
      response: "The issue with \"CosmicTorusTeamValidationTrigger\" failing indicates a problem with the namespace validation or missing/inaccurate metadata in Griffin Data Service. Below are steps to mitigate and resolve the issue. \n\n--- \n\n**Common Causes** \n\n1.- **Namespace Metadata Not Published or Updated**: The namespace metadata may not be synchronized with Griffin Data Service. \n\n2.- **Incorrect Torus Team Metadata**: The `TorusTeam` specified in the deployment pipeline does not match the one configured during onboarding. \n\n3.- **Invalid Configuration**: Multiple teams associated with the namespace or missing required details in Griffin Data Services. \n\n--- \n\n**Steps to Investigate** \n\n1.- **Verify Metadata in Griffin Service**: \n\n -- Use the tools or telemetry logs linked from the error message to verify that the namespace `ic3-auth-runtimeapi` exists and is properly configured. \n\n2.- **Check Namespace and Torus Configuration**: \n\n -- Run: \n\n ``` \n\n cc describe namespace ic3-auth-runtimeapi --output yaml \n\n ``` \n\n -- Ensure the correct `TorusTeam` is specified. Compare the value in the `cc` output with what is provided in the EV2 deployment configuration. \n\n3.- **Deployment Logs**: \n\n -- Review EV2 logs for additional error details by visiting the [EV2 Portal Dashboard](https://ev2portal.azure.net/#/Rollout/CosmicNpeResources/66b2e54c-d5ce-4231-916b-6571f795d9bd?RolloutInfra=Test). \n\n4.- **Team Validation Check**: \n\n -- Ensure that only one Torus team is associated with the namespace to avoid conflicts. \n\n--- \n\n**Mitigation Suggestions** \n\n1.- **Correct Torus Team Configuration**: \n\n -- Update the namespace configuration with the correct Torus team: \n\n ``` \n\n cc edit namespace ic3-auth-runtimeapi \n\n ``` \n\n Ensure the metadata matches onboarding portal configurations. \n\n2.- **Manually Synchronize Metadata**: \n\n -- Request the COSMIC onboarding team to synchronize the namespace metadata with Griffin Data Services. \n\n3.- **Retry Deployment**: \n\n -- After metadata updates, retry the deployment from the pipeline. This often resolves transient issues after synchronization. \n\n4.- **Escalate if Needed**: \n\n -- If the issue persists, escalate to the COSMIC App Deployment team via [COSMIC Troubleshooting Guide](https://aka.ms/cosmic911) for manual metadata correction. \n\n--- \n\n**References** \n\n-- [Fast Deployment to COSMIC DEV Ring in Visual Studio](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/onboarding/prepare-and-test-deployment/DevXpress-fast-deployment-to-cosmic-dev-ring-in-visual-studio) \n\n-- [Prepare and Test Deployment](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/onboarding/prepare-and-test-deployment/Scaffold-win-RDFE-to-COSMIC) \n\n-- [Onboard Service Metadata](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/onboarding/prepare-and-test-deployment/onboard-service-metadata) \n\n--- \n\n**Similar GitHub Issues and ICMs** \n\n-- [Issue# 7128 - Error while deploying to new DEV ring](https://github.com/substrate-platform/COSMIC/issues/7128) \n\n --- **Description**: Deployment failed due to Torus Team mismatch. \n\n --- **Resolution**: Metadata corrected, and the correct Torus Team was configured. \n\n --- **Status**: Closed. \n\n-- [ICM 569864022 - CosmicTorusTeamValidationTrigger blocking deployments](https://portal.microsofticm.com/imp/v5/incidents/details/569864022) \n\n --- **Resolution**: Metadata validated and redeployment succeeded. \n\n --- **Status**: Resolved."
    },
    modelB: {
      id: 'b3',
      model: 'Model B',
      response: "To mitigate the issue described, where the deployment to the new DEV ring fails with the error related to the `CosmicTorusTeamValidationTrigger` activity function, follow the structured approach below:\n\n---\n\n**Common Causes**\n\n1.- **DataServiceClient API Failure**: The error indicates that the `DataServiceClient` API failed to retrieve the `CosmicReleaseDefinition`. This could be due to:\n\n -- Misconfigured or missing release definitions in the deployment pipeline.\n\n -- Network connectivity issues between the deployment service and the DataServiceClient API.\n\n -- Authentication or permission issues preventing access to the required resources.\n\n2.- **Namespace or Partition-Specific Issues**:\n\n -- Resource constraints or misconfigurations in the `ic3-auth-runtimeapi` namespace.\n\n -- Issues specific to the `eastus-2` region or the DEV ring environment.\n\n3.- **Container Image Issues**:\n\n -- The specified container image (`Cosmic Base Image`) may be missing, outdated, or incompatible with the deployment configuration.\n\n4.- **Telemetry or Logging Gaps**:\n\n -- Missing telemetry data or incomplete logs can hinder the ability to diagnose the root cause effectively.\n\n---\n\n**Steps to Investigate**\n\n1.- **Check Deployment Logs**:\n\n -- Use the COSMIC CLI to retrieve detailed logs for the failed deployment:\n\n ```bash\n\n cc logs <pod-name> -n ic3-auth-runtimeapi\n\n ```\n\n -- Alternatively, access the EV2 Portal (link provided in the issue) to review the function execution logs for the `CosmicTorusTeamValidationTrigger` activity.\n\n2.- **Validate Release Definition**:\n\n -- Verify that the `CosmicReleaseDefinition` is correctly configured in the deployment pipeline. Check for missing or invalid parameters in the release definition YAML file.\n\n3.- **Test API Connectivity**:\n\n -- Test the connectivity to the DataServiceClient API endpoint from the deployment environment:\n\n ```bash\n\n curl -v <DataServiceClient-API-Endpoint>\n\n ```\n\n -- Ensure that the API endpoint is reachable and responding as expected.\n\n4.- **Verify Namespace and Resource Availability**:\n\n -- Check the status of the `ic3-auth-runtimeapi` namespace and ensure sufficient resources (CPU, memory) are available:\n\n ```bash\n\n cc get pods -n ic3-auth-runtimeapi\n\n cc describe namespace ic3-auth-runtimeapi\n\n ```\n\n5.- **Inspect Container Image**:\n\n -- Confirm that the specified container image (`Cosmic Base Image`) exists in the Azure Container Registry (ACR) and is accessible:\n\n ```bash\n\n az acr repository show --name <acr-name> --repository <repository-name>\n\n ```\n\n6.- **Check Permissions**:\n\n -- Ensure that the deployment service has the necessary permissions to access the DataServiceClient API and other required resources. This may involve validating Azure AD role assignments or service principal configurations.\n\n7.- **Review Telemetry**:\n\n -- Verify that telemetry data is being collected for the `ic3-auth-runtimeapi` namespace. Missing telemetry can indicate pipeline misconfigurations or service outages.\n\n---\n\n**Mitigation Suggestions**\n\n1.- **Fix Release Definition**:\n\n -- If the `CosmicReleaseDefinition` is misconfigured, update the YAML file with the correct parameters and re-trigger the deployment.\n\n2.- **Restart Deployment Services**:\n\n -- Restart the deployment-related services in the `ic3-auth-runtimeapi` namespace to resolve transient issues:\n\n ```bash\n\n cc rollout restart deployment <deployment-name> -n ic3-auth-runtimeapi\n\n ```\n\n3.- **Rebuild and Push Container Image**:\n\n -- If the container image is missing or outdated, rebuild the image and push it to the ACR:\n\n ```bash\n\n docker build -t <acr-name>.azurecr.io/<repository-name>:<tag> .\n\n docker push <acr-name>.azurecr.io/<repository-name>:<tag>\n\n ```\n\n4.- **Apply JIT Elevation**:\n\n -- If permissions are insufficient, apply Just-In-Time (JIT) elevation to the required role (e.g., Contributor) and retry the deployment. Refer to the [JIT elevation documentation](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/tools/cosmic-cli/securely-access-app-jit).\n\n5.- **Coordinate with the COSMIC Team**:\n\n -- If the issue persists, escalate to the COSMIC team for further investigation. Provide detailed logs and telemetry data to assist in debugging.\n\n---\n\n**References**\n\n-- [COSMIC CLI Documentation](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/tools/cosmic-cli/access-clusters-with-cc)\n\n-- [JIT Elevation Documentation](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/tools/cosmic-cli/securely-access-app-jit)\n\n-- [COSMIC Operation Portal (COP)](https://aka.ms/cop)\n\nBy following these steps, you should be able to identify and resolve the root cause of the deployment failure, ensuring successful submission of the release to the COSMIC DEV ring.\n\n**Date:** 2025-09-16"
    }
  },
  {
    id: 'q4',
    query: "Can you provide an overview of the COSMIC Platform?",
    modelA: {
      id: 'a4',
      model: 'Model A',
      response: "COSMIC (Containers on Substrate-Managed Intelligent Clusters) is a modern, compliant microservice platform built on top of Azure Kubernetes Service (AKS). It enables services to be built and deployed via containers, utilizing technologies like Docker and Kubernetes. COSMIC aims to standardize software delivery across Microsoft\'s Experience + Devices organization, improving agility and reducing time-to-market for features.\n\nKey Concepts:\n\n * **Providers and Deployment:** COSMIC supports multiple clouds, including public (Worldwide), USGov (GCC), and Mooncake for China. Each deployment is segmented by silos, rings, and clusters to ensure compliance and safe deployment practices.\n\n * **Namespaces and Partitions:** Services are isolated using namespaces, while partitions provide flexibility in creating service topology across different rings and regions to simplify routing and deployment.\n\n * **Monitoring and Metrics:** COSMIC provides tools like Grafana dashboards to monitor services, capacity utilization, and deployment health.\n\nCOSMIC\'s foundations are built on shared software systems, ensuring compliance and streamlining partner onboarding.\n\n### References\n\n * [COSMIC Overview](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/overview/what/COSMIC-overview)\n\n * [COSMIC Basic Concepts](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/overview/what/COSMIC-basicConcept)"
    },
    modelB: {
      id: 'b4',
      model: 'Model B',
      response: "**Overview of the COSMIC Platform**\n\nThe COSMIC Platform is a critical infrastructure component within the Microsoft 365 Substrate, designed to manage and deploy containerized applications and services. It provides a secure, scalable, and efficient environment for both Windows and Linux runtimes, with a strong focus on security, compliance, and operational stability. The platform is built on top of Azure Kubernetes Service (AKS) and integrates deeply with Azure services to enhance its capabilities [Data: Entities (210)].\n\n---\n\n**Key Features and Capabilities**\n\n1.- **Container Orchestration and Hosting**:\n\n * COSMIC leverages AKS for hosting and orchestrating container workloads. It supports both Windows and Linux containers, with Linux capacity targeted to increase to 25% of compute cores [Data: Entities (210)].\n\n * The platform uses CBL-Mariner, a secure Linux distribution, as the underlying operating system for container hosting [Data: Entities (210)].\n\n2.- **Security and Compliance**:\n\n * COSMIC adheres to stringent security certifications, such as GCC High, and performs regular vulnerability assessments. It ensures the security and integrity of container images, including addressing vulnerabilities like CVE-2024-8096 and others [Data: Entities (210)].\n\n * The platform employs Azure Container Registry (ACR) for secure storage and management of container images [Data: Entities (210)].\n\n3.- **Namespace and Resource Management**:\n\n * Namespace management is facilitated by services like `cosmic-namespace-agent` and `cosmic-namespacemgmt-allocator`, ensuring efficient allocation and isolation of resources [Data: Entities (210)].\n\n4.- **Deployment and Configuration Management**:\n\n * Deployment workflows are streamlined through tools like MOBR, SRM, and EV2, ensuring efficient and secure deployment processes [Data: Entities (210)].\n\n * The platform integrates with GitOps workflows via FLUX, enabling automated synchronization of cluster configurations with Git repositories [Data: Reports (0)].\n\n5.- **High Availability and Disaster Recovery (HA/DR)**:\n\n * COSMIC supports HA/DR capabilities through extensions like the COSMICAppDeploymentExtension, ensuring service continuity during failures or maintenance [Data: Entities (210)].\n\n6.- **Monitoring and Incident Management**:\n\n * Platform-level monitoring is available through tools like Azure Workbooks, which provide insights into availability and operational status. Integration with IcM Alerts ensures proactive incident management [Data: Entities (9243); Reports (0)].\n\n---\n\n### Known Issues and Challenges\n\n1.- **Deployment Issues**:\n\n * Common problems include missing Managed Service Identity (MSI) configurations and deployment failures due to resource contention or DNS discrepancies [Data: Entities (210); Reports (0)].\n\n2.- **Orphan Resources**:\n\n * Orphaned Kubernetes entities, such as unused Pods and Services, can increase operational costs and interfere with new deployments. Regular cleanup is necessary to maintain cluster efficiency [Data: Reports (0)].\n\n3.- **Security Vulnerabilities**:\n\n * The platform addresses vulnerabilities in container images, such as issues with krb5, expat, curl, and glibc, through regular updates and patches [Data: Entities (210)].\n\n---\n\n### Integration with Other COSMIC Components\n\nThe COSMIC Platform is tightly integrated with other components to enhance its functionality:\n\n * **FLUX**: Ensures configuration consistency through GitOps workflows [Data: Reports (0)].\n\n * **Scaffolding Platform**: Automates the generation of deployment artifacts like Kubernetes manifests and Helm charts [Data: Reports (0)].\n\n * **Cluster Availability Group (CAG)**: Enforces high availability policies, such as the \"one-cluster-down-at-a-time\" rule, to minimize service disruptions [Data: Reports (0)].\n\n---\n\n### Conclusion\n\nThe COSMIC Platform is a cornerstone of the Microsoft 365 Substrate, providing a robust and secure environment for managing containerized applications. Its integration with Azure services, focus on security and compliance, and support for high availability make it a reliable choice for large-scale, mission-critical workloads. However, partners must remain vigilant about known issues, such as deployment challenges and orphan resources, to ensure smooth operations.\n\n**Date:** 2025-09-16"
    }
  },
  {
    id: 'q5',
    query: "How to diagnose this incident?\n\n* Title: Cosmic Pod MEM Utilization greater than 80\% of MEM limit in last 30 min. Namespace: substrate-turing-turingbot Cluster: cosmic-prod-s01-000-nam-canadacentral-aks\n\n* Alert name: rulegroup_AlertRule_cosmic-prod-s01-000-nam-canadacentral-aks_0/pod-mem-usage\n\n* Severity: Sev4\n\n* Subscription: f25d1c1e-3c70-4188-ad86-00d5d3c21e9b\n\n* Resource Group: cosmic-prod-s01-000-nam-canadacentral\n\n* Kubernetes service: cosmic-prod-s01-000-nam-canadacentral-aks\n\n* Description: Rule pod-mem-usage is unhealthy. Evaluated value: 80.029. For duration: 30m\n\n* Monitoring service: Prometheus\n\n* Signal type: Metric\n\n* Fired time: 8/12/2025 5:41:42 PM\n\n* Alert ID: c04b36ed-1f8d-f34c-442a-3dac68a50002\n\n* Alert rule ID: /subscriptions/f25d1c1e-3c70-4188-ad86-00d5d3c21e9b/resourcegroups/cosmic-prod-s01-000-nam-canadacentral/providers/Microsoft.AlertsManagement/prometheusRuleGroups/rulegroup_AlertRule_cosmic-prod-s01-000-nam-canadacentral-aks_0",
    modelA: {
      id: 'a5',
      model: 'Model A',
      response: "**Common Causes**\n\n* The \"Pod MEM Utilization > 80\%\" alert indicates that your pods are consistently nearing or exceeding memory limits as defined in your Kubernetes configurations. This could be due to:\n\n* * Increased service demand or elevated traffic causing higher memory usage.\n\n* * Memory inefficiencies or leaks in the service code.\n\n* * Misconfigured pod memory requests/limits.\n\n---\n\n**Steps to Diagnose**\n\n1.- **Visual Inspection in the Cosmic Dashboard**:\n\n* * Open [COSMIC\'s Memory Dashboard](https://aka.ms/cosmicdashboard).\n\n* * Filter by the ring (prod), region (CanadaCentral), cluster (`cosmic-prod-s01-000-nam-canadacentral-aks`), and namespace (`substrate-turing-turingbot`) from the alert details.\n\n* * Inspect memory usage trends over the last hour including spikes, patterns, or anomalies.\n\n2.- **Review Memory Requests and Limits**:\n\n* * Using `cc` CLI:\n\n ```\n\n cc describe pod -n substrate-turing-turingbot\n\n ```\n\n* * Examine the \"requests\" and \"limits\" set for memory in pods. Ensure these align with realistic service needs.\n\n3.- **Evaluate Resource Distribution**:\n\n* * Identify \"hot\" pods within the namespace consuming unusually high memory:\n\n ```\n\n cc top pod -n substrate-turing-turingbot\n\n ```\n\n* * Is the issue isolated to one or more specific pods or evenly distributed?\n\n4.- **Review Application Logs**:\n\n* * Obtain logs from the affected or high-consumption pods:\n\n ```\n\n cc logs <pod_name> -n substrate-turing-turingbot\n\n ```\n\n* * Identify any errors, exceptions, or high load patterns that could lead to increased memory usage.\n\n5.- **Application Deployment or Update History**:\n\n* * Check for recent deployment or feature updates that may have impacted memory usage.\n\n6.- **Historical Alerts**:\n\n* * Investigate if this alert has appeared previously and if there were resolved actions or postmortems available.\n\n---\n\n**Mitigation Suggestions**\n\n1.- **Scale-Up Pods Temporarily**:\n\n* * Increase pod memory limits and evaluate whether the issue is transient or caused by higher demand. Example:\n\n ```\n\n cc edit deployment <deployment_name> -n substrate-turing-turingbot\n\n ```\n\n Adjust `resources.limits.memory` and add replicas as needed.\n\n2.- **Review Application Code**:\n\n* * If logs indicate memory-intensive operations or leaks, prioritize optimization.\n\n3.- **Scale-Out Resources (Horizontal Scaling)**:\n\n* * Increase replicas for your deployment to distribute traffic and reduce individual pod memory consumption:\n\n ```\n\n cc scale deployment <deployment_name> --replicas=<number> -n substrate-turing-turingbot\n\n ```\n\n4.- **Traffic Shedding or Regional Load Balancing**:\n\n* * Redirect a portion of requests to alternate regions or backup clusters.\n\n5.- **Restart Memory-Intensive Pods**:\n\n* * Restart the problematic pods:\n\n ```\n\n cc delete pod <pod_name> -n substrate-turing-turingbot\n\n ```\n\n6.- **Long-Term Fix**:\n\n* * Evaluate specific Pod SKUs for your workload using [COSMIC Pod SKUs Guidance](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/onboarding/COSMICPodSKUs).\n\n---\n\n**References**\n\n* [Pod Mem / CPU Alert TSG](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/onboarding/monitor/pod-mem-cpu-alert-tsg)\n\n* [COSMIC Pod SKUs](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/onboarding/COSMICPodSKUs)\n\n---\n\n**Similar GitHub Issues and ICMs**\n\n* [Issue#6177 - Need guidance for pod size](https://github.com/substrate-platform/COSMIC/issues/6177)\n\n* * **Description**: Recommendations for Pod memory and CPU configuration.\n\n* * **Resolution**: Follow specific Pod Sizing guidelines.\n\n* * **Status**: Closed.\n\n* [ICM#616096735 - AKSCapacityHeavyUsage](https://portal.microsofticm.com/imp/v5/incidents/details/616096735)\n\n* * **Description**: Cluster provisioning failed; recommended scaling resources or switching regions.\n\n* * **Status**: Active.\n\n* [ICM#648081916 - Exceeded memory quota](https://portal.microsofticm.com/imp/v5/incidents/details/648081916)\n\n* * **Description**: Deployment failures due to memory quota exceeded.\n\n* * **Status**: Active."
    },
    modelB: {
      id: 'b5',
      model: 'Model B',
      response: "To diagnose the **Cosmic Pod MEM Utilization greater than 80\% of MEM limit** alert, follow the steps below. This alert indicates that one or more pods in the specified namespace and cluster have exceeded 80\% of their configured memory limit for a sustained period of 30 minutes. High memory utilization can lead to performance degradation, instability, or even pod crashes if not addressed.\n\n---\n\n**1. Verify the Alert Details**\n\n* Confirm the alert details in the monitoring system (Prometheus in this case).\n\n* Note the affected **namespace** (`substrate-turing-turingbot`), **cluster** (`cosmic-prod-s01-000-nam-canadacentral-aks`), and **alert rule ID** (`pod-mem-usage`).\n\n* Use the **COSMIC Grafana dashboards** to analyze memory usage trends for the affected pods:\n\n* * Navigate to the [COSMIC Application Health Dashboard](https://aka.ms/cosmic/grafana).\n\n* * Filter by **ring**, **region**, **namespace**, **location**, and **cluster** to locate the affected pods.\n\n* * Expand the **Memory Usage per Pod** visualization and filter by the specific pod names to confirm if memory utilization is consistently above 80\% [Data: Reports (3); Entities (6817)].\n\n---\n\n**2. Investigate Common Causes**\n\nHigh memory utilization can occur due to several reasons:\n\n* **Memory Leaks**: The application running in the pod may have a memory leak.\n\n* **Increased Workload**: A sudden spike in traffic or workload may have caused the pod to use more memory than usual.\n\n* **Misconfigured Resource Limits**: The pod\'s memory requests and limits may not be appropriately configured for the workload.\n\n* **Code Changes**: Recent deployments or updates may have introduced inefficient memory usage patterns [Data: Entities (6817, 11122); Reports (3)].\n\n---\n\n**3. Steps to Investigate**\n\n**3.1. Check Pod Metrics**\n\n* Use Grafana to analyze memory usage trends over time for the affected pods.\n\n* Look for any sudden spikes or sustained high memory usage patterns.\n\n**3.2. Inspect Pod Logs**\n\n* Access the logs of the affected pod(s) to identify potential errors or anomalies:\n\n ```bash\n\n cc logs <pod-name> -n substrate-turing-turingbot\n\n ```\n\n* Look for signs of memory leaks, such as repeated allocation errors or out-of-memory (OOM) events.\n\n**3.3. Examine Resource Configuration**\n\n* Review the pod\'s resource requests and limits to ensure they are appropriately configured:\n\n ```bash\n\n cc describe pod <pod-name> -n substrate-turing-turingbot\n\n ```\n\n* Check the `resources` section in the pod specification:\n\n ```yaml\n\n resources:\n\n requests:\n\n memory: <value>\n\n limits:\n\n memory: <value>\n\n ```\n\n**3.4. Analyze Application Behavior**\n\n* Investigate the application running within the pod for potential memory inefficiencies or leaks.\n\n* Check for recent code changes or deployments that might have introduced memory-related issues.\n\n**3.5. Node-Level Resource Contention**\n\n* Check if the node hosting the pod is experiencing resource contention:\n\n ```bash\n\n cc describe node <node-name>\n\n ```\n\n* Look for signs of memory pressure or overcommitment on the node.\n\n---\n\n**4. Mitigation Suggestions**\n\n**4.1. Scale Resources or Pods**\n\n* If the memory usage is due to increased workload, consider scaling the pod\'s resources or increasing the number of replicas:\n\n* * Update resource limits:\n\n ```bash\n\n cc edit deployment <deployment-name> -n substrate-turing-turingbot\n\n ```\n\n* * Scale replicas:\n\n ```bash\n\n cc scale deployment <deployment-name> --replicas=<number> -n substrate-turing-turingbot\n\n ```\n\n**4.2. Restart the Pod**\n\n* As a temporary measure, restart the affected pod to clear memory usage:\n\n ```bash\n\n cc delete pod <pod-name> -n substrate-turing-turingbot\n\n ```\n\n**4.3. Rollback Deployment**\n\n* If the issue is linked to a recent deployment, consider rolling back to a previous version:\n\n ```bash\n\n cc rollout undo deployment <deployment-name> -n substrate-turing-turingbot\n\n ```\n\n**4.4. Optimize Application Code**\n\n* Work with the development team to identify and fix memory leaks or optimize memory usage in the application.\n\n---\n\n**5. Monitor Post-Remediation**\n\n* After applying fixes, continue monitoring the pod\'s memory usage in Grafana to ensure the issue is resolved.\n\n* Use the **Linux Node Utilization** and **Windows Performance Counter** dashboards in Grafana for additional insights if needed [Data: Reports (3); Entities (6817)].\n\n---\n\n**References**\n\n* [COSMIC CLI (cc)](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/tools/cosmic-cli/access-clusters-with-cc)\n\n* [JIT Elevation](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/tools/cosmic-cli/securely-access-app-jit)\n\n* [COSMIC Operation Portal (COP)](https://aka.ms/cop)\n\nBy following these steps, you can effectively diagnose and mitigate the high memory utilization issue, ensuring the stability and performance of the affected pods.\n\n**Date:** 2025-09-16"
    }
  },
  {
    id: 'q6',
    query: "How would you mitigate this incident:\n\nTitle: Deployment in GCC is failing\n\nDescription: We\'re migrating GCC from RDFE to Cosmic, after moving traffic we noticed SNAT port exhaustion so we discussed with Cosmic team and agreed that we\'ll apply pod anti-affinity to maximize our SNAT ports bandwidth. Our deployment is just 11 pods so Cosmic team confirmed that this should be fine.\n\nCluster: cosmic-gcc-f01-05-usgov-usgovtexas-aks\n\nNamespace: ic3-asyncmedia-urlp\n\nThe deployment with pod anti-affinity failed (version 1.224.1-hotfix.1): Ev2 Portal - Dashboard\n\nEscort ticket that shows more details: Incident-574454437 Details - IcM\n\n1.- Only 2 pods out of 11 pods were updated, and those two are running healthy\n\n2.- There is an output for the cc describe pods, but I couldn\'t catch a specific error\n\nMy assumption is that the cluster auto-scalar didn\'t span more nodes for the pods (we need 11 nodes), could you please check what\'s wrong there? The escort ticket shows that all pods (old and new versions) are running fine so this is not a service/application issue",
    modelA: {
      id: 'a6',
      model: 'Model A',
      response: "**Common Causes**\n\n1.- The Cluster Autoscaler may have failed to scale up the nodes to accommodate pod anti-affinity requirements due to restrictive configurations or resource unavailability.\n\n2.- Incorrect or overly restrictive pod anti-affinity rules might cause insufficient scheduling options.\n\n3.- A potential SNAT port exhaustion leading to cluster-wide scheduling issues.\n\n4.- Misconfigured Kubernetes components causing an inability to launch pods efficiently.\n\n**Steps to Investigate**\n\n1.- **Inspect Cluster Autoscaler Logs**:\n\n * * Verify whether the autoscaler attempted to scale up and why it might have failed.\n\n * * Use `cc get events` and `cc describe pods` to identify errors during scheduling.\n\n2.- **Review Pod Anti-Affinity Configurations**:\n\n * * Ensure anti-affinity rules adequately balance spreading pods across nodes without overly restrictive placement.\n\n3.- **Check Node Resources**:\n\n * * Run `cc top nodes` to verify node resource capacity and identify resource constraints.\n\n4.- **Review SNAT Metrics**:\n\n * * Use [SNAT Ports Grafana Dashboard](https://aka.ms/cosmic/grafana/snat) to check allocations and potential exhaustion.\n\n5.- **Monitor Networking Logs**:\n\n * * Inspect relevant nodes and networking components to ensure underlying connectivity and resource allocation are functional.\n\n**Mitigation Suggestions**\n\n1.- **Adjust Pod Anti-Affinity Rules**:\n\n * * Use preferred instead of required rules for pod spreads to create flexible placement options.\n\n2.- **Manually Scale Up Cluster Nodes**:\n\n * * Use COSMIC tools or file a support request to override cluster autoscaler and add nodes manually if needed.\n\n3.- **Evaluate and Increase SNAT Ports**:\n\n * * If SNAT exhaustion is confirmed, increase the SNAT ports per node via the onboarding portal or create a PR in `namespace-metadata.json`.\n\n4.- **Leverage Devspaces for Debugging**:\n\n * * Use the COSMIC Devspace feature to debug and test pods in an isolated environment.\n\nFor continuous support visit <https://aka.ms/cosmic911>.\n\n**References**\n\n * [Troubleshooting Guide for SNAT Port Issues](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/troubleshooting/networking/TSG-for-Cosmic-SNAT-port-exhaustion-issue-is-found-in-1-pod)\n\n * [Understanding SNAT Ports in COSMIC](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/onboarding/set-up-service-configurations/SNAT-ports)\n\n * [Common COSMIC Troubleshooting Guide](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/onboarding/onboarding-guide/Common/Troubleshooting/cosmic-common-troubleshooting-guide)\n\n**Similar GitHub Issues and ICMs**\n\n * **[ICM 623033711 - SNAT Port Exhaustion in one of ic3-calling-callcontroller](https://portal.microsofticm.com/imp/v5/incidents/details/623033711)**\n\n * * Resolution: SNAT ports were manually increased for impacted clusters.\n\n * * Status: Resolved.\n\n * **[ICM 670074936 - New SNAT parameters were not deployed in GCC/GCCH/DoD](https://portal.microsofticm.com/imp/v5/incidents/details/670074936)**\n\n * * Resolution: Adjusted SNAT configuration and augmented IP counts as needed.\n\n * * Status: Resolved."
    },
    modelB: {
      id: 'b6',
      model: 'Model B',
      response: "To address the incident where the deployment in GCC is failing due to suspected cluster autoscaler issues and SNAT port exhaustion, here is a structured mitigation plan:\n\n---\n\n**Common Causes**\n\n1.- **Cluster Autoscaler Not Scaling Nodes**: The cluster autoscaler may not have triggered additional node provisioning due to misconfigurations, taints, or node affinity/anti-affinity rules.\n\n2.- **Pod Anti-Affinity Constraints**: The applied pod anti-affinity rules might be too restrictive, preventing pods from being scheduled on available nodes.\n\n3.- **Resource Quota or Capacity Issues**: The cluster may lack sufficient resources (e.g., vCores or memory) to accommodate the required 11 nodes.\n\n4.- **SNAT Port Exhaustion**: While pod anti-affinity was applied to mitigate SNAT port exhaustion, the issue may still persist if the cluster\'s SNAT port allocation is insufficient or improperly configured.\n\n---\n\n**Steps to Investigate**\n\n1.- **Check Cluster Autoscaler Logs**:\n\n * * Use the `cc logs` command to inspect the logs of the cluster autoscaler for errors or warnings related to scaling.\n\n * * Example: `cc logs deployment/cluster-autoscaler -n kube-system`.\n\n2.- **Verify Node Affinity and Anti-Affinity Rules**:\n\n * * Use `cc describe pod <pod-name>` to review the pod specifications and confirm that the anti-affinity rules are not overly restrictive.\n\n * * Example: `cc describe pod <pod-name>`.\n\n3.- **Inspect Node Resource Availability**:\n\n * * Check the current node capacity and utilization using `cc top nodes`.\n\n * * Example: `cc top nodes`.\n\n4.- **Review Resource Quotas**:\n\n * * Ensure that the namespace `ic3-asyncmedia-urlp` has sufficient resource quotas for the deployment.\n\n * * Example: `cc get resourcequotas -n ic3-asyncmedia-urlp`.\n\n5.- **Validate SNAT Port Allocation**:\n\n * * Use the COSMIC Dashboard to check the allocated and used SNAT ports for the cluster. Look for signs of exhaustion or misconfiguration.\n\n6.- **Check Deployment Status**:\n\n * * Use `cc get pods -n ic3-asyncmedia-urlp` to confirm the status of all pods (old and new versions) and identify any that are stuck in a pending state.\n\n---\n\n**Mitigation Suggestions**\n\n1.- **Adjust Pod Anti-Affinity Rules**:\n\n * * If the anti-affinity rules are too restrictive, consider relaxing them to allow more flexible pod scheduling. For example, use \"preferredDuringSchedulingIgnoredDuringExecution\" instead of \"requiredDuringSchedulingIgnoredDuringExecution\".\n\n2.- **Manually Scale the Cluster**:\n\n * * If the cluster autoscaler is not functioning as expected, manually scale the node pool to ensure sufficient capacity.\n\n * * Example: `cc scale nodepool <nodepool-name> --count=<desired-node-count>`.\n\n3.- **Increase SNAT Port Allocation**:\n\n * * If SNAT port exhaustion is confirmed, work with the COSMIC Networking Team to increase the SNAT port allocation for the cluster.\n\n4.- **Force Deployment Rollout**:\n\n * * If the deployment is stuck, force a rollout to ensure all pods are updated to the new version.\n\n * * Example: `cc rollout restart deployment <deployment-name> -n ic3-asyncmedia-urlp`.\n\n5.- **Monitor Deployment Progress**:\n\n * * Use the Ev2 Portal to track the deployment status and ensure that all pods are updated successfully.\n\n6.- **Escalate to COSMIC Support**:\n\n * * If the issue persists, escalate to the COSMIC team with the escort ticket (Incident-574454437) for further investigation.\n\n---\n\n**Preventive Measures**\n\n1.- **Proactive Capacity Validation**:\n\n * * Use the COSMIC Onboarding Portal to validate cluster capacity before deployments to avoid resource-related issues.\n\n2.- **Optimize SNAT Port Usage**:\n\n * * Implement connection pooling and reuse strategies in the application to minimize SNAT port consumption.\n\n3.- **Enable Detailed Monitoring**:\n\n * * Use tools like the COSMIC Dashboard and Health Guardian to monitor cluster health and resource usage proactively.\n\n---\n\n**Relevant Commands**\n\n * Check pod status: `cc get pods -n ic3-asyncmedia-urlp`\n\n * Describe a pod: `cc describe pod <pod-name> -n ic3-asyncmedia-urlp`\n\n * View node utilization: `cc top nodes`\n\n * Restart deployment: `cc rollout restart deployment <deployment-name> -n ic3-asyncmedia-urlp`\n\n * Scale node pool: `cc scale nodepool <nodepool-name> --count=<desired-node-count>`\n\n---\n\n**References**\n\n * [JIT Elevation](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/tools/cosmic-cli/securely-access-app-jit)\n\n * [COSMIC CLI (cc)](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/tools/cosmic-cli/access-clusters-with-cc)\n\n * [COSMIC Operation Portal (COP)](https://aka.ms/cop)\n\nBy following these steps, you should be able to identify and resolve the root cause of the deployment failure. Let me know if you need further assistance!\n\n**Date:** 2025-09-16"
    }
  },
  {
    id: 'q7',
    query: "how do I configure geneva agent using CBI",
    modelA: {
      id: 'a7',
      model: 'Model A',
      response: "To configure the Geneva agent for monitoring when using COSMIC Base Images (CBI), follow the detailed steps below:\n\n---\n\n**Prerequisites**\n\n1.- **Geneva Account**:\n\n* Ensure a Geneva Logs and Metrics account is set up. Follow the Geneva onboarding portal [here](https://portal.microsoftgeneva.com/account/onboard).\n* Use Managed Identity-based authentication for Geneva agents, or create an Azure Key Vault (AKV) certificate if required. More details are available [here](https://eng.ms/docs/products/geneva/collect/authentication/keyvaultcreatecert).\n2.- **COSMIC Managed Pod Identity**:\n\n* Set up Pod Identity as described [here](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/onboarding/prepare-and-test-deployment/setup-azure-pod-identity).\n\n---\n\n**For Windows Containers Using COSMIC Base Images**\n\n1.- **Integrate Geneva Agent**:\n\n* Reference the Geneva agent package in your project (`csproj`). Example:\n ```\n <ItemGroup><PackageReference Include=\"GenevaMonitoringAgent\" Version=\"<desired_version>\" /></ItemGroup>\n ```\n\n2.- **Setup Geneva Agent in Your Dockerfile**:\n\n* Add Geneva agent binaries and certificates in the image. Example:\n ```\n FROM cosmicbiprodacr.azurecr.io/windows/servercore:ltsc2022\n COPY . /myapp/\n COPY Monitoring/ /Monitoring/\n ```\n\n3.- **Configuration**:\n\n* Prepare and include a `StartupConfig.json` file with Geneva configurations.\n ```\n {\n \"MonitorAgentOptions\": {\n \"ShouldStartMonitorAgent\": true,\n \"MonitorAgentExecuteFile\": \"C:\\Monitoring\\Agent\\MonAgentLauncher.exe\",\n \"EnvVars\": {\n \"MONITORING_GCS_ACCOUNT\": \"YourGcsAccount\",\n \"MONITORING_GCS_ENVIRONMENT\": \"DiagnosticsPROD\",\n \"...other_env_vars...\": \"...\"\n }\n }\n }\n ```\n\n---\n\n**For Linux Containers**\n\n1.- **Deploy Geneva Agents as Sidecars**:\n\n* Use `app-resources.json` to configure Geneva log and metrics agents as sidecar containers.\n* Example:\n ```\n {\n \"containers\": [\n {\n \"name\": \"geneva-logs\",\n \"image\": \"mcr.microsoft.com/geneva/distroless/mdsd:1.35.7\",\n \"args\": [\"--env\", \"MONITORING_GCS_ACCOUNT=...\"]\n }\n ]\n }\n ```\n\n* Add necessary environment variables for `mdsd` (logs) and `mdm` (metrics).\n2.- **Integrate R9 Logger**:\n\n* Use the [R9 Logger SDK](https://eng.ms/docs/experiences-devices/r9-sdk/docs/telemetry/logging/geneva-log-export) to write logs and metrics to Geneva.\n\n---\n\n**General Recommendations**\n\n1.- **Optimize Resources**:\n\n* Configure appropriate CPU and memory limits for Geneva containers based on telemetry volume.\n2.- **Standardize Logging for Geneva**:\n\n* Ensure necessary Geneva configuration files (e.g., `GenevaLogConfig.xml`) are uploaded to the Geneva account.\n3.- **Follow Security Best Practices**:\n\n* Use Managed Identity where possible to avoid hardcoding secrets. Implement secure shutdown hooks to flush telemetry data before container termination.\n\n---\n\n**References**\n\n* [Windows COSMIC Base Images Setup Guide](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/onboarding/containerize/Create-dockerfile-cosmic-base-image)\n* [Setup Geneva Monitoring](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/onboarding/configure-containers/Setup-Geneva-monitoring)\n* [Geneva Monitoring Pipeline](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/onboarding/onboarding-guide/Common/Monitor/setup-geneva-monitoring-pipeline)"
    },
    modelB: {
      id: 'b7',
      model: 'Model B',
      response: "To configure the Geneva Monitoring Agent using COSMIC Base Images (CBI), you need to follow a structured process that ensures the agent is properly set up for logging and monitoring in the COSMIC environment. Below are the key steps and considerations:\n\n---\n\n**1. Prerequisites**\n\nBefore configuring the Geneva Monitoring Agent, ensure the following:\n\n* You have access to the Geneva Logs and Metrics Accounts.\n\n* The necessary namespaces and user roles are configured in the Geneva portal.\n\n* Authentication for the Geneva agent is set up using either **Managed Identities** (recommended) or **Azure KeyVault Certificates** [Data: Entities (10824, 10829); Relationships (19923, 19922)].\n\n---\n\n**2. Configuration Steps**\n\n**Step 1: Enable Geneva Monitoring in CBI**\n\n* Geneva Monitoring is disabled by default for Linux use cases in CBI. To enable it:\n\n* * Modify the `appsettings.dev.json` file and set the `DevGenevaDisable` flag to `false`.\n\n* * Update the `app-resources.json` file to include the necessary Geneva containers (`mdm`, `mds`, and `keyvault-agent`) [Data: Entities (4259, 10102)].\n\n**Step 2: Set Up Geneva Logs and Metrics Accounts**\n\n* Navigate to the Geneva portal and create or use existing Logs and Metrics Accounts.\n\n* Configure the namespace under the log account and ensure the following user role permissions are set:\n\n* * **Config**: `^YourNamespaceName.* Read`\n\n* * **Runner**: `^YourNamespaceName.* Read`, `^YourNamespaceName.* Write`\n\n* * **Agents**: `^YourNamespaceName.* Execute` [Data: Sources (4449)].\n\n**Step 3: Configure Authentication**\n\n* Use **Managed Identities** for authentication, as it is the recommended method in COSMIC. Alternatively, you can use **Azure KeyVault Certificates** if Managed Identities are not feasible.\n\n* Ensure the Geneva agent has access to the required credentials stored in Azure KeyVault or through Managed Identities [Data: Entities (10829, 10824)].\n\n**Step 4: Update Geneva Configuration**\n\n* Use the `InstallGeneva` script to update the Geneva configuration. This script is part of the GriffinD2 repository and allows you to add new events or modify existing configurations [Data: Entities (11058)].\n\n* Ensure the configuration file (`GenevaLogConfig.xml`) specifies the correct namespace, storage group, and monitoring account. Upload this configuration to the Geneva Logs Account settings [Data: Entities (10831)].\n\n**Step 5: Validate Configuration**\n\n* Validate the Geneva settings in the `CosmicBootstrap\Entrypoint.cmd` file to ensure proper monitoring of non-containerized services [Data: Entities (11656)].\n\n* If you encounter issues, use the Geneva Trouble Shooter tool to diagnose and resolve configuration problems [Data: Entities (7281)].\n\n---\n\n**3. Common Issues and Troubleshooting**\n\n**Issue 1: Geneva Agent Crashing on Boot**\n\n* This can occur due to an invalid configuration file or missing configuration paths. Ensure the configuration file is valid and the required paths (e.g., `C:\GenevaAgent\Configuration`) exist [Data: Entities (401, 4600); Relationships (520, 519)].\n\n**Issue 2: Unauthorized Access to GCS Configuration**\n\n* If the Geneva agent cannot download the configuration JSON blob from GCS, verify that the Geneva binaries are excluded from the signing step and that the agent has the necessary permissions [Data: Sources (2011)].\n\n**Issue 3: ContainersNotReady**\n\n* This issue may arise due to Geneva agent misconfiguration. Follow the Geneva Monitoring Agent Troubleshooting Guide (TSG) to resolve such issues [Data: Entities (2713, 7281); Relationships (4833)].\n\n---\n\n**4. Best Practices**\n\n* **Disable Unnecessary Extensions**: Disable default Monitoring Agent (MA) extensions like AzurePerfCollectorExtension and HealthExtension to optimize resource usage and reduce instability [Data: Sources (2551)].\n\n* **Graceful Shutdown**: Configure the Geneva containers to handle termination signals gracefully to prevent data loss during shutdown [Data: Entities (11538)].\n\n* **Regular Updates**: Keep the Geneva configuration and agent binaries up to date to avoid compatibility issues and leverage the latest features [Data: Entities (11058)].\n\n---\n\n**5. Additional Resources**\n\n* For detailed guidance on Geneva agent setup, refer to the Geneva Monitoring Agent Troubleshooting Guide (TSG) [Data: Entities (2713)].\n\n* Use the Geneva CLI and Geneva portal for advanced configuration and diagnostics.\n\n* If you encounter persistent issues, reach out to the COSMIC support team or refer to the COSMIC documentation for further assistance.\n\n---\n\nBy following these steps and best practices, you can successfully configure the Geneva Monitoring Agent using COSMIC Base Images (CBI) to enable robust logging and monitoring for your COSMIC services.\n\n**Date:** 2025-09-16"
    }
  },
  {
    id: 'q8',
    query: "what is the managed identity\'s object (principal) ID for cosmic app deployment extension?",
    modelA: {
      id: 'a8',
      model: 'Model A',
      response: "COSMIC platforms use a managed identity for app deployment extension across various configurations, with different object (principal) IDs depending on their environment and specific usage cases. Examples include: \n\n1.- **Torus Environment**: Principal ID = `447b50c4-7f53-4ceb--8155--9c156f447c24`. \n\n2.- Usage-pattern relates This Reservednx AOD cluster"
    },
    modelB: {
      id: 'b8',
      model: 'Model B',
      response: "The managed identity\'s object (principal) ID for the **COSMIC App Deployment Extension** is not explicitly provided in the available data. However, the **COSMIC-SIG-APP-DEPLOYMENT** team is responsible for managing application deployments within the COSMIC environment. This team requires the **service principal ID** for EV2Endpoints to ensure proper access to resources like the Azure Container Registry (ACR) [Data: Entities (5910); Relationships (10275)].\n\nIf you are looking for the specific **principal ID** for a managed identity related to app deployment, you may need to:\n\n1.- **Check the EV2Endpoint Configuration**: Ensure that the service principal ID used in the creation of the EV2Endpoint has been shared with the COSMIC-SIG-APP-DEPLOYMENT team. This is a critical step for resolving authentication issues in build pipelines [Data: Reports (2864)].\n\n2.- **Retrieve the Principal ID**: If you have access to the Azure environment, you can use Azure PowerShell or CLI commands to retrieve the principal ID of the managed identity. For example:\n\n ```powershell\n\n Get-AzADServicePrincipal -DisplayNameBeginsWith \<identity-name>\" | Select-Object Id\n\n ```\n\n Replace `<identity-name>` with the name of the managed identity associated with the app deployment.\n\n3.- **Contact the COSMIC-SIG-APP-DEPLOYMENT Team**: If the principal ID is not readily available, you may need to reach out to the COSMIC-SIG-APP-DEPLOYMENT team for further assistance.\n\nIf you need additional guidance on how to retrieve or configure managed identities in COSMIC, let me know!\n\n**Date:** 2025-09-16"
    }
  },
  {
    id: 'q9',
    query: "How do I find build version of a train?",
    modelA: {
      id: 'a9',
      model: 'Model A',
      response: "To find the build version of a train in COSMIC, inspect the pipeline details in Azure DevOps (ADO) where the build artifacts are generated. The key step involves configuring your pipeline to generate a unique build version number.\n\n1.-  Configure your pipeline with a task for setting the `BuildNumber`:\n\n ```\n - task: onebranch.pipeline.version@1\n displayName: \'Setup BuildNumber\'\n inputs:\n system: \'RevisionCounter\'\n major: \'1\'\n minor: \'0\'\n exclude_commit: true\n ```\n\n2.-  Review deployment artifacts for versioning:\n\n* Artifacts like `deployment-package.zip` and `catalog.json` typically contain version information.\n* Check for the version format generated based on your pipeline\'s `BuildNumber` settings.\n3.-  For detailed setup:\n\n* Use [M365PT templates](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/onboarding/prepare-and-test-deployment/M365PT-Create-build-pipeline) to extend pipeline functionality and set accurate build versions.\n\nFor additional support, refer to COSMIC documentation or contact ES365 COSMIC support at `es365csmsup@microsoft.com`.\n\n**References**\n\n* [M365PT Create Build Pipeline](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/onboarding/prepare-and-test-deployment/M365PT-Create-build-pipeline)\n* [Presence of Test Cases in COSMIC Build Pipeline](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/onboarding/prepare-and-test-deployment/Presence-Of-Testcases-in-Cosmic-build-pipeline)"
    },
    modelB: {
      id: 'b9',
      model: 'Model B',
      response: "To find the build version of a train in the COSMIC platform, you can follow these steps:\n\n---\n\n**1.- Identify the Train Type**\n\nFirst, determine the type of train you are looking for. COSMIC supports multiple types of trains, including:\n\n* **Platform Agent Train**: Weekly updates for platform agents.\n\n* **NodePool Train**: Monthly updates for node pools.\n\n* **OS Upgrade Train**: Bi-monthly updates for operating systems.\n\n* **Patch Train**: On-demand updates for patches [Data: Entities (10655); Relationships (19590, 19591, 19592, 19593)].\n\nEach train type has its own schedule and build version tracking mechanisms.\n\n---\n\n**2.- Use the COSMIC Release Train Schedule**\n\nThe COSMIC Release Train Schedule provides detailed deployment timelines and naming conventions for various trains, including NodePool and Platform Agent trains. It also maps these trains back to GriffinD2 builds, which are essential for identifying the build version [Data: Entities (4928); Relationships (8701, 8695, 8703)].\n\nYou can access the schedule via Microsoft SharePoint, which is available to COSMIC Agility team members. This document is particularly useful for planning and tracking train deployments.\n\n---\n\n**3.- Check the PlatformAgent Dashboard**\n\nFor Platform Agent Train build versions, you can use the [PlatformAgent Dashboard](https://aka.ms/cosmic/platformagent). This dashboard provides detailed information about agent deployment status, including:\n\n* `spec_platformAgentTrain`: The desired version of the agent.\n\n* `status_platformAgentTrain`: The actual version of the agent deployed.\n\n* `appliedVersion`: The applied version per agent [Data: Entities (7954); Relationships (13821)].\n\nThe dashboard allows filtering by specific agents, rings, and other parameters to locate the build version associated with your train.\n\n---\n\n**4.- Use GriffinD2 Build Pipelines**\n\nGriffinD2 pipelines are integral to COSMIC\'s build and deployment process. To find the minimal build version containing a specific change:\n\n* Navigate to the [GriffinD2 Official-Dogfood pipeline](https://dev.azure.com/O365Exchange/O365%20Core/_build?definitionId=33316) for master branch changes.\n\n* For backported changes, use the [GriffinD2 Official-Incremental pipeline](https://dev.azure.com/O365Exchange/O365%20Core/_build?definitionId=33317) [Data: Sources (3377)].\n\nThese pipelines tag builds with their versions, allowing you to identify the minimal build version containing your desired changes.\n\n---\n\n**5.- Use the Infra Trains Monitoring Dashboard**\n\nFor infra trains like NodePool or OS Upgrade trains, the [Infra Trains Monitoring Dashboard](https://aka.ms/c/MobrInfraTrains) provides a comprehensive view of deployments. You can scope the dashboard by:\n\n* **Train Type**: Platform, NodePool, etc.\n\n* **Build Version**: The specific build version of the train.\n\n* **Ring**: Test, SDF, MSIT, Prod [Data: Sources (3745)].\n\nThis dashboard also links to MOBR pipeline runs and the Ev2 portal for further tracking of deployment stages.\n\n---\n\n**6.- Generate Build Versions Using Scripts**\n\nIf you need to generate or confirm build versions for a train, you can use the `Request-GenerateCosmicUpgradeTrainTemplate.ps1` script. This script allows you to specify parameters like `BuildVersion`, `Ring`, and `TrainType`. For example:\n\n```powershell\n\nRequest-GenerateCosmicUpgradeTrainTemplate.ps1 -BuildVersion \"1.0.20371.0\" -Ring \"test\" -TrainType \"Daily\" -ControllerVersionOverrides \"agent:1.0.03130.7792,upgrade:1.0.03130.7792\"\n\n```\n\nThis script is particularly useful for generating upgrade templates for NodePool, Platform, and RBAC trains [Data: Entities (2587); Sources (2134)].\n\n---\n\n**7.- Consult the COSMIC Agility Team**\n\nFor trains like PA and NP, the COSMIC Agility Team confirms the values of `BuildVersion` and `ControllerVersionOverrides` in the golden template. For RBAC trains, Beiming Cui is responsible for confirming these values [Data: Entities (5511, 5512); Relationships (9622, 9623)].\n\n---\n\n**Summary**\n\nTo find the build version of a train:\n\n* Use dashboards like the PlatformAgent Dashboard or Infra Trains Monitoring Dashboard.\n\n* Refer to GriffinD2 pipelines for build tags.\n\n* Consult the COSMIC Release Train Schedule for mapping and timelines.\n\n* Use scripts like `Request-GenerateCosmicUpgradeTrainTemplate.ps1` for generation and confirmation.\n\n* Reach out to the COSMIC Agility Team for specific train types.\n\nThese tools and resources ensure you can accurately identify and track build versions across COSMIC trains.\n\n---\n\n**References**\n\n* [COSMIC CLI (cc)](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/tools/cosmic-cli/access-clusters-with-cc)\n\n* [COSMIC Operation Portal (COP)](https://aka.ms/cop)\n\n* [JIT elevation](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/tools/cosmic-cli/securely-access-app-jit)\n\n**Date:** 2025-09-16"
    }
  },
  {
    id: 'q10',
    query: "How to access kusto cluster logs from cosmic-monitoring-sdf-nam-2-workspace",
    modelA: {
      id: 'a10',
      model: 'Model A',
      response: "To access the Kusto cluster logs for the `cosmic-monitoring-sdf-nam-2-workspace`, follow these steps:\n\n1.- **Ensure Permissions**:\n\n* Verify you have the `COSMICPartner` eligibility on M365 Pulse. If not, search for and request the `COSMICPartner` eligibility.\n\n* Elevate your access through the appropriate JIT group:\n\n ```\n\n Request-AzureAdGroupRoleElevation -GroupName \"COSMIC Partner Logs Access - SDF\" -Reason \"Access Log Analytics\"\n\n ```\n\n2.- **Access the Workspace**:\n\n* Visit the Log Analytics workspace using the following URL: [Cosmic Monitoring SDF NAM 2 Workspace](https://ms.portal.azure.com/#@prdtrs01.onmicrosoft.com/resource/subscriptions/2b0fa1a3-2237-4422-abf7-98a8ebc207fd/resourceGroups/cosmic-sdf-monitoring-rg/providers/Microsoft.OperationalInsights/workspaces/cosmic-monitoring-sdf-nam-2-workspace/Overview).\n\n3.- **Query Logs**:\n\n* Use KQL (Kusto Query Language) to query logs within the workspace.\n\n* Example:\n\n ```\n\n union KubernetesPodInventory, KubernetesContainerLog_CL\n\n | where TimeGenerated > ago(1h)\n\n ```\n\n4.- **Additional Resources**:\n\n* Access aggregated metrics on dashboards from the [COSMIC Dashboard](https://aka.ms/cosmicdashboard).\n\n### References\n\n* [User Access to Log Analytics](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/tools/User-Access-Log-Analytics)\n\n* [Monitor Your Containerized App](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/onboarding/monitor/Monitor-containerized-app)"
    },
    modelB: {
      id: 'b10',
      model: 'Model B',
      response: "To access Kusto cluster logs from the `cosmic-monitoring-sdf-nam-2-workspace`, you will need to use the Azure Log Analytics Workspace associated with this COSMIC monitoring environment. Below are the steps and considerations for accessing and querying logs effectively:\n\n---\n\n**1. Prerequisites**\nBefore accessing the logs, ensure the following:\n* **Access Permissions**: You must have the appropriate permissions to query the `cosmic-monitoring-sdf-nam-2-workspace`. Typically, this requires **Contributor** or **Reader** permissions for the workspace. If you lack access, you may need to request Just-In-Time (JIT) elevation to the required role [Data: Entities (5691, 11514)].\n* **Authentication**: Use your Torus account or other approved authentication mechanisms to access the workspace. Ensure your account is configured correctly for the COSMIC environment [Data: Entities (6739)].\n\n---\n\n**2. Accessing the Workspace**\nYou can access the `cosmic-monitoring-sdf-nam-2-workspace` through the Azure portal or via Kusto Query Language (KQL) tools. \n\n**Via Azure Portal**\n1.- Navigate to the Azure portal: [Azure Portal](https://portal.azure.com).\n2.- Search for the `cosmic-monitoring-sdf-nam-2-workspace` in the Log Analytics Workspaces section.\n3.- Open the workspace and use the built-in query editor to run KQL queries.\n\n**Via KQL Tools**\nYou can also use tools like Azure Data Explorer or Kusto Explorer to connect to the workspace. Ensure you have the correct workspace ID and key for authentication.\n\n---\n\n**3. Querying Logs**\nOnce you have access, you can query logs using KQL. Below are some common queries for analyzing Kusto cluster logs:\n\n**Example Query: Kubernetes Events**\nTo view Kubernetes events (e.g., warnings, probe failures):\n```kql\nKubeEvents\n| where TimeGenerated > ago(30d)\n| where Level == \"Warning\" or Level == \"Error\"\n| project TimeGenerated, ClusterName, Namespace, PodName, Message\n```\nThis query retrieves events from the `KubeEvents` table, which is part of the workspace\'s data structure [Data: Entities (5691)].\n\n**Example Query: Cluster Logs**\nTo analyze logs related to specific clusters:\n```kql\nKubePodInventory\n| where ClusterName == \"cosmic-sdf-nam-2\"\n| project TimeGenerated, PodName, Namespace, Message\n```\nThis query filters logs for the `cosmic-sdf-nam-2` cluster and provides details about pod activity.\n\n**Example Query: Insights Metrics**\nTo monitor metrics like CPU or memory usage:\n```kql\nInsightsMetrics\n| where Namespace == \"prometheus\"\n| project TimeGenerated, Name, Value, Tags\n```\nThis query helps in identifying resource utilization trends.\n\n---\n\n**4. Troubleshooting Access Issues**\nIf you encounter issues accessing the workspace or logs:\n1.- **Verify Permissions**: Ensure your account has the necessary role assignments. Use the following command to check permissions:\n ```bash\n torus account show --workspace cosmic-monitoring-sdf-nam-2-workspace\n ```\n2.- **Check Workspace Configuration**: Ensure the workspace is correctly configured and active. Misconfigurations can lead to data ingestion delays or missing logs [Data: Entities (5691, 3349)].\n3.- **Validate URL**: If accessing via a URL, ensure it is correctly formatted. For example:\n ```\n https://aka.ms/cosmicsdfnamworkspace\n ```\n\n---\n\n**5. Additional Notes**\n* **Data Retention**: Logs in the `KubeEvents` table are retained for 30 days. Ensure you query within this timeframe to access relevant data [Data: Entities (5691)].\n* **Escalation**: For unresolved issues, escalate to the COSMIC Monitoring team or the Container Insights/ContainerInsightsAgent team with detailed logs and findings [Data: Reports (22)].\n\n---\n\nBy following these steps, you should be able to access and analyze Kusto cluster logs from the `cosmic-monitoring-sdf-nam-2-workspace`. If you need further assistance, refer to the COSMIC Operation Portal (COP) or the COSMIC CLI documentation for additional tools and commands:\n\n* [COSMIC CLI (cc)](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/tools/cosmic-cli/access-clusters-with-cc)\n* [COSMIC Operation Portal (COP)](https://aka.ms/cop)\n\n**Date:** 2025-09-16"
    }
  },
  {
    id: 'q11',
    query: "What are the key differences between building for GCC-H and DoD?",
    modelA: {
      id: 'a11',
      model: 'Model A',
      response: "Key differences between building for GCC-High (Government Community Cloud High) and DoD (Department of Defense) environments emerge due to stricter compliance, resource placement, security considerations, and network behaviors for DoD workloads.\n\n**Differences:**\n\n1.- **Regions and Resources:**\n\n* GCC-High allows for resources in USGOV regions such as USGOV Arizona and Texas.\n\n* DoD supports deployment only in specialized USDOD regions with stricter controls and additional federal audits.\n\n2.- **Regulatory Compliance:**\n\n* GCC-High environments adhere to high-security requirements but with slightly lenient access compared to DoD.\n\n* DoD builds include Federal Information Processing Standards (FIPS), Impact Levels (IL5 and IL6), and stricter adherence to Defense Information Systems Agency (DISA) standards.\n\n3.- **Code Changes and Mapping:**\n\n* For DoD, specific mappings and intelligent use of compliance data are required in `getSlices`, `GetSliceRoleSpecifications`, and `GetSubscriptionIds` methods in the service\'s codebase to handle stricter region specifics.\n\n4.- **Platform Resources:**\n\n* In DoD, development teams must determine whether to reuse platform resources in USDOD regions (older configurations) or migrate entirely to USGOV regions controlled by COSMIC.\n\n* GCC-High lacks such conditional configurations, being limited already to USGov deployments.\n\n**Further Resources:**\n\n* [Onboard COSMIC to GCC/DoD](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/onboarding/onboarding-guide/OSI-OC/osi-oc-onboard-sov-cloud)\n\n* [Compliance, Security, Privacy Guidelines](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/onboarding/prerequisites/Security-privacy-compliance-CELA)"
    },
    modelB: {
      id: 'b11',
      model: 'Model B',
      response: "Building for GCC-H (Government Community Cloud High) and DoD (Department of Defense) environments within the COSMIC platform involves distinct considerations due to their unique compliance, security, and operational requirements. Below are the key differences between the two environments:\n\n---\n\n**1. Purpose and Compliance Requirements**\n\n* **GCC-H**: GCC-H is designed to host government services that require high levels of security and compliance but are not as stringent as those required by the DoD. It adheres to standards like FedRAMP High and ITAR (International Traffic in Arms Regulations) but is generally used for civilian government agencies [Data: Entities (740, 218)].\n\n* **DoD**: The DoD environment is tailored specifically for U.S. defense agencies and must meet the most stringent security and compliance requirements. It operates under the ITAR framework and includes additional specifications for defense operations, such as stricter network and firewall configurations, and compliance with DoD-specific policies [Data: Entities (191, 355)].\n\n---\n\n**2. Deployment Rings and Readiness**\n\n* **GCC-H**: GCC-H is part of the broader COSMIC deployment landscape and is integrated with other environments like TEST and PROD. It is often used for workloads that are in the Pilot Preview stage, undergoing testing and verification before production traffic [Data: Entities (740)].\n\n* **DoD**: The DoD environment functions as a distinct deployment ring and is currently in the attestation process, meaning it is not yet ready for production traffic. This process ensures that all configurations and security measures meet the rigorous standards required for defense operations [Data: Entities (191)].\n\n---\n\n**3. Technical Configurations**\n\n* **GCC-H**: Deployments in GCC-H require specific configurations, such as SNAT parameter settings, and involve monitoring and failover processes between primary and secondary workspaces. It also supports containerized services through the COSMIC management plane [Data: Entities (740, 218)].\n\n* **DoD**: The DoD environment requires additional configurations, such as the `AppDeployDoD` parameter in rollout JSON files, and careful management of network traffic and firewall rules. It also includes namespaces affected by issues like `ImagePullBackOff` and `ProgressDeadlineExceeded`, which require accurate image versions and reconciler configurations [Data: Entities (191, 355)].\n\n---\n\n**4. Known Issues and Vulnerabilities**\n\n* **GCC-H**: GCC-H has been affected by container vulnerabilities in components like `deployment-agent-linux` and `sync-agent-linux`. These vulnerabilities impact the security posture of the environment and require targeted remediation efforts [Data: Entities (740)].\n\n* **DoD**: The DoD environment has faced similar issues, such as `ImagePullBackOff` errors and deployment failures due to incompatibility between GCC deployments and the DoD ring. Additionally, the DoD environment has experienced portal outages, impacting access to critical services [Data: Entities (191, 355)].\n\n---\n\n**5. Operational and Access Considerations**\n\n* **GCC-H**: Access to GCC-H clusters requires specific roles, such as Contributor, Operator, and LogReader. Elevation requests are necessary for debugging and management tasks, and deployments often require Lockbox approvals [Data: Entities (218)].\n\n* **DoD**: Operations in the DoD environment require elevated permissions and specific monitoring subscriptions. The environment also demands meticulous management of deployment artifacts and configurations to ensure compatibility with the DoD ring [Data: Entities (191)].\n\n---\n\n**6. Use Cases**\n\n* **GCC-H**: Primarily used for hosting civilian government workloads that require high security and compliance but do not involve defense-specific operations [Data: Entities (740)].\n\n* **DoD**: Exclusively used for defense-related applications and services, with a focus on supporting U.S. defense agencies\' stringent operational and security needs [Data: Entities (191)].\n\n---\n\n**Summary**\n\nIn summary, while both GCC-H and DoD environments are part of the COSMIC platform and adhere to ITAR compliance, the DoD environment has stricter security, compliance, and operational requirements. It is specifically tailored for defense operations, whereas GCC-H is designed for broader government use cases. These differences necessitate distinct deployment configurations, troubleshooting procedures, and access controls for each environment.\n\nLet me know if you need further details or specific guidance on building for these environments!\n\n**Date:** 2025-09-16"
    }
  },
  {
    id: 'q12',
    query: "How would you mitigate this incident?\n\n* Title: [NodePoolTrain] NP11C - Images missing from PROD\n\n* Description: Team please help recovering this images to the ACR\n\n* Example error:\n\ncosmic-prod-d04-001-eur-westeurope\n\nic3-fraud-pstn-scoring\n\nImagePullBackOff / ErrImagePull\n\nBack-off pulling image \"cosmicprodacr.azurecr.io/ic3-fraud-calling-proxy@sha256:3520d185de36d978aa1da59f53d72906d9bda5e68492d2a353408c9a47f8f9a3\"",
    modelA: {
      id: 'a12',
      model: 'Model A',
      response: "**Common Causes:**\n\n1.- **Images missing from Azure Container Registry (ACR)**: Images in the registry may have been deleted or improperly tagged/moved to different repositories.\n\n2.- **Pull Access Denied**: Incorrect permissions or missing access for the nodes trying to pull the images.\n\n3.- **Node/Cluster State Issues**: Restarts or issues with the Kubernetes nodes may cause pods to fail in pulling updated images.\n\n4.- **Reference Errors**: Image version mismatch or incorrect hashes in deployment manifests.\n\n---\n\n**Steps to Investigate:**\n\n1.- **Check ACR Image Availability**:\n\n* Navigate to the ACR UI or use Azure CLI to confirm the image exists in the registry.\n\n* Command: `az acr repository show --name <acr_name> --image <image_name>`.\n\n2.- **Verify Deployment Manifests**:\n\n* Inspect the Deployment/Pod spec for correct `image` tag or hash using: `cc get deployments -o yaml` or `cc get pod <pod-name> -o yaml`.\n\n3.- **Kubernetes Events**:\n\n* Use: `cc describe pod <pod_name>` to find detailed error messages or reasons for the `ImagePullBackOff`.\n\n4.- **Node Pool Issues**:\n\n* Check if node restarts or capacity changes have caused issues by describing the nodes: `cc describe node <node_name>`.\n\n5.- **Logs for Errors**:\n\n* Use: `cc logs <pod_name>` to examine if there are logs regarding image pull and registry access.\n\n---\n\n**Mitigation Suggestions:**\n\n1.- **Restore Images to ACR**:\n\n* If images are missing, restore them using the script recommended in previous incidents:\n\n ```\n\n Start-CosmicCopyImageWorkflow.ps1 -DeploymentRing prod -SourceImageDigests <missing-digest>\n\n ```\n\n2.- **Tag Correction**:\n\n* Verify correct tagging/versioning for the image and ensure it\'s redeployed.\n\n3.- **Allowlist Missing ACR**:\n\n* Update security/permission policies to ensure nodes can pull from the correct ACR.\n\n4.- **Recreate Pods**:\n\n* Use: `cc delete pod <pod_name>` or scale your deployment/spec.\n\n5.- **Update Node Configuration**:\n\n* If node-specific errors exist, reconfigure node access or scale pool capacity.\n\n---\n\n**References:**\n\n* [ACR Storage and Troubleshooting](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/troubleshooting/application-deployment/ACR-Storage-Usage-Troubleshooting)\n\n**Similar GitHub Issues and ICMs:**\n\n1.- [ICM# 654248611 - PlatformAgents in ImagePullBackOff](https://portal.microsofticm.com/imp/v5/incidents/details/654248611)\n\n* Resolution: Verified and restored missing images for impacted namespaces.\n\n* Status: **Resolved**\n\n2.- [ICM# 593965812 - Images Missing in NodePoolTrain](https://portal.microsofticm.com/imp/v5/incidents/details/593965812)\n\n* Resolution: Ran `Start-CosmicCopyImageWorkflow.ps1` to restore images.\n\n* Status: **Resolved**\n\n3.- [Issue# 6978 - ImagePullBackOff Detected after Node Restart](https://github.com/substrate-platform/COSMIC/issues/6978)\n\n* Description: Large-scale node restarts caused images being marked unavailable.\n\n* Status: **Closed**"
    },
    modelB: {
      id: 'b12',
      model: 'Model B',
      response: "To mitigate the incident involving missing images in the Azure Container Registry (ACR) and the resulting `ImagePullBackOff` or `ErrImagePull` errors, follow the steps below. These steps are tailored to the COSMIC environment and leverage available tools and processes.\n\n---\n\n**Common Causes**\n\n1.- **Image Not Found in ACR**: The specified image may not exist in the `cosmicprodacr.azurecr.io` registry due to a failed or incomplete image push.\n\n2.- **Image Copy Workflow Issues**: The image may not have been propagated to all required rings or regions.\n\n3.- **Configuration Errors**: Incorrect image references (e.g., wrong SHA256 digest or tag) in the deployment pipeline.\n\n4.- **Network or Permission Issues**: Network isolation or insufficient permissions may prevent the image from being pulled.\n\n---\n\n**Steps to Investigate**\n\n1.- **Verify Image Existence in ACR**:\n\n* Use the Azure CLI to check if the image exists in the `cosmicprodacr.azurecr.io` registry:\n\n ```bash\n\n az acr repository show-manifests --name cosmicprodacr --repository ic3-fraud-calling-proxy\n\n ```\n\n* Confirm the presence of the image with the specified SHA256 digest (`3520d185de36d978aa1da59f53d72906d9bda5e68492d2a353408c9a47f8f9a3`).\n\n2.- **Check Deployment Configuration**:\n\n* Review the deployment spec file to ensure the image reference is correct. Use the `cc edit` command to inspect the deployment:\n\n ```bash\n\n cc edit deployment ic3-fraud-pstn-scoring -n <namespace>\n\n ```\n\n* Verify that the image name, tag, and digest match the expected values.\n\n3.- **Investigate Image Copy Workflow**:\n\n* If the image is missing, check whether it was copied to the production ACR using the Image Copy Pipeline. This can be done by reviewing the pipeline logs in Azure DevOps:\n\n* * [MOBR Copy Pipeline for WW/Sovereign Cloud](https://dev.azure.com/O365Exchange/O365%20Core/_build?definitionId=29812&_a=summary)\n\n* Confirm whether the image was successfully copied to the `cosmicprodacr` registry.\n\n4.- **Check for Network or Permission Issues**:\n\n* Ensure that the cluster has the necessary permissions to pull images from the ACR. If deploying to a sovereign cloud, elevate to the appropriate subscription and verify access:\n\n ```bash\n\n Request-AzureResourceRoleElevation -Role Contributor -SubscriptionId <SubscriptionID> -Reason \"Checking ACR For Image\"\n\n ```\n\n---\n\n**Mitigation Steps**\n\n1.- **Run the Image Copy Workflow**:\n\n* If the image is missing, use the Image Copy Pipeline to copy the image to the production ACR. Example PowerShell command:\n\n ```powershell\n\n $buildTag = \"1.0.XXXX.XXXX\" # Replace with the correct build tag\n\n $isolatedBaseImageName = \"cdpx478ae0ce50f844e799a6cf4b9b40d97e00.azurecr.io/ic3-fraud-calling-proxy\"\n\n $acrDigest = \"sha256:3520d185de36d978aa1da59f53d72906d9bda5e68492d2a353408c9a47f8f9a3\"\n\n $image = \"$isolatedBaseImageName@$acrDigest\"\n\n $rings = @(\"debug\", \"infra\", \"test\", \"prod\")\n\n foreach($ring in $rings){\n\n Start-CosmicCopyImageWorkflow.ps1 -DeploymentRing $ring -SourceImageDigests $image -DeploymentVersion $buildTag\n\n }\n\n ```\n\n2.- **Update Deployment Configuration**:\n\n* If the image reference in the deployment spec is incorrect, update it using the `cc edit` command:\n\n ```bash\n\n cc edit deployment ic3-fraud-pstn-scoring -n <namespace>\n\n ```\n\n* Replace the incorrect image reference with the correct one.\n\n3.- **Scale Down and Scale Up the Deployment**:\n\n* After ensuring the image is available in the ACR and the deployment configuration is correct, restart the affected pods:\n\n ```bash\n\n cc scale deployment ic3-fraud-pstn-scoring -n <namespace> --replicas=0\n\n cc scale deployment ic3-fraud-pstn-scoring -n <namespace> --replicas=<desired-replicas>\n\n ```\n\n4.- **Monitor the Deployment**:\n\n* Use the `cc get pods` and `cc describe pod` commands to monitor the status of the pods:\n\n ```bash\n\n cc get pods -n <namespace>\n\n cc describe pod <pod-name> -n <namespace>\n\n ```\n\n---\n\n**Preventive Measures**\n\n1.- **Automate Image Copying**:\n\n* Ensure that the Image Copy Pipeline is integrated into the deployment process to automatically propagate images to all required rings and regions.\n\n2.- **Implement ACR Cleanup**:\n\n* Use the COSMIC ACR Cleanup Script to manage storage and prevent capacity issues that could disrupt image availability.\n\n3.- **Regularly Validate Deployment Configurations**:\n\n* Periodically review deployment configurations to ensure image references are accurate and up-to-date.\n\n4.- **Scale ACR Usage**:\n\n* If the ACR is nearing capacity, create a new ACR and update the deployment configurations accordingly. Follow the steps outlined in the [ACR Usage Scale-Up Guide](https://o365exchange.visualstudio.com/O365%20Core/_git/GriffinD2?path=/sources/dev/ManagementPlane/MgmtPlane.Configuration/Template/PolicyAssignment/policy-assignment-test-overrides.json&version=GBmaster&_a=contents).\n\n---\n\nBy following these steps, the missing images can be restored to the ACR, and the `ImagePullBackOff` issue can be resolved, ensuring the smooth operation of the affected services.\n\n---\n\n**References**\n\n* [COSMIC CLI (cc)](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/tools/cosmic-cli/access-clusters-with-cc)\n\n* [JIT Elevation](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/tools/cosmic-cli/securely-access-app-jit)\n\n* [MOBR Copy Pipeline](https://dev.azure.com/O365Exchange/O365%20Core/_build?definitionId=29812&_a=summary)\n\n**Date:** 2025-09-16"
    }
  },
  {
    id: 'q13',
    query: "how to request for capacity?",
    modelA: {
      id: 'a13',
      model: 'Model A',
      response: "To request COSMIC capacity:\n\n1.- For capacity required to be deployed in the next 30 days:\n\n* Submit an ad hoc, on-demand capacity request for real-time approval through the [CCX Portal](https://aka.ms/M365CCX).\n\n2.- You can check capacity approvals in [Odyssey](https://aka.ms/vCoreAllocation).\n\n3.- To view regional supply availability, consult:\n\n* [Stratus - Azure Capacity Guide](https://prod.stratus.ms/azure-capacity-guide/regional-summary)\n\n* [Azure Offer Restrictions](https://msit.powerbi.com/groups/me/reports/939367b4-36cd-4fe9-b8fe-f1923e2a1a28/ReportSectiona56a766a728d4a0e73ce?experience=power-bi)\n\nNote:\n\n* Approval isn\'t required for TEST, SDF, or NPE=DEV rings.\n\n* Capacity is approved at the Service ID level, aligning with [Service Tree](https://microsoftservicetree.com/home).\n\n* Partners should request the total vCores needed to deploy by service. COSMIC buffers will be automatically added.\n\nFor support or issues with the capacity process, use the [CCX Portal Ticket Submission](https://aka.ms/M365CCX) (SLA < 24 hrs).\n\nReferences:\n\n* [COSMIC Capacity Overview](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/concepts/m365-capacity/m365-cap-Overview)"
    },
    modelB: {
      id: 'b13',
      model: 'Model B',
      response: "To request capacity in the COSMIC environment, you need to follow a structured process managed by the M365 Capacity Team. Below is a detailed guide on how to initiate and manage capacity requests effectively:\n\n---\n\n**1.- Overview of the Capacity Request Process**\n\nThe capacity request process is designed to allocate additional computational resources (e.g., vCores) required for service expansion, onboarding, or maintaining operations in COSMIC clusters. This process ensures that services have the necessary resources to operate efficiently, especially in constrained regions or during onboarding to higher rings like MSIT and PROD.\n\nCapacity requests are submitted through the **CCX platform**, which validates the request against budget compliance and supply status. For large requests (e.g., over 5,000 vCores), manual approval is required [Data: Entities (1271, 9033); Relationships (15929)].\n\n---\n\n**2.- Steps to Submit a Capacity Request**\n\n**Step 1: Pre-Request Planning**\n\n* **Identify Resource Needs**: Determine the required computational resources (e.g., number of vCores, memory) for your service. This includes understanding the regional requirements and aligning with COSMIC Pod SKUs for optimal resource usage.\n\n* **Engage with the M365 Capacity Team**: If you are unsure about your requirements, consult the M365 Capacity Team for guidance. They can assist in planning and validating your request [Data: Entities (9720, 1271); Relationships (9372, 9357)].\n\n**Step 2: Submit the Request**\n\n* **Use the CCX Platform**: Log in to the CCX platform and submit your capacity request. Provide details such as:\n\n* * Service Tree ID\n\n* * Target region(s)\n\n* * Required VM family\n\n* * Number of cores needed\n\n* **Track Status in Grafana**: After submission, you can monitor the status of your request in the Grafana dashboard. This dashboard provides insights into available capacity allocations, expiration dates, and the status of your request [Data: Entities (9033); Relationships (15929, 15928)].\n\n**Step 3: Approval and Validation**\n\n* **Approval by M365 Capacity Team**: The M365 Capacity Team reviews and approves the request. Approved capacity allocations are tracked with an availability date and expiration date.\n\n* **Capacity Validation**: For onboarding to MSIT and PROD rings, capacity validation is performed to ensure that the approved capacity matches the namespace requirements. This step is critical to avoid deployment failures [Data: Entities (1271, 9033); Reports (2733)].\n\n---\n\n**3.- Common Issues and Troubleshooting**\n\n* **Insufficient Capacity**: If your request is rejected due to insufficient capacity in the target region, consider submitting a new request with adjusted parameters or exploring alternative VM SKUs [Data: Entities (3244); Relationships (5852)].\n\n* **Expired Approvals**: Capacity approvals are valid for a limited time (e.g., two months). Ensure that you utilize the approved capacity before the expiration date. If the approval expires, you will need to submit a new request [Data: Entities (4762); Reports (2733)].\n\n* **Incorrect Service Tree ID**: Ensure that the correct Service Tree ID is included in your request. Errors in this field can lead to delays or failures in capacity allocation [Data: Entities (1271); Relationships (4848)].\n\n---\n\n**4.- Additional Support**\n\n* **CCX Support Tickets**: If you encounter issues during the request process, submit a support ticket through the CCX platform. Provide details such as capacity IDs or screenshots to expedite resolution [Data: Entities (9035); Relationships (15930)].\n\n* **COSMIC911**: For urgent capacity-related issues, you can escalate through the COSMIC911 platform. This is particularly useful for resolving blockers during onboarding [Data: Entities (9032); Relationships (15931)].\n\n* **Contact the Capacity Team**: For further assistance, you can reach out to the M365 Capacity Team via email (e.g., opgcosmiccapacity@microsoft.com) [Data: Entities (5390)].\n\n---\n\n**5.- Key Considerations**\n\n* **Mandatory for MSIT and PROD Rings**: Capacity requests are required for onboarding to MSIT and PROD rings. While not mandatory for TEST and SDF rings, it is strongly recommended to avoid resource constraints during cluster build-out [Data: Reports (2733)].\n\n* **Plan for Constrained Regions**: Some regions, such as US regions, may have limited capacity. Engage with the Capacity Team early to mitigate potential issues [Data: Reports (2733)].\n\n---\n\nBy following these steps and leveraging the available tools and support systems, you can ensure a smooth capacity request process in the COSMIC environment. For more details, refer to the [COSMIC Capacity Documentation](https://o365exchange.visualstudio.com/O365%20Core/_wiki/wikis/O365%20Core.wiki/202651/COSMIC-Capacity).\n\n---\n\n### References\n\n* [COSMIC Capacity Documentation](https://o365exchange.visualstudio.com/O365%20Core/_wiki/wikis/O365%20Core.wiki/202651/COSMIC-Capacity)\n\n* [Grafana Dashboard for Capacity Tracking](https://cosmicmonitoring-b6a0cza8a4ghfnda.scus.grafana.azure.com/d/c078eb3d-9561-4c9d-b99d-e5ebffb12545/capacity-allocation-partner?orgId=1)\n\n**Date:** 2025-09-16"
    }
  },
  {
    id: 'q14',
    query: "What is cosmic app deployment",
    modelA: {
      id: 'a14',
      model: 'Model A',
      response: "COSMIC app deployment refers to deploying containerized applications in the COSMIC platform. This involves managing and deploying Kubernetes resources, integrating with Cosmic-specific tools and constraints, and ensuring a seamless, compliant runtime environment for microservices. Key features include:\n\n1.- **Use of Deployment Pipelines**:\n\n* Services typically deploy using EV2 workflows or similar mechanisms.\n\n* Custom deployment attributes, such as node selectors or resource quotas, need to adhere to COSMIC-dependent configurations.\n\n2.- **Compliance with Namespace and Partitioning**:\n\n* Applications are deployed within specific namespaces.\n\n* Correct metadata propagation for partitions is crucial for availability and routing.\n\n3.- **Reliability and Troubleshooting**:\n\n* App deployments strictly follow rules for readiness probes, resource quotas, and CNAME/ATM monitoring setups.\n\n* Built-in validation steps help partners align their configurations and resources with expected standards.\n\nReferences:\n\n* [App Deployment General Troubleshooting](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/troubleshooting/application-deployment/App-Deployment-General-Troubleshooting) for common issues during deployment."
    },
    modelB: {
      id: 'b14',
      model: 'Model B',
      response: "**Overview of COSMIC App Deployment**\n\nCOSMIC App Deployment refers to the process and infrastructure used to deploy applications within the COSMIC platform. It is a critical component of the COSMIC ecosystem, designed to ensure that application changes are efficiently and securely deployed across various environments, including development (Dev), integration (INT), and production (Prod). The deployment process is highly automated and adheres to strict validation, configuration, and compliance standards to maintain the stability and reliability of the platform.\n\nThe COSMIC App Deployment system is built on a robust pipeline that integrates multiple tools and services, such as the EV2 deployment system, Azure DevOps, and the COSMIC Inventory Store. These components work together to manage the lifecycle of application deployments, from build and validation to release and monitoring [Data: Entities (367, 4478, 8912, 10301); Relationships (7946, 18856, 18857)].\n\n---\n\n**Key Components of COSMIC App Deployment**\n\n1.- **Application Deployment Pipeline**:\n\n* The COSMIC App Deployment pipeline is a Coronado-based Continuous Deployment (CD) solution. It uses metadata from Azure DevOps release definitions and follows a Configuration-as-Code (CaC) approach, with the Git-based COSMIC Inventory Store serving as the source of truth for configurations. This ensures that deployments are consistent, traceable, and compliant [Data: Entities (10301); Relationships (18856, 18857)].\n\n2.- **Core Components**:\n\n* **Application Deployment Extension**: Handles the deployment of partner applications and updates to COSMIC clusters.\n\n* **Release Service**: Manages the release process, including approvals and validations.\n\n* **Sync Agent**: Ensures synchronization of deployment configurations across environments.\n\n* **Deployment Agent**: Executes the deployment tasks within the COSMIC infrastructure [Data: Entities (4478); Relationships (7941, 7942, 7943, 7944)].\n\n3.- **Validation and Monitoring**:\n\n* The deployment process includes multiple validation stages, such as `ValidateAppPackage` and `ValidatePartitions`, to ensure that application changes meet the required standards before being deployed.\n\n* Monitoring tools like Grafana Dashboards and the EV2 Portal are used to track deployment success rates, submission times, and incidents. These tools provide partners with insights into the health and performance of their deployments [Data: Sources (2518); Entities (4478, 10301)].\n\n---\n\n**Known Issues and Troubleshooting**\n\nCOSMIC App Deployment is a complex system, and issues can arise during the deployment process. Some common problems include:\n\n1.- **Failed Submissions**:\n\n* Deployment submissions may fail due to connectivity issues with the Release Service or insufficient permissions on the Azure Container Registry (ACR). These issues often require re-triggering the deployment pipeline or adjusting permissions [Data: Entities (367, 1086); Relationships (11932, 1916)].\n\n2.- **Hanging or Timing Out**:\n\n* Deployments can hang or time out, blocking critical release validation and rollout processes. This may necessitate retries or manual intervention [Data: Entities (1086); Relationships (1916)].\n\n3.- **Resource Constraints**:\n\n* Deployment failures can occur due to insufficient resources in the Kubernetes cluster, such as CPU or memory. Troubleshooting steps include scaling the cluster or adjusting resource requests and limits [Data: Entities (1781)].\n\n4.- **Deployment Freezes**:\n\n* Deployment freezes, managed by the COSMIC OCE team, can halt the pipeline to enforce compliance with validation policies. Partners must coordinate with the OCE team to resolve such freezes [Data: Entities (367)].\n\n---\n\n**Tools and Resources for Partners**\n\nPartners deploying applications in COSMIC have access to several tools and resources to facilitate and troubleshoot deployments:\n\n1.- **COSMIC CLI (`cc`)**:\n\n* Partners can use the `cc` command-line tool to interact with COSMIC clusters, monitor deployments, and debug issues. For example:\n\n* * View deployment logs: `cc logs <pod-name>`\n\n* * Debug a pod: `cc cosmic-debug pod <pod-name>` [Data: Sources (3634)].\n\n2.- **COSMIC Operations Portal (COP)**:\n\n* The COP provides a web-based interface for managing deployments, viewing logs, and scaling deployments. It complements the CLI by offering a user-friendly platform for service management [Data: Sources (3634)].\n\n3.- **Grafana Dashboards**:\n\n* Dashboards like the Deployment Monitoring Dashboard and App Deployment Health Dashboard provide detailed metrics and insights into deployment performance and incidents [Data: Sources (2518)].\n\n---\n\n**Conclusion**\n\nCOSMIC App Deployment is a sophisticated and essential system for managing application lifecycles within the COSMIC platform. By leveraging advanced tools, automated pipelines, and robust validation processes, it ensures that application changes are deployed securely and efficiently. While issues can arise, the availability of self-serve debugging tools, monitoring dashboards, and support teams like the COSMIC App Deployment Team helps partners resolve problems and maintain smooth operations [Data: Entities (4478, 8912, 10301, 11306); Sources (2518, 3634)].\n\n**Date:** 2025-09-16"
    }
  },
  {
    id: 'q15',
    query: "how to elevate to Management Plane in cosmic? if I need to assign permissions to some resouces",
    modelA: {
      id: 'a15',
      model: 'Model A',
      response: "**Elevating to the Management Plane in COSMIC**\n\nTo elevate to the Management Plane for assigning permissions or managing resources in COSMIC, you typically need to request Just-In-Time (JIT) elevation, which provides temporary access to specific roles required for your operations.\n\n**Steps to Request Elevation:**\n\n1.- **Request Namespace Elevation**:\n\n* If you require namespace-specific access (e.g., Contributor role for deployment tasks):\n\n ```\n\n Request-CosmicNamespaceElevation -Ring <Test|SDF|MSIT|PROD> -Location <eastus|westus2...> -Role Contributor -Namespace <namespace_name> -Reason \"Assign permissions\"\n\n ```\n\n2.- **Request Cluster Elevation**:\n\n* For cluster-wide access, access as a Contributor role:\n\n ```\n\n Request-CosmicClusterElevation -Ring <Test|SDF|MSIT|PROD> -Location <eastus|westus2...> -Role Contributor -Reason \"Resource permission assignment\"\n\n ```\n\n3.- Use the `cc` CLI after gaining the required role to manage resources.\n\n**Notes:**\n\n* Access must comply with your security group rules (e.g., Geneva logs, Kusto data pipelines).\n\n* For detailed role assignments (e.g., Key Vault Contributor), permissions need to be explicitly granted within deployment manifests or the Azure portal, depending on the resource type.\n\n**References:**\n\n* [How to Take Dumps via Debug Commands](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/troubleshooting/debug-tools/How-to-processdump)"
    },
    modelB: {
      id: 'b15',
      model: 'Model B',
      response: "To elevate permissions to the COSMIC Management Plane for assigning permissions to resources, you will need to follow the Just-In-Time (JIT) elevation process specific to COSMIC. Below are the steps and considerations for achieving this:\n\n---\n\n**Understanding Management Plane Elevation**\n\nThe COSMIC Management Plane is a critical component responsible for orchestrating resources, services, and operations across COSMIC clusters. Elevation to the Management Plane is often required for tasks such as assigning permissions to resources, configuring RBAC settings, or managing subscriptions. This process ensures that only authorized users can perform privileged actions, maintaining the security and integrity of the platform [Data: Entities (426, 8207); Reports (589)].\n\n---\n\n**Steps to Elevate to the Management Plane**\n\n1.- **Determine the Required Role**:\n\n* Identify the specific role you need for the task. For example:\n\n* * **Contributor Role**: Required for modifying and managing resources.\n\n* * **Reader Role**: For read-only access to resources.\n\n* * **LogReader Role**: For accessing logs and debugging.\n\n* For assigning permissions to resources, the **Contributor Role** is typically required [Data: Entities (2358, 8207, 10747)].\n\n2.- **Request Elevation**:\n\n* Use the appropriate JIT elevation command to request access. For namespace-level actions, you can use:\n\n ```bash\n\n Request-CosmicNamespaceElevation -Ring <ring> -Location <location> -Role Contributor -Namespace <namespace> -Reason \"Assigning permissions to resources\"\n\n ```\n\n* For cluster-level actions, use:\n\n ```bash\n\n Request-CosmicClusterElevation -Ring <ring> -Location <location> -Role Contributor -Reason \"Assigning permissions to resources\"\n\n ```\n\n* Ensure you specify the correct ring, location, and namespace or cluster details [Data: Entities (5563, 3934); Reports (2786)].\n\n3.- **Verify Elevation**:\n\n* Once the elevation request is approved, verify your elevated permissions by running a test command, such as listing resources in the namespace or cluster:\n\n ```bash\n\n cc get pods -n <namespace>\n\n ```\n\n4.- **Perform the Required Actions**:\n\n* After elevation, you can assign permissions to resources. For example, to configure RBAC settings, ensure that the necessary Azure Active Directory (AAD) groups are added to the resource\'s RBAC configuration. This is particularly important during tasks like MP Takeover or managing ATM subscriptions [Data: Entities (3427); Reports (2275)].\n\n---\n\n**Common Issues and Troubleshooting**\n\n* **Elevation Errors**:\n\n* * If you encounter errors during elevation, such as blocked or auto-denied requests, ensure that:\n\n* * * You have the necessary eligibility (e.g., GriffinD2 eligibility for certain roles).\n\n* * * Your JIT account is properly configured [Data: Entities (5976, 1194)].\n\n* * Contact the COSMIC Security and Secrets Team for assistance if the issue persists [Data: Relationships (10397)].\n\n* **403 Errors in COP**:\n\n* * If you experience permission errors in the COSMIC Operation Portal (COP) after elevation, ensure that your role elevation has been properly configured and reverted if necessary. Misconfigured AzureResourceRoleElevation can also lead to such issues [Data: Reports (1928)].\n\n---\n\n**Additional Resources**\n\n* **COSMIC CLI Documentation**: [Access Clusters with cc](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/tools/cosmic-cli/access-clusters-with-cc)\n\n* **JIT Elevation Guide**: [Securely Access App JIT](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/tools/cosmic-cli/securely-access-app-jit)\n\n* **COSMIC Operation Portal (COP)**: [COP Portal](https://aka.ms/cop)\n\n---\n\nBy following these steps, you can successfully elevate to the Management Plane and assign permissions to resources. If you encounter any issues, refer to the troubleshooting section or reach out to the appropriate support teams.\n\n**Date:** 2025-09-16"
    }
  },
  {
    id: 'q16',
    query: "Show me how you would mitigate this issue:\n\nDeployment stuck on the test stage and blocking our whole CICD\n\nHere\'s the EV2 error:\n\n[14f65c12-aecb-4cff-b87b-8007ed896fdb] deploymentName: \'meetingartifacts-deployment\', podName: \'meetingartifacts-deployment-748b796997-4rkwr\' is in Pending state, indicating a failed scheduling issue. Reason \'FailedScheduling\', Message: \'0/13 nodes are available: 1 node(s) had untolerated taint {ignore-taint.cluster-autoscaler.kubernetes.io/draining: true}, 2 node(s) were unschedulable, 3 node(s) didn\'t match Pod\'s node affinity/selector, 7 node(s) had untolerated taint {ignore-taint.cluster-autoscaler.kubernetes.io/cosmicready: true}. preemption: 0/13 nodes are available: 13 Preemption is not helpful for scheduling.\'. The estimated time to fully propagate updates to all pods is approximately 60 minutes, under optimal conditions with no capacity constraints or partner package/runtime dependencies impacting deployment.",
    modelA: {
      id: 'a16',
      model: 'Model A',
      response: "**Mitigation Plan for Deployment Stuck at Test Stage with \"FailedScheduling\" Error**\n\n**Common Causes**\n\n1.- **Untolerated Node Taints**: Nodes might have taints like `{ignore-taint.cluster-autoscaler.kubernetes.io/cosmicready: true}` or others, which prevent scheduling.\n\n2.- **Node Affinity or Selector Mismatches**: Pod\'s affinity/selector rules might not match available nodes.\n\n3.- **Node Resource Constraints**: Insufficient resources (e.g., CPU, memory) on the nodes.\n\n4.- **Cluster Autoscaler Issues**: Autoscaler might not create additional nodes due to misconfigurations.\n\n5.- **Anti-Affinity Rules or Topology Constraints**: Pods constrained by custom topologies or anti-affinity rules.\n\n---\n\n**Steps to Investigate**\n\n1.- **Describe Pod Events**: Run:\n\n ```\n\n cc describe pod <pod_name>\n\n ```\n\n Check taints or affinity/selector mismatches in the scheduling events.\n\n2.- **Inspect Node Status**:\n\n ```\n\n cc get nodes -o wide\n\n ```\n\n Look for taints, unready nodes, or nodes with high resource utilization.\n\n3.- **Check Deployment Details**:\n\n ```\n\n cc describe deployment <deployment_name>\n\n ```\n\n Verify affinity/anti-affinity rules or topology constraints.\n\n4.- **Cluster Autoscaler State**: Use Kusto queries or cluster monitoring dashboards to confirm autoscaler activity.\n\n5.- **Manual Insights**: Investigate taints like `{ignore-taint.cluster-autoscaler.kubernetes.io/draining: true}` and ensure nodes aren\'t being drained incorrectly.\n\n---\n\n**Mitigation Suggestions**\n\n1.- **Remove Non-Critical Node Taints**: Manually remove unnecessary taints to unblock scheduling temporarily:\n\n ```\n\n cc taint nodes <node_name> <taint>-\n\n ```\n\n2.- **Update Node Affinity/Selector Rules**: Adjust affinity or selector rules in the deployment manifest.\n\n3.- **Scale Node Pool**: Ensure sufficient capacity by scaling the node pool:\n\n ```\n\n az aks nodepool update --resource-group <rg_name> --cluster-name <cluster_name> --size <new_size>\n\n ```\n\n4.- **Relax Anti-Affinity Rules**: Temporarily relax anti-affinity constraints.\n\n5.- **Coordination with COSMIC Team**: If the problem persists, escalate to the COSMIC Topology or Capacity team for detailed investigation and resolution.\n\n6.- **Restart Deployment**: Post-mitigation, restart the deployment:\n\n ```\n\n cc rollout restart deployment <deployment_name> -n <namespace>\n\n ```\n\n---\n\n**References**\n\n* [App Deployment General Troubleshooting](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/troubleshooting/application-deployment/App-Deployment-General-Troubleshooting)\n\n* [Code Blue Alert Pod Provisioning TSG](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/troubleshooting/CodeBlueAlerts/CodeBlueAlertPodProvisioningTSG)\n\n**Similar GitHub Issues and ICMs**\n\n1.- [Issue# 2396 - Pod in test ring partition always in \"Pending\" state](https://github.com/substrate-platform/COSMIC/issues/2396)\n\n* **Description**: Node taints causing scheduling issues.\n\n* **Resolution**: Adjusted node affinity/taints to allow scheduling.\n\n* **Status**: Closed.\n\n2.- [ICM# 657043007 - Pod remains Pending state during new deployment](https://portal.microsofticm.com/imp/v5/incidents/details/657043007)\n\n* **Description**: Untolerated taints blocked pod scheduling.\n\n* **Resolution**: Taints manually removed.\n\n* **Status**: Resolved.\n\n3.- [ICM# 669970673 - COSMIC failed scheduling - untolerated taint](https://portal.microsofticm.com/imp/v5/incidents/details/669970673)\n\n* **Description**: Taints and node affinity issues caused pods to remain unscheduled.\n\n* **Resolution**: Resolved via automated enrichment with capacity adjustments.\n\n* **Status**: Resolved."
    },
    modelB: {
      id: 'b16',
      model: 'Model B',
      response: "To address the issue of a deployment stuck in the test stage due to a failed scheduling issue, we need to systematically investigate and mitigate the root causes. Below is a structured approach to resolving this problem.\n\n---\n\n**Common Causes**\n\nThe error message indicates several potential root causes for the scheduling failure:\n\n1.- **Untolerated Taints**: Nodes have taints such as `{ignore-taint.cluster-autoscaler.kubernetes.io/draining: true}` and `{ignore-taint.cluster-autoscaler.kubernetes.io/cosmicready: true}` that the pod does not tolerate.\n\n2.- **Node Affinity/Selector Mismatch**: The pod\'s node affinity or selector rules do not match the available nodes.\n\n3.- **Unschedulable Nodes**: Some nodes are marked as unschedulable, possibly due to maintenance or configuration issues.\n\n4.- **Preemption Ineffectiveness**: The cluster-autoscaler is unable to preempt existing workloads to free up resources for the pending pod.\n\n---\n\n**Steps to Investigate**\n\n1.- **Check Pod Events and Scheduling Details**:\n\n Use the `cc` CLI to describe the pod and gather more details about the scheduling failure:\n\n ```bash\n\n cc describe pod meetingartifacts-deployment-748b796997-4rkwr -n <namespace>\n\n ```\n\n Look for specific taints, affinity rules, or resource constraints causing the issue.\n\n2.- **Inspect Node Conditions**:\n\n List all nodes in the cluster and check their taints, conditions, and allocatable resources:\n\n ```bash\n\n cc get nodes\n\n cc describe node <node-name>\n\n ```\n\n Focus on nodes with the taints `{ignore-taint.cluster-autoscaler.kubernetes.io/draining: true}` and `{ignore-taint.cluster-autoscaler.kubernetes.io/cosmicready: true}`.\n\n3.- **Verify Node Affinity Rules**:\n\n Check the deployment\'s node affinity and selector configuration:\n\n ```bash\n\n cc describe deployment meetingartifacts-deployment -n <namespace>\n\n ```\n\n Ensure the affinity rules align with the available nodes.\n\n4.- **Check Cluster Autoscaler Logs**:\n\n Investigate whether the cluster-autoscaler is functioning correctly and why preemption is not effective. This may require JIT elevation to access logs:\n\n ```bash\n\n cc logs -n kube-system <cluster-autoscaler-pod-name>\n\n ```\n\n5.- **Review Resource Requests and Limits**:\n\n Ensure the pod\'s resource requests (CPU, memory) are within the allocatable limits of the nodes:\n\n ```bash\n\n cc describe pod meetingartifacts-deployment-748b796997-4rkwr -n <namespace>\n\n ```\n\n---\n\n**Mitigation Suggestions**\n\n1.- **Handle Untolerated Taints**:\n\n* If the taints are temporary (e.g., draining nodes), wait for the nodes to become available or manually uncordon them:\n\n ```bash\n\n cc uncordon <node-name>\n\n ```\n\n* If the taints are permanent, add tolerations to the deployment to allow the pod to schedule on these nodes:\n\n ```yaml\n\n tolerations:\n\n - key: \"ignore-taint.cluster-autoscaler.kubernetes.io/cosmicready\"\n\n operator: \"Exists\"\n\n effect: \"NoSchedule\"\n\n ```\n\n2.- **Adjust Node Affinity Rules**:\n\n Modify the deployment\'s node affinity or selector rules to match the available nodes:\n\n ```bash\n\n cc edit deployment meetingartifacts-deployment -n <namespace>\n\n ```\n\n Update the `nodeAffinity` section to align with the cluster\'s node labels.\n\n3.- **Scale Up the Cluster**:\n\n If resource constraints are the issue, scale up the cluster to add more nodes:\n\n ```bash\n\n cc scale deployment cluster-autoscaler --replicas=<desired-count>\n\n ```\n\n4.- **Restart the Deployment**:\n\n After making changes, restart the deployment to trigger a new scheduling attempt:\n\n ```bash\n\n cc rollout restart deployment meetingartifacts-deployment -n <namespace>\n\n ```\n\n5.- **Coordinate with the COSMIC Team**:\n\n If the issue persists, escalate to the COSMIC team for further investigation, especially if the taints or node conditions are managed at the platform level.\n\n---\n\n**Preventive Measures**\n\n1.- **Enable Rightsizing**:\n\n Ensure the deployment is configured for rightsizing to optimize resource allocation. Check for the `machete.microsoft.com/rightsizingPercentage` annotation:\n\n ```bash\n\n cc describe deployment meetingartifacts-deployment -n <namespace>\n\n ```\n\n2.- **Monitor Cluster Health**:\n\n Use the COSMIC Operation Portal (COP) to monitor cluster health and deployment status:\n\n [COSMIC Operation Portal (COP)](https://aka.ms/cop)\n\n3.- **Validate Configurations in Pre-Production**:\n\n Use the SDF Ring or other pre-production environments to validate configurations before deploying to production.\n\n---\n\n**References**\n\n* [JIT Elevation](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/tools/cosmic-cli/securely-access-app-jit)\n\n* [COSMIC CLI (cc)](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/tools/cosmic-cli/access-clusters-with-cc)\n\n* [COSMIC Operation Portal (COP)](https://aka.ms/cop)\n\nBy following these steps, you should be able to identify and resolve the root cause of the scheduling issue, allowing the deployment to proceed.\n\n**Date:** 2025-09-16"
    }
  },
  {
    id: 'q17',
    query: "can you show how to troubleshoot pods in crashloopbackoff issue?",
    modelA: {
      id: 'a17',
      model: 'Model A',
      response: "**Steps to Troubleshoot Pods in `CrashLoopBackOff`**\n\n**Common Causes**:\n\n1.- **Application Errors**: Code-level issues causing the application to crash repeatedly.\n\n2.- **Configuration Failures**: Incorrect environment variables, config maps, or secrets.\n\n3.- **Resource Constraints**: Memory or CPU limits insufficient for the container.\n\n4.- **Dependency Failures**: External services or dependencies unreachable.\n\n5.- **Startup/Readiness Probe Failures**: Incorrect Kubernetes probe configurations.\n\n6.- **Platform Instability**: Node issues or taints preventing pod execution.\n\n---\n\n**Steps to Investigate**\n\n1.- **Check Pod Status**:\n\n ```\n\n cc get pods\n\n cc describe pod <pod-name>\n\n ```\n\n Review the events and reasons behind `CrashLoopBackOff`.\n\n2.- **Check Container Logs**:\n\n ```\n\n cc logs <pod-name> --previous\n\n ```\n\n Look for runtime errors or dependency issues in the logs.\n\n3.- **Verify Resource Allocations**:\n\n ```\n\n cc get pod <pod-name> -o yaml\n\n ```\n\n Check configurations such as `limits` and `requests`.\n\n4.- **Examine Configuration Files**:\n\n* Validate that correct ConfigMaps, Secrets, or environment variables are mounted as expected.\n\n5.- **Run Readiness Probe Debugging**:\n\n ```\n\n cc describe pod <pod-name>\n\n ```\n\n Ensure readiness or startup probes pass and aren \'t causing repeated restarts.\n\n6.- **Kubernetes Node Issues**: Check node health and taints:\n\n ```\n\n cc describe node <node-name>\n\n ```\n\n---\n\n**Mitigation Suggestions**\n\n1.- **Fix Application Errors**:\n\n* Review code and logs to identify crash sources.\n\n* Redeploy after fixing issues.\n\n2.- **Correct Configuration or Secrets**:\n\n* Verify mounted volumes, environment variable paths.\n\n* Fix missing secrets or invalid configurations.\n\n3.- **Increase Resource Allocations**:\n\n* Adjust the `requests` or `limits` in the pod spec.\n\n4.- **Resolve Dependency Failures**:\n\n* Ensure network and external services are reachable.\n\n5.- **Fix Probe Configurations**:\n\n* Correct misconfigured startup/readiness/liveness probes.\n\n6.- **Restart or Replace Affected Nodes**: If nodes show issues, cordon and replace them:\n\n ```\n\n cc drain <node-name>\n\n ```\n\n---\n\n### References\n\n* [Seccomp Troubleshooting Guide](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/troubleshooting/linux-seccomp/seccomp-troubleshooting-guide)\n\n* [Pod CrashLoopBackOff Alert Troubleshooting](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/onboarding/monitor/pod-crashloopbackoff-alert-tsg)\n\n### Similar GitHub Issues and ICMs\n\n1.- [Issue# 6494 - Deployment shows CrashLoopBackOff](https://github.com/substrate-platform/COSMIC/issues/6494)\n\n* **Description**: Deployment stuck with pods in `CrashLoopBackOff`.\n\n* **Resolution**: Fixed configuration issues (labels and bootstrap files).\n\n* **Status**: Closed.\n\n2.- [Issue# 469 - CrashLoopBackOff on Deployment](https://github.com/substrate-platform/COSMIC/issues/469)\n\n* **Description**: Deployment fails due to repeated restarts from invalid secret references.\n\n* **Resolution**: Adjusted Key Vault allowlist and implemented MSI strategies.\n\n* **Status**: Closed.\n\n3.- [ICM# 632970420 - Missing CrashLoopBackOff Alerts for a Namespace](https://portal.microsofticm.com/imp/v5/incidents/details/632970420)\n\n* **Description**: CrashLoopBackOff caused availability drop, mitigating actions failed initially due to misconfiguration.\n\n* **Resolution**: Mitigation involved correcting monitoring configurations and removing failing pods.\n\n* **Status**: Resolved.\n\n4.- [ICM# 610589763 - Cosmic Pods Failing Post-Deployment](https://portal.microsofticm.com/imp/v5/incidents/details/610589763)\n\n* **Description**: Pods in CrashLoopBackOff due to incorrect PDB configuration and resource limits.\n\n* **Resolution**: Evacuated deployment and fixed PDB violations.\n\n* **Status**: Resolved."
    },
    modelB: {
      id: 'b17',
      model: 'Model B',
      response: "**Troubleshooting Pods in CrashLoopBackOff State**\n\nWhen a pod enters a `CrashLoopBackOff` state in the COSMIC platform, it indicates that the pod is repeatedly failing and restarting. This issue can arise due to various reasons, including application errors, configuration issues, resource constraints, or dependency failures. Below is a structured guide to troubleshoot and resolve this issue.\n\n---\n\n**Common Causes**\n\n1.- **Application Errors**: Issues within the application code, such as unhandled exceptions or runtime errors, can cause containers to crash [Data: Relationships (21004)].\n\n2.- **Configuration Errors**: Incorrect environment variables, missing configuration files, or invalid pod specifications can lead to crashes [Data: Relationships (21005)].\n\n3.- **Dependency Failures**: Failures in accessing required services or APIs during container startup can result in crashes [Data: Relationships (21006)].\n\n4.- **Probe Failures**: Misconfigured liveness or readiness probes can cause Kubernetes to restart containers unnecessarily [Data: Relationships (21008)].\n\n5.- **Platform Instability**: Issues with the underlying node or platform services, such as managed identity binding failures, can disrupt pod operations [Data: Relationships (21009)].\n\n6.- **Resource Constraints**: Insufficient CPU, memory, or ephemeral storage can prevent pods from running successfully [Data: Reports (208)].\n\n---\n\n**Steps to Investigate**\n\n1.- **Check Pod Events and Logs**:\n\n* Use the `cc describe pod <pod-name>` command to view the pod\'s events and identify the reason for the crash.\n\n* Retrieve logs using `cc logs <pod-name>` to analyze the container\'s output and identify errors or stack traces.\n\n2.- **Inspect Configuration**:\n\n* Verify the pod\'s configuration using `cc describe pod <pod-name>` to ensure environment variables, volume mounts, and other settings are correct.\n\n* Check for missing or invalid `cosmicIdentity` fields in the namespace configuration, as these are critical for identity binding [Data: Reports (208)].\n\n3.- **Analyze Resource Usage**:\n\n* Use `cc top pods` and `cc top nodes` to check resource utilization and identify potential bottlenecks.\n\n* Look for error messages like \"Insufficient CPU\" or \"Insufficient memory\" in the pod events [Data: Reports (208)].\n\n4.- **Validate Probes**:\n\n* Review the liveness and readiness probe configurations in the pod spec. Misconfigured probes can cause unnecessary restarts [Data: Entities (11286)].\n\n5.- **Check Dependency Status**:\n\n* If the pod relies on external services, verify their availability and connectivity. Use `cc logs` to identify dependency-related errors [Data: Entities (11285)].\n\n6.- **Platform and Node Issues**:\n\n* Investigate node-level issues using `cc describe node <node-name>` or by checking the COSMIC Operation Portal (COP) for node health and events.\n\n* If the issue is node-specific, consider cordoning and draining the node using `cc cordon <node-name>` and `cc drain <node-name>` [Data: Entities (6946)].\n\n---\n\n**Mitigation Suggestions**\n\n1.- **Fix Application Errors**:\n\n* Address any application-level issues identified in the logs. For example, resolve unhandled exceptions or runtime errors.\n\n2.- **Correct Configuration Issues**:\n\n* Update the pod\'s configuration to fix invalid or missing settings. Use `cc edit pod <pod-name>` to make changes if necessary.\n\n3.- **Adjust Resource Requests and Limits**:\n\n* Modify the pod\'s resource requests and limits to ensure sufficient resources are allocated. Use `cc edit deployment <deployment-name>` to update the deployment spec.\n\n4.- **Resolve Dependency Failures**:\n\n* Ensure all required services and APIs are accessible. Update service endpoints or credentials as needed.\n\n5.- **Update Probe Configurations**:\n\n* Correct any misconfigured liveness or readiness probes to prevent unnecessary restarts.\n\n6.- **Restart Pods**:\n\n* After making changes, restart the affected pods using `cc delete pod <pod-name>`. Kubernetes will recreate the pod with the updated configuration.\n\n7.- **Escalate Persistent Issues**:\n\n* If the issue persists, escalate to the COSMIC team with relevant logs and metrics. Use the COSMIC Operation Portal (COP) to gather additional diagnostics.\n\n---\n\n**Useful Commands**\n\n* **Describe Pod**: `cc describe pod <pod-name>`\n\n* **View Logs**: `cc logs <pod-name>`\n\n* **Check Resource Usage**: `cc top pods`, `cc top nodes`\n\n* **Edit Deployment**: `cc edit deployment <deployment-name>`\n\n* **Restart Pod**: `cc delete pod <pod-name>`\n\n---\n\n**References**\n\n* [JIT Elevation](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/tools/cosmic-cli/securely-access-app-jit)\n\n* [COSMIC CLI (cc)](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/tools/cosmic-cli/access-clusters-with-cc)\n\n* [COSMIC Operation Portal (COP)](https://aka.ms/cop)\n\nBy following these steps, you should be able to identify and resolve the root cause of the `CrashLoopBackOff` state, ensuring stable pod operations in your COSMIC environment.\n\n**Date:** 2025-09-16"
    }
  },
  {
    id: 'q18',
    query: "how do i Consume the Cosmic.ManagementPlane.Inventory.Client SDK in visual studio code",
    modelA: {
      id: 'a18',
      model: 'Model A',
      response: "No specific information was found about the **Cosmic.ManagementPlane.Inventory.Client SDK** in the COSMIC documentation. You might want to confirm the exact SDK or component name or reach out to the COSMIC development team for guidance. In the meantime, here are general steps to consume an SDK in Visual Studio Code:\n\n**General Steps to Consume an SDK in Visual Studio Code**\n\n1.- **Add the SDK as a Dependency**:\n\n* If the SDK is available via NuGet:\n\n ```\n\n dotnet add package <PackageName>\n\n ```\n\n Replace `<PackageName>` with the name of the SDK\'s NuGet package.\n\n2.- **Configure in Your Project**:\n\n* Import the SDK\'s namespace in your code:\n\n ```\n\n using Cosmic.ManagementPlane.Inventory.Client;\n\n ```\n\n3.- **Implement the Client**:\n\n* Follow the SDK\'s documentation to create and initialize clients, and use the provided APIs for the specific functionality.\n\n4.- **Run and Test**:\n\n* Test your integration by running:\n\n ```\n\n dotnet run\n\n ```\n\nIf you need more assistance, you can visit [COSMIC Onboarding and Help](https://aka.ms/cosmic911)."
    },
    modelB: {
      id: 'b18',
      model: 'Model B',
      response: "To consume the `Cosmic.ManagementPlane.Inventory.Client` SDK in Visual Studio Code (VS Code), follow the steps below. This guide assumes you are working in a COSMIC environment and have the necessary permissions and configurations in place.\n\n---\n\n**1.- Prerequisites**\n\nBefore you begin, ensure the following:\n\n* **Development Environment**: Install Visual Studio Code and set up the necessary extensions, such as the `.NET Core` extension for C# development.\n\n* **SDK Access**: Ensure you have access to the `Cosmic.ManagementPlane.Inventory.Client` SDK, which is available as a NuGet package.\n\n* **Authentication**: You will need credentials (e.g., Azure AD tenant ID, client ID, and client secret) to authenticate with the Inventory Service.\n\n---\n\n**2.- Install the SDK**\n\nThe `Cosmic.ManagementPlane.Inventory.Client` SDK is distributed as a NuGet package. To install it in your project:\n\n1.- Open your project in VS Code.\n\n2.- Add the SDK to your project using the following command in the terminal:\n\n ```bash\n\n dotnet add package Microsoft.Cosmic.ManagementPlane.InventoryService.Client\n\n ```\n\n This will add the SDK as a dependency in your `.csproj` file.\n\n3.- Verify the installation by checking the `PackageReference` in your `.csproj` file:\n\n ```xml\n\n <PackageReference Include=\"Microsoft.Cosmic.ManagementPlane.InventoryService.Client\" Version=\"x.y.z\" />\n\n ```\n\n Replace `x.y.z` with the installed version.\n\n---\n\n**3.- Configure the SDK**\n\nTo use the SDK, you need to configure it with the appropriate authentication and endpoint details. Below is an example of how to set up the `Inventory Client`:\n\n**Code Snippet for Client Initialization**\n\n```csharp\n\nusing Microsoft.Cosmic.ManagementPlane.InventoryService.Client;\n\nvar address = \"https://partition00-test.inventory.cosmic-int.office.net:9443\"; // Replace with the appropriate endpoint for your ring (e.g., sdf, msit, prod)\n\nvar tenantId = \"<Your-Tenant-ID>\"; // Azure AD Tenant ID\n\nvar clientId = \"<Your-Client-ID>\"; // Azure AD Client ID\n\nvar clientSecret = \"<Your-Client-Secret>\"; // Azure AD Client Secret\n\nvar scopes = new string[] { \"api://cosmic.managementplane.inventory/.default\" };\n\n// Create an Azure AD Token Provider\n\nvar tokenProvider = new AzureADTokenProvider(tenantId, clientId, clientSecret, scopes);\n\n// Create the Inventory Client\n\nvar inventoryClient = new InventoryClient(new Uri(address), tokenProvider);\n\n```\n\n---\n\n**4.- Perform Inventory Operations**\n\nOnce the client is initialized, you can use it to perform operations on the COSMIC Inventory. For example:\n\n**Example: Create a Record**\n\n```csharp\n\nvar sampleRecord = new InventoryRecord\n\n{\n\n Name = \"SampleRecord\",\n\n Description = \"This is a sample inventory record.\"\n\n};\n\nvar result = await inventoryClient.CreateAsync(sampleRecord, Guid.NewGuid(), CancellationToken.None);\n\nConsole.WriteLine($\"Record created with ID: {result.Id}\");\n\n```\n\n**Example: Retrieve a Record**\n\n```csharp\n\nvar recordId = \"<Record-ID>\";\n\nvar record = await inventoryClient.GetAsync(recordId, CancellationToken.None);\n\nConsole.WriteLine($\"Record Name: {record.Name}, Description: {record.Description}\");\n\n```\n\n---\n\n**5.- Debugging and Troubleshooting**\n\n* **Authentication Issues**: Ensure that the Azure AD credentials (tenant ID, client ID, and client secret) are correct and have the necessary permissions (`CosmicManagementPlane.Inventory.ReadWrite`).\n\n* **Endpoint Configuration**: Verify that the endpoint URL matches the COSMIC ring you are working in (e.g., test, sdf, msit, prod).\n\n* **NuGet Package Issues**: If you encounter errors related to missing dependencies, run the following command to restore packages:\n\n ```bash\n\n dotnet restore\n\n ```\n\n---\n\n**6.- Best Practices**\n\n* **Secure Credentials**: Store sensitive information like client secrets in a secure location, such as environment variables or Azure Key Vault.\n\n* **Error Handling**: Implement robust error handling for API calls to handle scenarios like network failures or invalid inputs.\n\n* **Version Compatibility**: Ensure that the SDK version is compatible with your COSMIC environment.\n\n---\n\n**7.- Additional Resources**\n\n* **COSMIC Documentation**: Refer to the official COSMIC documentation for more details on the `Cosmic.ManagementPlane.Inventory.Client` SDK [Data: Sources (2333, 3473)].\n\n* **NuGet Package**: Check the NuGet package details for updates and version information.\n\n* **API Reference**: Explore the SDK\'s API reference to understand the available methods and their usage.\n\nBy following these steps, you can effectively consume the `Cosmic.ManagementPlane.Inventory.Client` SDK in Visual Studio Code and integrate it into your COSMIC workflows.\n\n**Date:** 2025-09-16"
    }
  },
  {
    id: 'q19',
    query: "How to check deployment start time in ev2rollout table",
    modelA: {
      id: 'a19',
      model: 'Model A',
      response: "To check the deployment start time in the `Ev2Rollout` table, you can query the table in your Log Analytics Workspace across the Rollout logs. Here's an example query path you can follow:\n\n**Steps**:\n\n1.- Ensure you know the **Log Analytics Workspace** your deployment logs are being published to. Common workspace mappings are:\n\n* **Test**: [Log Analytics Workspace for TEST](http://aka.ms/cosmictestnamworkspace-secondary)\n\n* **SDF**: [Log Analytics Workspace for SDF](http://aka.ms/cosmicsdfnamworkspace)\n\n* **MSIT** and **PROD**: [Log Analytics Workspace](http://aka.ms/cosmicmsitnamworkspace)\n\n2.- Run this query in the Log Analytics Workspace:\n\n ```\n\n Ev2RolloutLogs_CL\n\n | where TimeGenerated > ago(1h) // Modify time range as needed\n\n | where RolloutName_s == \"<DeploymentName>\" // Replace with your Deployment Name\n\n | project RolloutStartTime = TimeGenerated, RolloutName = RolloutName_s\n\n | sort by RolloutStartTime asc\n\n ```\n\n Replace `<DeploymentName>` with your deployment identifier.\n\n3.- Review deployment start times after filtering for relevant logs.\n\nIf further assistance is required regarding deployment logs, contact the [COSMIC ICM channel](https://aka.ms/cosmic911).\n\n---\n\n### References\n\n* [App Deployment General Troubleshooting](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/troubleshooting/application-deployment/App-Deployment-General-Troubleshooting)"
    },
    modelB: {
      id: 'b19',
      model: 'Model B',
      response: "To check the deployment start time in the `Ev2Rollout` table, you can use the Log Analytics workspace associated with your COSMIC environment. The `Ev2Rollout` table contains detailed logs about deployment processes, including timestamps for various stages of the rollout. Below are the steps to query the deployment start time:\n\n---\n\n**Steps to Query Deployment Start Time**\n\n1.- **Access the Log Analytics Workspace**:\n\n * Open the Log Analytics workspace corresponding to your deployment environment. This workspace is typically linked to the COSMIC monitoring system.\n\n2.- **Run a KQL Query**:\n\n * Use the following KQL (Kusto Query Language) query to extract the deployment start time:\n\n ```kql\n\n Ev2RolloutCosmicReleaseMap_CL\n\n | where SubmitCosmicDeployment_s == \"Started\"\n\n | project DeploymentStartTime = TimeGenerated, DeploymentName = RolloutName_s\n\n | take 5\n\n ```\n\n * * This query filters for deployments that have started (`SubmitCosmicDeployment_s == \"Started`) and projects the start time (`TimeGenerated`) along with the deployment name (`RolloutName_s`).\n\n3.- **Analyze the Results**:\n\n * The query will return a list of deployments with their start times and names. You can further refine the query by adding filters for specific deployment names, environments, or rings.\n\n---\n\n**Additional Notes**\n\n* **Log Analytics Table**: The `Ev2RolloutCosmicReleaseMap_CL` table is specifically designed to track deployment statuses and failures. It logs key events such as the `SubmitRelease` step, which is critical for identifying deployment progress [Data: Entities (6305); Sources (2921)].\n\n* **Filtering by Environment or Ring**:\n\n* * If you want to narrow down the results to a specific environment or ring (e.g., SDF, MSIT, or Fairfax), you can add additional filters to the query:\n\n ```kql\n\n | where Environment_s == \"SDF\"\n\n ```\n\n* **Tracking Failures**:\n\n* If you suspect deployment issues, you can modify the query to check for failed deployments:\n\n ```kql\n\n | where SubmitCosmicDeployment_s == \"Failed\"\n\n ```\n\n---\n\n**Troubleshooting Deployment Issues**\n\nIf you encounter issues while querying or analyzing deployment logs, consider the following:\n\n* **Check Permissions**: Ensure you have the necessary permissions to access the Log Analytics workspace.\n\n* **Enable No Progress Alerts**: If deployments are stuck, enabling the `EnableNoProgressAlert` property in the rollout parameter file can help generate ICM tickets for better visibility [Data: Entities (10927); Sources (4402)].\n\nFor more detailed tracking, you can also use the EV2 portal to monitor deployment stages and logs [Data: Relationships (14155); Sources (3428)].\n\n---\n\n**References**\n\n* [COSMIC CLI (cc)](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/tools/cosmic-cli/access-clusters-with-cc)\n\n* [COSMIC Operation Portal (COP)](https://aka.ms/cop)\n\n**Date:** 2025-09-16"
    }
  },
  {
    id: 'q20',
    query: "COSMIC\Networking is now leveraging Nightwatch to end-to-end test some of our scenarios. One of those scenarios is what we call Private Endpoints, which in short consists in establishing a private connection between a cluster and an Azure resource.\n\nFor that to work, we\'ll need to create some dummy resources in different subscriptions. Our initial plan is to create 2 KVs and 2 CosmosDBs for WW, ITAR, and Gallatin (totaling thus 12 resources).\n\nGiven the background, our questions for you are:\n\n1.- From security standpoint, do we need any type of approval to create those resources? They won\'t be used for any other purpose rather than the Nightwatch one.\n\n2.- Do we currently hold any automation that either deletes or scans for recently created resources in COSMIC subscriptions? If so, how can we ensure that we are not gonna get flagged by it?\n\n3.- Can we randomly select a subscription to create those resources or is there a recommended (and existent) subscription that we can leverage?\n\n4.- Do you have any suggestions of which resource group we could create our resources? If no suggestions, we\'ll most likely create a new RG.",
    modelA: {
      id: 'a20',
      model: 'Model A',
      response: "**Answers to Your Questions**\n\n**1. Security Approval**\n\nAccording to [Security FAQ](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/onboarding/prerequisites/Security-FAQ), COSMIC-related resource creations must adhere to M365 security requirements. For dummy resources used solely for test scenarios (like Nightwatch), consult your M365 Product Security contacts to confirm if these resources need manual approvals or compliance checks based on your environment (e.g., WW, ITAR, or Gallatin).\n\n---\n\n**2. Automation for Deletion or Scanning**\n\nCOSMIC does not explicitly enforce deletion or scanning automation for recently created resources by partners. Ensure:\n\n* Proper tagging of resources to avoid accidental identification as stale or unused.\n\n* Resources created for test environments are monitored and managed to comply with resource lifecycle best practices.\n\n---\n\n**3. Subscription Selection**\n\nSpecific guidance on selecting subscriptions is not noted. However:\n\n* It is recommended to create resources under a designated subscription aligned with the test environment\'s purpose (e.g., TEST, SDF, ITAR).\n\n* For compliance, select subscriptions with pre-configured ACLs and governance rules. Refer to [Network Security and Traffic Identification](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/onboarding/set-up-service-configurations/Network-Security-and-Traffic-Identification) for network security considerations.\n\n---\n\n**4. Resource Group**\n\nYou can create a new resource group if there aren\'t existing groups meant for test-related resources in your target subscriptions. Ensure the resource group\'s purpose aligns with your testing requirements and use a naming convention consistent with your team\'s standards for log monitoring and cleanup.\n\n---\n\n### Additional Suggestions\n\n* **Tag Dummy Resources**: Ensure resources are tagged correctly (e.g., `Environment:Testing`, `Purpose:Nightwatch`) to denote their temporary nature.\n\n* **Review Compliance**: Coordinate with the CELA (Compliance, Ethics, and Legal Affairs) guidelines, as noted in the [Security, Privacy, and Compliance Reviews](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/onboarding/prerequisites/Security-privacy-compliance-CELA).\n\n### References\n\n* [Security FAQ](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/onboarding/prerequisites/Security-FAQ)\n\n* [Network Security and Traffic Identification](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/onboarding/set-up-service-configurations/Network-Security-and-Traffic-Identification)\n\n* [Security, Privacy, and Compliance Reviews](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/onboarding/prerequisites/Security-privacy-compliance-CELA)"
    },
    modelB: {
      id: 'b20',
      model: 'Model B',
      response: "**1. Security Approval for Resource Creation**\n\nFrom a security standpoint, creating resources like Key Vaults (KVs) and CosmosDBs for testing purposes in COSMIC subscriptions does not inherently require additional approval, provided the resources are used exclusively for Nightwatch testing and do not interact with production workloads. However, there are a few considerations to ensure compliance with COSMIC\'s security and operational standards:\n\n* **Role Assignments and Permissions**: Ensure that the necessary roles (e.g., \"Key Vault Contributor\" or \"CosmosDB Contributor\") are assigned to the appropriate identities. For example, COSMIC Azure Pod Identity or other service identities may need specific permissions to access these resources [Data: Entities (7745, 10802)].\n\n* **Resource Provider Registration**: Verify that the required resource providers (e.g., for Key Vault and CosmosDB) are registered in the target subscriptions. This is a prerequisite for creating and managing these resources [Data: Sources (4424)].\n\n* **Approval for ITAR and Gallatin**: For ITAR and Gallatin environments, additional scrutiny may apply due to their compliance requirements. Ensure that the resources adhere to ITAR and Gallatin-specific guidelines, and consult with the COSMIC compliance team if needed [Data: Entities (10759)].\n\n**2. Automation for Resource Scanning or Deletion**\n\nCOSMIC does have automation processes in place to manage resources, including scanning for orphaned or recently created resources. For example:\n\n* **Orphaned Resource Cleanup**: COSMIC performs cleanup operations for orphaned resources, such as Azure Key Vaults, within specific resource groups (e.g., COSMIC Auth RG) to ensure efficient resource management and security compliance [Data: Entities (1539)].\n\n* **Monitoring and Alerts**: Nightwatch itself emits Geneva MDM metrics (e.g., `NightWatchCosmicResourceTestResult`) to monitor the state of resources. These metrics can help track the health and usage of test resources [Data: Entities (9489, 9496)].\n\nTo avoid being flagged by these processes:\n\n* Clearly label the resources as test resources using appropriate tags or annotations (e.g., `Environment: Test`, `Purpose: Nightwatch`).\n\n* Place the resources in a dedicated resource group or subscription specifically designated for testing purposes.\n\n* Communicate with the COSMIC operations team to ensure these resources are excluded from automated cleanup or monitoring workflows.\n\n**3. Subscription Selection for Resource Creation**\n\nIt is not recommended to randomly select a subscription for creating these resources. Instead, consider the following:\n\n* **COSMIC Management Subscriptions**: Use a COSMIC management subscription, such as the \"COSMIC Management - Dev - TestTRS01\" subscription, which is specifically designated for managing test environments [Data: Entities (4720)].\n\n* **Compliance Requirements**: For ITAR and Gallatin, ensure that the selected subscriptions meet the compliance requirements for these environments [Data: Entities (10759)].\n\n* **Subscription Role Assignment Limits**: Be mindful of the 4K role assignment limit in COSMIC subscriptions, which may impact operations if exceeded [Data: Entities (8022, 8023)].\n\n**4. Resource Group Suggestions**\n\nIf no existing resource group is suitable, creating a new resource group is a valid approach. However, consider the following:\n\n* **Existing Resource Groups**: Check if there are existing resource groups, such as \"COSMIC Test Monitoring RG\" or \"COSMIC Auth RG,\" that are already used for testing or monitoring purposes [Data: Entities (4514, 1539)].\n\n* **Naming Conventions**: Use a clear and descriptive naming convention for the new resource group, such as `Nightwatch-Testing-RG`, to indicate its purpose.\n\n* **Isolation**: Ensure the resource group is isolated from production workloads to avoid accidental interference.\n\n**Additional Recommendations**\n\n* **Tagging and Documentation**: Use consistent tagging and maintain documentation for the created resources to facilitate tracking and management.\n\n* **Resource Cleanup**: Plan for the cleanup of these resources after testing to avoid unnecessary costs and resource sprawl.\n\n* **Coordination with COSMIC Teams**: Inform the COSMIC operations and compliance teams about the testing initiative to ensure alignment with broader operational policies.\n\nBy following these guidelines, you can ensure that the creation and management of test resources for Nightwatch scenarios are secure, compliant, and efficient.\n\n**Date:** 2025-09-16"
    }
  },
  {
    id: 'q21',
    query: "I am seeing a pending pod issue in my namespace and wanted to check if it is caused by a node pool train. What logs should I look at?",
    modelA: {
      id: 'a21',
      model: 'Model A',
      response: "To investigate if a pending pod issue is linked to a **node pool train**, follow these steps:\n\n---\n\n**Logs to Examine**\n\n1.- **Check Pod Events**:\n\n* Use the following command to examine pod events for scheduling or node assignment details:\n\n ```\n\n cc describe pod <pod-name>\n\n ```\n\n* * Look for events like `node(s) didn\'t match Pod\'s node affinity/selector` or `untolerated taints`.\n\n2.- **Inspect Node Logs**:\n\n* Review node taints or status that may prevent pod scheduling:\n\n ```\n\n cc get nodes\n\n cc describe node <node-name>\n\n ```\n\n Focus on taints like `ignore-taint.cluster-autoscaler.kubernetes.io/cosmicready` or `draining`.\n\n3.- **Cluster Autoscaler Logs**:\n\n* Fetch autoscaler logs for scaling insights or node pool issues:\n\n ```\n\n cc describe configmap cluster-autoscaler-status -n kube-system\n\n ```\n\n4.- **Relevant Kusto Events**:\n\n* Query for KubeEvents in Log Analytics for deeper insights (e.g., scheduling delays, taints, or capacity constraints). Example:\n\n ```\n\n KubeEvents\n\n | where Namespace == \"<your-namespace>\"\n\n | sort by TimeGenerated desc\n\n ```\n\n5.- **Deployment Logs and NP Train Logs**:\n\n* Use EV2 logs or deployment analysis tools to confirm if a node pool train was recently run:\n\n* * Access EV2 portal logs ([EV2 Portal](https://ev2portal.azure.net)).\n\n* * Query `Ev2RolloutLogs_CL` table in Log Analytics.\n\n6.- **Check Node Pool Upgrades**:\n\n* Verify if recent node pool upgrades (NP trains) impacted cluster availability:\n\n* * Use [Node Pool Train Dashboards](https://aka.ms/cosmicdeploymentdashboard).\n\n* * Find records for maintenance schedules specific to the ring and cluster.\n\n---\n\n**Additional Tools**\n\n* **COSMIC Operations Portal (COP)**:\n\n* * Check the pods for namespace and node availability using COP: [COP Portal](https://aka.ms/cop).\n\n* **Grafana Dashboards**:\n\n* * Use the [Pod Health Dashboard](https://aka.ms/cosmic/namespacehealth) to view cluster-wide pod health.\n\n---\n\n**Common Causes**\n\n* **Active Node Pool Train**: Nodes undergoing upgrades may cause temporary pod scheduling delays.\n\n* **Node Taints**: Taints during upgrades (e.g., `draining` or `cosmicready`).\n\n* **Affinity or Resource Mismatch**: Pods could fail to schedule if node selectors or resource requests don\'t match node capabilities.\n\n* **Cluster Autoscaler Issues**: Failures or scaling coordination post node drain.\n\n---\n\n**Mitigation Suggestions**\n\n1.- **Node Scheduling**:\n\n* Remove blocking taints:\n\n ```\n\n cc taint nodes <node-name> key=value:NoSchedule-\n\n ```\n\n2.- **Confirm Node Pool Readiness**:\n\n* If node pool train is still running, validate using node pool logs and metrics.\n\n3.- **Temporary Resource Adjustment**:\n\n* Increase pod limits or assign tolerations:\n\n ```\n\n tolerance: [{ key: \"cosmicready\", operator: \"Exists\", effect: \"NoSchedule\" }]\n\n ```\n\n4.- **Contact COSMIC Teams**:\n\n* If the issue persists or no node pool train is running, escalate to [COSMIC Support](https://aka.ms/cosmic911).\n\n---\n\n**References**\n\n* [Code Blue Alert: Pod Provisioning TSG](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/troubleshooting/CodeBlueAlerts/CodeBlueAlertPodProvisioningTSG)\n\n* [Code Blue Alert: Minimum Requested Pod Availability TSG](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/troubleshooting/CodeBlueAlerts/CodeBlueAlertMinimumRequestedPodAvailabilityTSG)\n\n---\n\n**Similar GitHub Issues and ICMs**\n\n1.- [ICM# 632796908 - Pod Pending (NP Train Cause)](https://portal.microsofticm.com/imp/v5/incidents/details/632796908)\n\n* **Description**: Pods stuck due to NP train upgrades.\n\n* **Status**: Resolved with node pool train completion.\n\n2.- [ICM# 662082136 - DNS Breakage During Node Pool Train](https://portal.microsofticm.com/imp/v5/incidents/details/662082136)\n\n* **Description**: Node pool upgrades caused CoreDNS resolution failures.\n\n* **Resolution**: Dispersed CoreDNS pods to mitigate.\n\n* **Status**: Mitigated.\n\n3.- [GitHub# 10151 - Node Pool Upgrade Investigation](https://github.com/substrate-platform/COSMIC/issues/10151)\n\n* **Description**: Node pool upgrade influenced workloads.\n\n* **Resolution**: Identified operational differences during the upgrade process.\n\n* **Status**: Closed."
    },
    modelB: {
      id: 'b21',
      model: 'Model B',
      response: "To investigate whether the pending pod issue in your namespace is caused by a node pool train, you can follow a structured troubleshooting approach. Below are the steps and logs you should examine:\n\n---\n\n**Common Causes of Pending Pods**\n\nPending pods in COSMIC environments can occur due to various reasons, including:\n\n1.- **Node Pool Capacity Issues**: Insufficient CPU, memory, or other resources in the node pool.\n\n2.- **Node Affinity or Taints**: Mismatches between pod scheduling requirements (e.g., node affinity, tolerations) and node configurations.\n\n3.- **Node Pool Train Impact**: Node pool upgrades or train processes can temporarily disrupt pod scheduling.\n\n4.- **Preemption Failures**: No suitable preemption victims are available to free up resources for the pending pod.\n\n5.- **Misconfigurations**: Errors in pod or node pool configurations, such as incorrect resource requests or limits.\n\n---\n\n**Logs and Tools to Investigate**\n\n1.- **Check Pending Pods in the Namespace**:\n\n Use the `cc` CLI to identify pending pods in your namespace:\n\n ```bash\n\n cc get pods -A --field-selector=status.phase=Pending\n\n ```\n\n Once identified, describe the pod to gather more details:\n\n ```bash\n\n cc describe pod <pod-name> -n <namespace>\n\n ```\n\n Look for events such as \"Insufficient CPU\" or \"Untolerated taints\" in the pod description [Data: Entities (5363, 4066); Relationships (7305, 4392)].\n\n2.- **Node Pool Train Logs**:\n\n If you suspect the issue is related to a node pool train, check the logs for the node pool train process. Use the **COSMIC Operation Portal (COP)** or **Cosmic Event LA** to query logs for the affected node pool:\n\n* **COP Smart TSG**: Provides detailed error messages for node pool train issues.\n\n* **Cosmic Event LA**: Query logs for the node pool in the affected region. For example:\n\n ```kusto\n\n AzureDiagnostics\n\n | where Category == \"cluster-autoscaler\" and ResourceGroup contains \"<nodepool-resource-group>\"\n\n | where TimeGenerated >= ago(2h)\n\n | project TimeGenerated, log_s\n\n ```\n\n These logs can help identify if the node pool train caused resource constraints or disruptions [Data: Reports (19); Sources (3257)].\n\n3.- **Scheduler Logs**:\n\n The Kubernetes scheduler plays a critical role in assigning pods to nodes. Check the logs of the `cosmic-scheduler` to identify preemption events or scheduling failures:\n\n ```bash\n\n cc logs <scheduler-pod-name> -n kube-system | sls \"preemptor\"\n\n ```\n\n This can help determine if the scheduler attempted to preempt resources for the pending pod but failed [Data: Sources (2727)].\n\n4.- **Cluster Autoscaler Logs**:\n\n If the node pool autoscaler is enabled, verify whether it attempted to scale up the node pool to accommodate the pending pod. Use the following Kusto query:\n\n ```kusto\n\n AzureDiagnostics\n\n | where Category == \"cluster-autoscaler\"\n\n | where TimeGenerated >= ago(2h)\n\n | project TimeGenerated, log_s\n\n ```\n\n Look for messages indicating scaling failures or delays [Data: Sources (2433)].\n\n5.- **Node Pool State**:\n\n Use the `cc` CLI to check the state of the node pool:\n\n ```bash\n\n cc get nodes\n\n ```\n\n Look for nodes that are cordoned, unschedulable, or in a degraded state. If nodes are cordoned due to a node pool train, this could explain the pending pods [Data: Entities (7551, 3181); Relationships (13034, 5751)].\n\n---\n\n**Steps to Mitigate**\n\n1.- **Node Pool Train Issues**:\n\n* If the node pool train is causing the issue, check the progress of the train and ensure that unhealthy pods are not blocking the upgrade. You may need to edit PodDisruptionBudget (PDB) configurations, drain old nodes, and revert PDB edits after the train completes [Data: Entities (3270); Relationships (5913, 6234)].\n\n2.- **Resource Constraints**:\n\n* If the issue is due to insufficient resources, consider scaling the node pool or adjusting pod resource requests and limits.\n\n3.- **Transient Issues**:\n\n* For transient or node-specific problems, manually delete the problematic pod to allow it to reschedule:\n\n ```bash\n\n cc delete pod <pod-name> -n <namespace>\n\n ```\n\n4.- **Namespace Owner Coordination**:\n\n* If the issue involves partner deployments, PDBs, or quotas, contact the namespace owner via the Namespace Owner Dashboard for further coordination [Data: Entities (7555); Relationships (13037)].\n\n---\n\n**References**\n\n* [JIT Elevation](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/tools/cosmic-cli/securely-access-app-jit)\n\n* [COSMIC CLI (cc)](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/tools/cosmic-cli/access-clusters-with-cc)\n\n* [COSMIC Operation Portal (COP)](https://aka.ms/cop)\n\nBy following these steps and analyzing the relevant logs, you should be able to determine whether the pending pod issue is related to a node pool train or another root cause.\n\n**Date:** 2025-09-16"
    }
  },
  {
    id: 'q22',
    query: "How do I onboard my service to COSMIC?",
    modelA: {
      id: 'a22',
      model: 'Model A',
      response: "To onboard your service to COSMIC:\n\n1.- **Create a New Workload Request**:\n\n* If your workload is not listed in the [COSMIC workload mapping](https://aka.ms/cosmic/workload), submit a new workload request.\n\n* The COSMIC Core team will review and approve your request if valid.\n\n2.- **Post-Approval Steps**:\n\n* Once approved, the workload will be visible in the COSMIC UI.\n\n* Collaborate with your workload owner to manage resources like namespaces and capacity.\n\n3.- **Namespace and Partition Provisioning**:\n\n* Use the COSMIC UI to:\n\n* * Select your workload, service group, and namespace.\n\n* * Create partitions as required.\n\n* * Submit a pull request for approval by the `COSMIC-topologies` team.\n\n4.- **Greenfield Services**:\n\n* Start creating your service alongside onboarding using tools like [M365 DevXpress](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/onboarding/prepare-and-test-deployment/devxpress-cosmic-extension), which provides a deployment-ready service template.\n\nAdditional details and support links can be found in the [COSMIC Onboarding Guide](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/onboarding/onboarding-guide)."
    },
    modelB: {
      id: 'b22',
      model: 'Model B',
      response: "Onboarding a service to COSMIC involves a structured process that ensures your service is properly configured, compliant, and ready for deployment within the COSMIC environment. The onboarding process is facilitated through the **COSMIC Onboarding Portal (COSOP)**, which provides a browser-based, end-to-end experience. Below is a detailed guide to help you onboard your service:\n\n---\n\n**1. Overview of the Onboarding Process**\n\nThe COSMIC onboarding process is divided into several phases, each addressing specific aspects of service configuration and deployment readiness. These phases include:\n\n* **Build**: Create the COSMIC service with a service name, runtime model, and App ID.\n\n* **Set Up Your Environment**: Configure foundational elements like the Service Tree ID, Incident Management (IcM) team, Torus Team, and code repository.\n\n* **Namespace Onboarding**: Define workloads, request capacity, and configure deployment rings.\n\n* **Configure Your Service**: Define data access policies and ensure compliance with security requirements.\n\n* **Reviews and Approvals**: Obtain necessary reviews and approvals for security, compliance, and operational readiness [Data: Entities (5060, 5062, 5063); Reports (2667)].\n\n---\n\n**2. Step-by-Step Guide**\n\n**Step 1: Build Your Service**\n\n1.- Access the COSMIC Onboarding Portal (COSOP) at [COSOP Build Dashboard](https://substrate.microsoft.net/v2/build).\n\n2.- Select **Start Building** and choose **COSMIC Service** as the type of service to create.\n\n3.- Provide a name for your service project. This name is used for organizational purposes in COSOP but is not propagated to the COSMIC backend.\n\n4.- Save the service details to proceed to the next phase [Data: Reports (2667)].\n\n**Step 2: Set Up Your Environment**\n\n1.- Configure the **Service Tree ID** and associate it with your COSMIC service. If you dont have a Service Tree ID, create one using the Service Tree ID Portal.\n\n2.- Set up the **Incident Management (IcM) Team** for your service to handle operational incidents.\n\n3.- Configure the **Torus Team** associated with your service. Ensure the Torus Team name is consistent across all configurations to avoid deployment errors like `TorusTeamUnauthorized` [Data: Entities (5060); Reports (1260)].\n\n4.- Select or request a compliant **Code Repository** for your service. If your existing repository is non-compliant, follow the troubleshooting guidance provided in COSOP [Data: Reports (2667)].\n\n**Step 3: Namespace Onboarding**\n\n1.- Define your **COSMIC Workload** and ensure it aligns with supported workloads (e.g., Substrate, Office Product Group).\n\n2.- Request **Capacity Allocation** for your namespace. This step ensures sufficient resources are available for your service. Capacity validation checks for compute, storage, and network resources [Data: Relationships (9352, 9373)].\n\n3.- Configure deployment **Rings** (e.g., Test, SDF, MSIT, Prod) to manage the lifecycle of your service across environments [Data: Reports (2667)].\n\n**Step 4: Configure Your Service**\n\n1.- Define **Data Access Policies** to ensure compliance with security and regulatory requirements.\n\n2.- Use the COSOP dashboard to review and finalize your service configuration [Data: Entities (5062)].\n\n**Step 5: Reviews and Approvals**\n\n1.- Submit your service for **Security and Compliance Reviews**. This step ensures your service meets all regulatory and organizational standards.\n\n2.- Obtain final approvals to complete the onboarding process [Data: Entities (5063)].\n\n---\n\n**3. Key Considerations**\n\n* **Namespace Configuration**: Each namespace must have a unique name and consistent Service Tree ID. Services within a namespace can have different pod specifications but must share the same Torus Team name [Data: Reports (2726)].\n\n* **Capacity Validation**: Ensure that sufficient resources are available for your service. If capacity validation fails, you may need to free up resources or request additional capacity [Data: Relationships (9352)].\n\n* **Non-Modifiable Components**: Certain components, such as namespace names and compliance classifications, cannot be modified after onboarding. Plan these configurations carefully to avoid the need for offboarding and re-onboarding [Data: Reports (2726)].\n\n---\n\n**4. Troubleshooting Common Issues**\n\n* **TorusTeamUnauthorized Error**: This error occurs when the Torus Team name in the onboarding configuration does not match the subscription mapping. Ensure consistency across all configurations [Data: Reports (1260)].\n\n* **Capacity Validation Failures**: Use commands like `cosmicctl capacity check` to diagnose resource availability issues. Free up resources or scale up infrastructure as needed [Data: Relationships (9352)].\n\n---\n\n**5. Additional Resources**\n\n* **COSMIC Onboarding Portal (COSOP)**: [COSOP Documentation](https://substrate.microsoft.net/v2/build)\n\n* **COSMIC 911**: For non-modifiable component changes, submit a request via [COSMIC 911](https://aka.ms/cosmic911).\n\n* **Capacity Allocation Guidance**: [COSMIC Capacity Allocation](https://aka.ms/COSMIC-CapacityAllocation)\n\nBy following these steps and leveraging the available resources, you can successfully onboard your service to COSMIC. If you encounter any issues, reach out to the COSMIC Onboarding Crew or consult the COSMIC documentation for further assistance.\n\n**Date:** 2025-09-16"
    }
  },
  {
    id: 'q23',
    query: "How would you mitigate this issue: errors like: Cosmic ACR doesn\'t have to access partner ACR, in both gcch &dod\n\n \n\nCosmic ACR doesn\'t have to access partner ACR. Please grant permission of your ACR to AAD app service principle: \'78eb5dad-67dd-404c-bf3e-7ae1191c94e3\'. HTTP statusCode: \'400\', Response content: \'Operation registries-4751536b-93eb-4287-a63b-ad7d40988a62 failed. Resource /subscriptions/464272ca-1d25-4268-a79d-59fc5e91dc71/resourceGroups/gcch-acr-rg/providers/Microsoft.ContainerRegistry/registries/cosmicgcchacr Failed to get manifest of ess1eshpcosmic.azurecr.io/metadataprocessor-ws22@sha256:817b9be033ff340274b435adc41e5d3eab8a5dfd95a8a91891565d6478c3ba9f: Remote registry returned 401 unauthorized, Unauthorized Unauthorized {\"errors\":[{\"code\":\"UNAUTHORIZED\",\"message\":\"authentication required, visit https://aka.ms/acr/authorization for more information.\",\"detail\":[{\"Type\":\"repository\",\"Name\":\"metadataprocessor-ws22\",\"Action\":\"pull\"}]}]}",
    modelA: {
      id: 'a23',
      model: 'Model A',
      response: "The issue you are encountering occurs because the **COSMIC ACR doesn\'t have the required access to your partner ACR**, leading to an unauthorized error (`401 Unauthorized`). Here is how you can resolve it:\n\n**Mitigation Steps**\n\n1.- **Grant Permissions to the AAD Service Principal**:\n\n* Assign `Reader` or `AcrPull` permissions to the AAD service principal: `78eb5dad-67dd-404c-bf3e-7ae1191c94e3`.\n\n* Execute these steps in the Azure CLI:\n\n ```\n\n az acr update --name <YourACRName> --admin-enabled true\n\n az role assignment create --assignee 78eb5dad-67dd-404c-bf3e-7ae1191c94e3\\n\n --scope /subscriptions/<subscription-id>/resourceGroups/<resource-group-name>/providers/Microsoft.ContainerRegistry/registries/<YourACRName>\\n\n --role AcrPull\n\n ```\n\n2.- **Verify the Permissions**:\n\n* Verify if the service principal has been successfully assigned the role:\n\n ```\n\n az role assignment list --assignee 78eb5dad-67dd-404c-bf3e-7ae1191c94e3\\n\n --scope /subscriptions/<subscription-id>/resourceGroups/<resource-group-name>/providers/Microsoft.ContainerRegistry/registries/<YourACRName>\n\n ```\n\n3.- **Authorize the ACR**:\n\n* Authenticate against your ACR for image access and pulls:\n\n ```\n\n az acr login --name <YourACRName>\n\n ```\n\n4.- **Retry the Deployment**:\n\n* After granting the permissions and verifying them, retry your deployment to ensure it proceeds without authorization issues.\n\n---\n\n**Common Causes**\n\n* **Missing `AcrPull` Permissions**: The COSMIC-managed AAD service principal is not granted the required access (e.g., `Reader` or `AcrPull`) on the partner ACR.\n\n* **Misconfigured Role Assignments**: The service principal is incorrectly assigned or scoped.\n\n---\n\n**References**\n\n* [Application Deployment: ACR Storage Usage & Troubleshooting](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/troubleshooting/application-deployment/ACR-Storage-Usage-Troubleshooting)\n\nFor further help, visit [COSMIC Support](https://aka.ms/cosmic911)."
    },
    modelB: {
      id: 'b23',
      model: 'Model B',
      response: "To mitigate the issue where the COSMIC Azure Container Registry (ACR) does not have access to a partner\'s ACR, resulting in errors such as \"Remote registry returned 401 unauthorized,\" follow the steps below. These steps are tailored for environments like GCCH (Government Community Cloud High) and DOD (Department of Defense) where additional security and compliance requirements may apply.\n\n---\n\n**Common Causes**\n\n1.- **Missing Permissions**: The COSMIC service principal does not have the required `ACR Pull` role assigned to access the partner\'s ACR.\n\n2.- **Cross-Tenant Configuration**: The COSMIC service principal and the partner\'s ACR may belong to different Azure Active Directory (AAD) tenants, requiring explicit cross-tenant permissions.\n\n3.- **Authentication Issues**: Expired or misconfigured authentication tokens can prevent access to the partner\'s ACR.\n\n4.- **Incorrect Image References**: The image name, tag, or digest specified in the deployment pipeline may be incorrect.\n\n---\n\n**Steps to Investigate**\n\n1.- **Verify the Error Details**:\n\n* Confirm the error message and HTTP status code (`401 Unauthorized`) in the logs.\n\n* Identify the COSMIC service principal\'s object ID (`78eb5dad-67dd-404c-bf3e-7ae1191c94e3` in this case) and the partner\'s ACR details (e.g., `ess1eshpcosmic.azurecr.io`).\n\n2.- **Check Current Permissions**:\n\n* Use the Azure CLI to list the role assignments for the partner\'s ACR:\n\n ```bash\n\n az role assignment list --scope /subscriptions/<Subscription_ID>/resourceGroups/<Resource_Group>/providers/Microsoft.ContainerRegistry/registries/<ACR_Name> --assignee <COSMIC_Service_Principal_Object_ID> -o table\n\n ```\n\n* Replace placeholders with the appropriate subscription ID, resource group, ACR name, and service principal object ID.\n\n3.- **Validate Image Availability**:\n\n* Ensure the specified image (`metadataprocessor-ws22@sha256:817b9be033ff340274b435adc41e5d3eab8a5dfd95a8a91891565d6478c3ba9f`) exists in the partner\'s ACR:\n\n ```bash\n\n az acr repository show-manifests --name <ACR_Name> --repository <Repository_Name>\n\n ```\n\n4.- **Cross-Tenant Considerations**:\n\n* If the COSMIC service principal belongs to a different AAD tenant, confirm that the partner\'s ACR allows access from external tenants.\n\n---\n\n**Mitigation Steps**\n\n1.- **Grant the `ACR Pull` Role to the COSMIC Service Principal**:\n\n* Assign the `ACR Pull` role to the COSMIC service principal for the partner\'s ACR:\n\n ```bash\n\n az role assignment create --assignee 78eb5dad-67dd-404c-bf3e-7ae1191c94e3 --role \"AcrPull\" --scope /subscriptions/<Subscription_ID>/resourceGroups/<Resource_Group>/providers/Microsoft.ContainerRegistry/registries/<ACR_Name>\n\n ```\n\n* Replace placeholders with the appropriate values.\n\n2.- **Verify Role Assignment**:\n\n* Confirm that the role assignment has propagated successfully:\n\n ```bash\n\n az role assignment list --assignee 78eb5dad-67dd-404c-bf3e-7ae1191c94e3 --scope /subscriptions/<Subscription_ID>/resourceGroups/<Resource_Group>/providers/Microsoft.ContainerRegistry/registries/<ACR_Name> -o table\n\n ```\n\n3.- **Update Deployment Pipeline**:\n\n* Ensure the deployment pipeline references the correct image name, tag, or digest. Avoid using variables for the ACR name in pipeline templates, as this can cause issues.\n\n4.- **Test the Deployment**:\n\n* Retry the deployment pipeline to verify that the issue is resolved.\n\n5.- **Escalate if Necessary**:\n\n* If the issue persists, escalate to the COSMIC Incident and Change Management (ICM) channel with the following details:\n\n* * Error code and message.\n\n* * COSMIC service principal object ID.\n\n* * Partner ACR details (name, subscription ID, resource group).\n\n---\n\n**Additional Considerations for GCCH and DOD**\n\n* **Compliance Requirements**: Ensure that all role assignments and configurations adhere to GCCH and DOD compliance standards.\n\n* **Network Configuration**: Verify that network policies and firewalls allow access between the COSMIC environment and the partner\'s ACR.\n\n* **Authentication Tokens**: Regularly refresh authentication tokens to prevent expiration-related issues.\n\n---\n\n**References**\n\n* [Azure Container Registry Authentication](https://aka.ms/acr/authorization)\n\n* [COSMIC ICM Channel](http://aka.ms/cosmic911)\n\nBy following these steps, you can resolve the issue and ensure that the COSMIC ACR has the necessary access to the partner\'s ACR for seamless deployment operations.\n\n**Date:** 2025-09-16"
    }
  },
  {
    id: 'q24',
    query: "What is TEF?",
    modelA: {
      id: 'a24',
      model: 'Model A',
      response: "**TEF (Task Execution Framework)** in COSMIC is a mechanism used to securely execute operational commands across the COSMIC infrastructure. It ensures proper authorization, compliance, and logging while managing tasks like scaling operations.\n\nExamples of TEF tasks include creating, updating, or deleting instant scale-up requests for namespace instances. These tasks are controlled and auditable, requiring specific privileges and lockbox approvals for execution. For details on specific commands, you can refer to the [Instant Scale Up and Instant Scale Down](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/concepts/fleet-provisioning-scaling/instant-scaleup-scaledown) documentation."
    },
    modelB: {
      id: 'b24',
      model: 'Model B',
      response: "**Overview of TEF (Task Execution Framework)**\n\nThe **Task Execution Framework (TEF)** is a critical component of the COSMIC platform, designed to manage, execute, and monitor tasks across various environments and operational rings. It plays a pivotal role in automating and streamlining management operations within COSMIC, ensuring consistency, reliability, and scalability in task execution. TEF is used by internal engineers, COSMIC partners, and external services to perform a wide range of operations, such as rolling out Kubernetes versions, automating patching and upgrades, and managing rogue pods [Data: Entities (4473, 5277)].\n\n---\n\n**Key Features and Capabilities**\n\n1.- **Task Scheduling and Execution**:\n\n* TEF supports both ad-hoc and scheduled tasks, allowing flexibility in task execution.\n\n* Tasks are executed in specific rings and environments, adhering to deployment strategies. For example, tasks like the **EmergencyBootstrapTask** can be used for rapid ad-hoc recovery operations [Data: Entities (4473); Sources (3221)].\n\n2.- **Logging and Monitoring**:\n\n* TEF integrates with **LogAnalytics** for centralized logging and monitoring of task execution.\n\n* Deployment progress and task execution metrics can be visualized through the **TEF Grafana Dashboard**, providing operational transparency [Data: Entities (4473, 5277)].\n\n3.- **Communication and Automation**:\n\n* TEF acts as a communication bridge between key COSMIC components, such as **RescueBox** and **CORA**, enabling seamless automation workflows. It routes requests from RescueBox to the CORA agent in the target cluster for execution [Data: Entities (4473)].\n\n4.- **Tenant Isolation**:\n\n* TEF supports tenant-specific configurations, ensuring proper isolation between tenants. This is particularly important for managing tenant services and maintaining independence across different environments [Data: Entities (5277)].\n\n5.- **Task Execution Mechanisms**:\n\n* TEF uses components like the **Distributed Management Service (DMS)** and the Scheduler Service to execute tasks. Tasks are identified and tracked using unique task IDs, which can be queried for status and logs [Data: Entities (5277)].\n\n---\n\n**Known Issues and Troubleshooting**\n\nTEF is a robust framework, but certain issues can arise during its operation:\n\n* **Task Execution Failures**: These can occur due to misconfigured task parameters or errors in the `schedule.yaml` file. Logs in LogAnalytics can help diagnose such issues [Data: Entities (4473)].\n\n* **Communication Failures**: Network connectivity issues between RescueBox and the target cluster can disrupt task execution. TEF logs should be inspected for routing errors [Data: Entities (4473)].\n\n* **Monitoring Discrepancies**: Delayed or missing metrics in the TEF Grafana Dashboard may result from misconfigured data sources or logging issues [Data: Entities (4473)].\n\nTroubleshooting tools include commands like `gwrc` (to retrieve workflow runtime context) and `gwt` (to query workflow tree status). Logs can also be queried in LogAnalytics using task-specific filters [Data: Entities (4473); Sources (2517)].\n\n---\n\n**Integration with Other COSMIC Components**\n\nTEF is deeply integrated with other COSMIC components:\n\n* **Scheduler Service**: Defines task execution parameters using `schedule.yaml` files.\n\n* **RescueBox and CORA**: Facilitates communication and automation workflows.\n\n* **LogAnalytics and Grafana**: Provides centralized logging and monitoring capabilities.\n\n* **Tenant Services**: Ensures proper onboarding and isolation for tenant-specific operations [Data: Entities (4473, 5277)].\n\n---\n\n**Importance in COSMIC Operations**\n\nTEF is essential for maintaining the operational efficiency of COSMIC clusters. By automating repetitive tasks, providing robust monitoring, and ensuring tenant isolation, TEF enables COSMIC partners and engineers to focus on higher-value activities. Its ability to handle both routine and emergency tasks makes it a cornerstone of COSMIC\'s management plane [Data: Entities (4473, 5277)].\n\nFor more details on TEF\'s capabilities and usage, you can refer to the [COSMIC CLI documentation](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/tools/cosmic-cli/access-clusters-with-cc) or explore the [COSMIC Operation Portal (COP)](https://aka.ms/cop).\n\n**Date:** 2025-09-16"
    }
  },
  {
    id: 'q25',
    query: "how to trouble shoot cluster provisioning status",
    modelA: {
      id: 'a25',
      model: 'Model A',
      response: "To troubleshoot **cluster provisioning status**, follow these steps:\n\n**Steps to Investigate and Diagnose**\n\n1.- **Verify Node Compatibility**:\n\n* Check whether the appropriate operating system (Windows/Linux) is available for pods to be scheduled.\n\n* Use the `app-resources.json` file and verify node compatibility (e.g., selectors, taints).\n\n2.- **Access Cluster and Namespace**:\n\n* Use the `cc` CLI to set the target cluster and namespace:\n\n ```\n\n cc set <ring> <silo> <instance> <location> -n <namespace>\n\n ```\n\n3.- **Check Pod Node Selector Configuration**:\n\n* Ensure pod specifications have correct node selector configurations:\n\n ```\n\n cc describe pod <pod-name>\n\n ```\n\n4.- **Inspect Node Availability**:\n\n* List available nodes and check their status:\n\n ```\n\n cc get nodes\n\n ```\n\n5.- **Log Analytics Query**:\n\n* Use Log Analytics to identify node taints or resource exhaustion preventing scheduling:\n\n ```\n\n KubeEvents\n\n | where TimeGenerated between (<start-time>..<end-time>)\n\n | and Namespace == \"<your-namespace>\"\n\n ```\n\n6.- **Raise an ICM**:\n\n* If the cluster has no required nodes or issues go beyond direct control, escalate to COSMIC teams via an ICM ticket: [Create ICM](https://portal.microsofticm.com/imp/v3/incidents/create?tmpl=K3I1d1).\n\n**Common Causes**\n\n* Insufficient nodes in the cluster.\n\n* Node taints or resource exhaustion.\n\n* Incorrect node selectors in the pod specification.\n\n* Issues with cluster topology during provisioning.\n\n**Mitigation Suggestions**\n\n* Confirm nodes are correctly configured and available.\n\n* Adjust pod specs (e.g., node selectors, tolerations).\n\n* Remove or update taints on nodes causing issues:\n\n ```\n\n cc taint nodes <node-name> <key>:<value>-\n\n ```\n\n* Collaborate with the COSMIC topology team if required.\n\n---\n\n**References**\n\n* [Code Blue Alert Pod Provisioning TSG](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/troubleshooting/CodeBlueAlerts/CodeBlueAlertPodProvisioningTSG)\n\n* [Troubleshooting for COSMIC CLI](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/tools/cosmic-cli/troubleshoot-guide)\n\nFor further support, you can visit [COSMIC Support](https://aka.ms/cosmic911)."
    },
    modelB: {
      id: 'b25',
      model: 'Model B',
      response: "**Troubleshooting Cluster Provisioning Status in COSMIC**\n\nCluster provisioning issues in COSMIC can arise due to various factors, including capacity constraints, configuration errors, or dependency failures. Below is a structured approach to troubleshooting cluster provisioning status, grounded in COSMIC documentation and best practices.\n\n---\n\n**Common Causes of Cluster Provisioning Issues**\n\n1.- **Capacity Validation Failures**: Insufficient vCores or other resources in the target region can prevent successful provisioning. This is often observed in regions with high demand or limited quotas [Data: Reports (5); Entities (1269)].\n\n2.- **Configuration Errors**: Issues such as invalid flighting configurations, outdated templates, or metadata mismatches can disrupt the provisioning process [Data: Entities (5500); Reports (5)].\n\n3.- **Dependency Failures**: Problems with network security group (NSG) readiness, platform agent identity setup, or firewall template creation can block provisioning [Data: Entities (5504, 5503, 3298)].\n\n4.- **Subscription Issues**: Errors during subscription allocation or readiness can delay provisioning, as seen in cases like MSIT cluster provisioning [Data: Entities (1445); Relationships (2437, 2438, 2439)].\n\n5.- **Transient Errors**: Temporary issues such as API timeouts or resource unavailability can cause provisioning to fail intermittently [Data: Entities (5500)].\n\n---\n\n**Steps to Investigate Cluster Provisioning Status**\n\n1.- **Check Provisioning Status on Dashboards**\n\n* Use the **Partner NS Provisioning Status Dashboard** or the **Cluster Provisioning Dashboard** to monitor the status of clusters. Look for fields such as `status_isProvisioned` and `UpdateReason` to identify the current state and any error messages [Data: Entities (1108); Sources (2768)].\n\n* If the Lens Explorer dashboard is deprecated, run CIDW queries to retrieve detailed provisioning logs. Example query:\n\n ```kql\n\n cluster_cluster\n\n | where status_isProvisioned == 'false'\n\n | project Cluster, UpdateReason, UpdateMessage\n\n ```\n\n [Data: Sources (2768)].\n\n2.- **Validate Capacity**\n\n* Run the `cosmic-capacity-cli` command to check resource availability in the target region:\n\n ```shell\n\n cosmic-capacity-cli check --region <region> --sku <sku>\n\n ```\n\n* If capacity is insufficient, escalate to the Cosmic Capacity team with details such as cluster ID, region, and SKU [Data: Entities (5500); Sources (2768)].\n\n3.- **Inspect Configuration Files**\n\n* Review flighting configuration files for errors:\n\n ```shell\n\n cat /etc/cosmic/flighting/config.yaml\n\n ```\n\n* Ensure all required fields are populated and valid. Restart the flighting service to apply changes:\n\n ```shell\n\n systemctl restart cosmic-flighting\n\n ```\n\n [Data: Entities (5500)].\n\n4.- **Verify Management Plane Integration**\n\n* Check cluster registration status using the Management Plane API:\n\n ```shell\n\n GET /api/v1/clusters/<cluster_id>/status\n\n ```\n\n* If the cluster is unregistered, attempt re-registration:\n\n ```shell\n\n POST /api/v1/clusters/<cluster_id>/register\n\n ```\n\n [Data: Entities (5500)].\n\n5.- **Investigate Dependency Failures**\n\n* For NSG readiness issues, create an ICM ticket to the Cosmic Networking team [Data: Entities (5504)].\n\n* For platform agent identity delays, escalate to the Cosmic Identity team [Data: Entities (5503)].\n\n* For firewall template errors, update the SDP orchestration workflow to ensure templates are created [Data: Entities (3298)].\n\n6.- **Review Logs**\n\n* Check provisioning logs for error codes or patterns:\n\n ```shell\n\n tail -f /var/log/cosmic/provisioning.log\n\n ```\n\n* Look for specific error messages such as `VMSizeNotSupported` or `ClusterProvisioningFailed` [Data: Sources (2768)].\n\n7.- **Retry Provisioning**\n\n* If the issue is transient, retry the provisioning process:\n\n ```shell\n\n cosmic-cli retry-provisioning --cluster-id <cluster_id>\n\n ```\n\n* The default retry interval is 5 minutes, with a maximum of 3 retries [Data: Entities (5500)].\n\n---\n\n### Mitigation Suggestions\n\n1.- **Capacity Adjustments**: Work with the Cosmic Capacity team to increase resource allocations in the target region.\n\n2.- **Configuration Updates**: Ensure flighting configurations and templates are up-to-date and validated before provisioning.\n\n3.- **Dependency Resolution**: Address NSG, platform agent identity, and firewall template issues promptly by engaging the relevant teams.\n\n4.- **Monitoring and Alerts**: Set up Code Blue Alerts to detect provisioning delays and escalate issues automatically [Data: Sources (2608)].\n\n---\n\n### References\n\n* [Cluster Provisioning Troubleshooting Guide](https://aka.ms/cosmic/cluster)\n\n* [COSMIC CLI Documentation](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/tools/cosmic-cli/access-clusters-with-cc)\n\n* [COSMIC Operation Portal (COP)](https://aka.ms/cop)\n\n* [JIT Elevation Documentation](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/tools/cosmic-cli/securely-access-app-jit)\n\nBy following these steps, partners can systematically diagnose and resolve cluster provisioning issues, ensuring smooth operations within the COSMIC environment.\n\n**Date:** 2025-09-16"
    }
  },
  {
    id: 'q26',
    query: "what is the Application ID for Cosmic App Deployment extension for Tenant 72f988bf-86f1-41af-91ab-2d7cd011db47",
    modelA: {
      id: 'a26',
      model: 'Model A',
      response: "The **Application ID** for the **COSMIC App Deployment extension** in the **Corp tenant (72f988bf-86f1-41af-91ab-2d7cd011db47)** is **75bde40a-8baa-4c1c-a1e8-8efdb16b210a**.\n\nFor further details or assistance, check the [App Deployment General Troubleshooting](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/troubleshooting/application-deployment/App-Deployment-General-Troubleshooting)."
    },
    modelB: {
      id: 'b26',
      model: 'Model B',
      response: "The Application ID for the **COSMIC App Deployment Extension** in the tenant `72f988bf-86f1-41af-91ab-2d7cd011db47` (Microsoft Tenant) is not explicitly mentioned in the provided data. The available information includes details about the extension\'s functionality, its role in the COSMIC infrastructure, and its integration with other components, but the specific Application ID for this tenant is not listed.\n\nIf you need to retrieve the Application ID, you can use the Azure CLI or Azure Portal to query the registered applications in the tenant. For example:\n\n```bash\n\naz ad app list --filter \"displayName eq \'COSMIC App Deployment Extension\'\"\n\n```\n\nAlternatively, you can check the **COSMIC Operation Portal (COP)** or consult the relevant documentation for further details.\n\nIf you have additional context or specific identifiers, I can help refine the search. Let me know!\n\n**Date:** 2025-09-16"
    }
  },
  {
    id: 'q27',
    query: "Is there any documentations on PDB?",
    modelA: {
      id: 'a27',
      model: 'Model A',
      response: "**Documentation on Pod Disruption Budget (PDB)**\n\nThere are multiple documents available on PDB in the COSMIC platform:\n\n1.- **Pod Disruption Budget Warnings in Build Validations**:\n\n* Discusses common PDB warnings in app configurations and how to mitigate them.\n\n* Link: [Cosmic Build Warnings TSG](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/troubleshooting/general/Warning-TSG)\n\n2.- **PDB Violation Troubleshooting**:\n\n* Covers how to resolve violations related to PDB configurations in COSMIC, including compliance steps and manual cleanup processes.\n\n* Link: [\[QEI-PR3.6.2\] MICROSOFT.O365.Cosmic.PDBViolation TSG](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/troubleshooting/QEI/%5BQEI-PR3.6.2%5DMICROSOFT.O365.Cosmic)\n\n3.- **PDB Metrics and Availability Monitoring**:\n\n* Explains the concept of PDB availability, its metrics, and how to improve resilience through proper configuration.\n\n* Link: [PDB Availability Metric Description](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/tools/grafana/metrics/PdbAvailabilityMetricDescription)\n\nEach document provides valuable insights into configuring and managing PDBs effectively for high-availability environments."
    },
    modelB: {
      id: 'b27',
      model: 'Model B',
      response: "Yes, there is extensive documentation on Pod Disruption Budgets (PDBs) in the COSMIC environment. Below is a summary of the key points and resources available:\n\n---\n\n**Overview of Pod Disruption Budgets (PDBs)**\n\nPod Disruption Budgets (PDBs) are Kubernetes policies designed to maintain application availability during voluntary disruptions, such as upgrades, maintenance, or scaling activities. They ensure that a minimum number of pods remain available or limit the maximum number of pods that can be disrupted at any given time. PDBs are critical for maintaining service continuity and high availability in COSMIC-managed clusters [Data: Entities (1506, 257)].\n\n---\n\n**Key Configuration Parameters**\n\nPDBs are configured using the following parameters:\n\n* **`minAvailable`**: Specifies the minimum number of pods that must remain available during disruptions.\n\n* **`maxUnavailable`**: Defines the maximum number of pods that can be unavailable during maintenance operations.\n\nThese configurations are essential for ensuring operational stability and resilience. For example, overly restrictive PDB settings can block pod evictions, leading to upgrade failures and operational hindrances [Data: Entities (1506); Sources (2809)].\n\n---\n\n**Common Issues and Fixes**\n\nSeveral common issues related to PDBs have been identified in COSMIC environments, along with recommended fixes:\n\n1.- **Missing PDB**: Workloads without a PDB may experience service availability dips during node pool upgrades. The solution is to create a PDB for the workload.\n\n2.- **Improper `minAvailable` Configuration**: Using `minAvailable` instead of `maxUnavailable` can lead to overly restrictive settings. Switching to `maxUnavailable` is recommended.\n\n3.- **Single or Zero Replica Workloads**: Workloads with only one or zero replicas are prone to disruptions. Configuring replicas to be greater than one or adding Horizontal Pod Autoscaler (HPA) with `minReplicas > 1` is advised.\n\n4.- **Orphaned PDBs**: PDBs not associated with any workload should be cleaned up to avoid accidental matches [Data: Sources (2809)].\n\n---\n\n**Troubleshooting and Monitoring**\n\nCOSMIC provides several tools and guides for troubleshooting PDB-related issues:\n\n* **Troubleshooting Guides (TSGs)**: These include the \"PDB Violation Alert TSG\" and \"PDB Budget Violated Alert TSG,\" which provide steps for investigating and resolving PDB violations. These guides emphasize checking pod states, accessing cluster and namespace information, and creating incidents for partner services if necessary [Data: Entities (9890, 9892); Relationships (17796, 17807)].\n\n* **Commands**: Use `cc describe pdb -n <namespace>` to view PDB details and `cc get pods -n <namespace>` to check pod states. These commands help diagnose issues such as PDB violations or unready pods [Data: Sources (4016)].\n\n* **Grafana Dashboard**: A live view of PDB compliance is available via the Grafana dashboard, which provides insights into PDB status by cluster and namespace [Data: Relationships (17800, 17805)].\n\n---\n\n**Best Practices**\n\n1.- Use `maxUnavailable` in percentage format (e.g., `20%`) for flexibility and to avoid overly restrictive configurations.\n\n2.- Ensure workloads have at least two replicas or configure HPA with `minReplicas > 1` to allow for disruptions during maintenance.\n\n3.- Regularly review and adjust PDB settings to align with application scaling and maintenance needs.\n\n4.- Implement PodTopologySpread constraints to distribute pods evenly across nodes, minimizing the impact of single-node failures [Data: Sources (2809)].\n\n---\n\n**Known Issues and Alerts**\n\n* **PDB Violation Alerts**: These are triggered when PDBs are violated in multiple namespaces. They require immediate investigation to identify the root cause, such as crashing pods or node pool upgrades.\n\n* **PDB Down Alerts**: These indicate that the PDB is below 50% for an extended period, signaling potential service disruptions [Data: Entities (10249, 10253)].\n\n---\n\n**Additional Resources**\n\n* **COSMIC Documentation**: Detailed information on PDBs, including configuration examples and troubleshooting steps, is available in COSMIC\'s internal documentation.\n\n* **Kubernetes Documentation**: For general Kubernetes PDB concepts, refer to the [Kubernetes PDB Guide](https://kubernetes.io/docs/tasks/run-application/configure-pdb/).\n\n---\n\nIf you need further assistance with PDBs in COSMIC, you can use the COSMIC CLI (`cc`) commands or access the COSMIC Operation Portal (COP) for additional tools and insights.\n\n**References:**\n\n* [JIT elevation](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/tools/cosmic-cli/securely-access-app-jit)\n\n* [COSMIC CLI (cc)](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/tools/cosmic-cli/access-clusters-with-cc)\n\n* [COSMIC Operation Portal (COP)](https://aka.ms/cop)\n\n**Date:** 2025-09-16"
    }
  },
  {
    id: 'q28',
    query: "how to get a dump using debug cosmic cli",
    modelA: {
      id: 'a28',
      model: 'Model A',
      response: "**Steps to Get a Dump Using the COSMIC CLI**\n\n1.- **JIT Elevation**: Request JIT (Just-In-Time) elevation to obtain the required permissions:\n\n ```\n\n Request-CosmicNamespaceElevation -Ring <prod/msit/sdf/test> -Location <region> -Role GetDumpContributor -Namespace <namespace> -Reason \"Debugging\"\n\n ```\n\n Example:\n\n ```\n\n Request-CosmicNamespaceElevation -Ring msit -Location eastus -Role GetDumpContributor -Namespace \'example-namespace\' -Reason \"Debugging\"\n\n ```\n\n Ensure your LockBox request is approved before proceeding.\n\n2.- **Set Cluster Filter**: Configure the `cc` filter to target your namespace:\n\n ```\n\n cc set -n <namespace> -r <ring> -s <silo> -i <instance> -a <location>\n\n ```\n\n Example:\n\n ```\n\n cc set -n example-namespace -r msit -s d02 -i 05 -a eastus\n\n ```\n\n3.- **Trigger a Native Dump**: Use the `cc debug getdump` command:\n\n* By process name:\n\n ```\n\n cc debug getdump -p <pod-name> -c <container-name> --processName <process-name>\n\n ```\n\n* By process ID:\n\n ```\n\n cc debug getdump -p <pod-name> -c <container-name> --processID <process-ID>\n\n ```\n\n If you are unsure about the process details, use:\n\n ```\n\n cc debug getdump -p <pod-name> -c <container-name>\n\n ```\n\n This will list processes in the `Status` section of the command output.\n\n4.- **Describe Native Dump Status**: View the progress or result of the dump:\n\n ```\n\n cc describe linuxnativedump <resource-name>\n\n ```\n\n The `Status` section will provide the URL to the dump resource.\n\n5.- **Download the Dump**: Use the link in the `Status` field to access the Azure Portal\'s download option.\n\n6.- **Extract Application Binary (if needed)**: If analyzing the dump requires the application binary, copy it from the pod:\n\n ```\n\n cc cp <namespace>/<pod-name>:<path-in-pod> <local-destination>\n\n ```\n\n7.- **Analyze the Dump**: Use debugging tools such as GDB (for native apps) or Delve (for Go apps) to analyze the dump:\n\n* Example for GDB:\n\n ```\n\n gdb <application-binary> <dump-file>\n\n ```\n\n* Example for Delve:\n\n ```\n\n dlv core <application-binary> <dump-file>\n\n ```\n\n**References**\n\n* [Native Dump Linux](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/troubleshooting/debug-tools/Native-Dump-Linux)"
    },
    modelB: {
      id: 'b28',
      model: 'Model B',
      response: "To obtain a process dump using the COSMIC CLI (`cc`), you can follow the steps outlined below. The process involves setting up the appropriate context, ensuring you have the necessary permissions, and using the `cc debug getdump` command. This guide applies to both Linux and Windows environments in COSMIC.\n\n---\n\n**Prerequisites**\n\n1.- **COSMIC CLI Version**: Ensure you have the latest version of the COSMIC CLI installed. You can update it using:\n\n ```bash\n\n cc update\n\n ```\n\n2.- **JIT Elevation**: You need to elevate your permissions to the appropriate role:\n\n* For **COSMIC partners**, request the `GetDumpContributor` role:\n\n ```powershell\n\n Request-CosmicNamespaceElevation -Ring <ring> -Location <location> -Role GetDumpContributor -Namespace <namespace> -Reason \"Debug\"\n\n ```\n\n* For **COSMIC OCEs**, request the `Contributor` role:\n\n ```powershell\n\n Request-CosmicClusterElevation -Ring <ring> -Location <location> -Role Contributor -Reason \"Debug\"\n\n ```\n\n Ensure the LockBox request is approved before proceeding [Data: Entities (11137, 5399, 349); Sources (2740)].\n\n3.- **Access Configuration**: If you are a partner, configure the `AzureWatsonNamespace` environment variable in your deployment or pod template to specify where the dump results will be saved. This ensures the results are accessible to you [Data: Sources (4476)].\n\n---\n\n**Steps to Trigger a Dump**\n\n**1.- Set the Context**\n\nBefore running the dump command, set the appropriate cluster context using the `cc set` command:\n\n```bash\n\ncc set -n <namespace> -r <ring> -s <stamp> -i <instance> -a <region>\n\n```\n\nFor example:\n\n```bash\n\ncc set -n cosmic-debug-agent -r test -s d05 -i 00 -a eastus\n\n```\n\nThis ensures that the CLI is targeting the correct cluster and namespace [Data: Sources (4476, 2740)].\n\n**2.- Trigger the Dump**\n\nUse the `cc debug getdump` command to capture the dump. The command can be used in different ways depending on whether you know the process name or ID:\n\n* **If you know the process name**:\n\n ```bash\n\n cc debug getdump --pod <pod-name> --processName <process-name> --hpc\n\n ```\n\n Example:\n\n ```bash\n\n cc debug getdump --pod cosmic-debug-agent-deployment-55f4d9f9bf-d7vlg --processName kube-proxy --hpc\n\n ```\n\n* **If you know the process ID**:\n\n ```bash\n\n cc debug getdump --pod <pod-name> --processID <process-id> --hpc\n\n ```\n\n* **If you do not know the process name or ID**:\n\n Run the command without specifying the process parameters. This will list all available processes in the output:\n\n ```bash\n\n cc debug getdump --pod <pod-name> --hpc\n\n ```\n\n After identifying the process, re-run the command with the process name or ID [Data: Entities (1883, 11135); Sources (4476, 2740)].\n\n**3.- View the Dump Operation Progress**\n\nOnce the dump operation is triggered, you can monitor its progress and retrieve the results by describing the `LinuxNativeDump` resource:\n\n```bash\n\ncc describe linuxnativedump <resource-name>\n\n```\n\nThe output will include a URL to the dump file stored in Azure Watson or another configured storage location [Data: Entities (5396); Sources (2740)].\n\n---\n\n**Accessing and Debugging the Dump**\n\n1.- **Download the Dump**: Use the URL provided in the `cc describe` output to download the dump file. Log in to the Azure Portal with your JIT account if required.\n\n2.- **Analyze the Dump**:\n\n* For .NET applications, use tools like Visual Studio or `dotnet-dump`.\n\n* For native applications (e.g., C++, Go), use tools like GDB or Delve [Data: Entities (7039, 4103); Sources (2740)].\n\n---\n\n**Known Issues and Workarounds**\n\n1.- **Gallatin Environment**: The `cc debug getdump` command is not functional in the Gallatin environment. As a workaround, you may need to manually collect dumps by accessing the cluster directly [Data: Entities (1883); Sources (1599)].\n\n2.- **Access Issues**: If you encounter access issues with Azure Watson, ensure your security group permissions are correctly configured. You may need to contact the Watson support team for assistance [Data: Entities (4118); Sources (4476)].\n\n---\n\n**Additional Notes**\n\n* The `cc debug getdump` command supports both Linux and Windows environments, but the specific steps and configurations may vary. Refer to the appropriate documentation for your environment.\n\n* For partners, ensure that your namespace is properly registered with Azure Watson to access the dump results [Data: Entities (4118); Sources (4476)].\n\nFor more details on JIT elevation and the COSMIC CLI, refer to the following resources:\n\n* [JIT Elevation Documentation](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/tools/cosmic-cli/securely-access-app-jit)\n\n* [COSMIC CLI Documentation](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/tools/cosmic-cli/access-clusters-with-cc)\n\n**Date:** 2025-09-16"
    }
  },
  {
    id: 'q29',
    query: "We have a repo but associated with 2 different service trees so we need to deploy to 2 different namespaces. In the previous pipeline, were able to share one build pipeline that generates artifacts under different paths (i.e.1p and 3p), that release pipeline can specify one of the folder to deploy from (release pipeline for 1p service, it specifies to deploy from \'drop_cosmicartifacts_cosmicartifactjob/package/IdeasPersselectionSmp/1p/\')\n\nWe started to migrate to the new M365GPT pipeline, those files were populated fine in the new build pipeline, however, in the release pipeline, it failed when try to find \'app-metadata.json\' file, while this file is under a different path \'deploymentpackage.zip/1p\' and the pipeline try to find it under \'deploymentpacakge.zip\'\n\nSo wondering if there\'s way to specify path for app-metadata.json file in release pipeline?",
    modelA: {
      id: 'a29',
      model: 'Model A',
      response: "To handle the path of `app-metadata.json` during the release pipeline setup in the **M365GPT pipeline**, follow the steps based on your described issue:\n\n**Steps to Resolve `app-metadata.json` Path Issue**\n\n1.- **Customize the Cosmic Deployment Task**:\n\n* In the release pipeline, ensure the **Cosmic deployment task** allows specifying a custom path for the `app-metadata.json` file.\n\n* Modify the `ev2.parameters.json` or equivalent in the deployment task YAML to specify the relative folder for the `app-metadata.json`.\n\n* Example:\n\n ```\n\n {\n\n \"Ev2ArtifactsServiceRootPath\": \"deploymentpackage.zip/1p\",\n\n \"PathToAppMetadata\": \"1p\"\n\n }\n\n ```\n\n2.- **Verify the Artifact Path in Deployment**:\n\n* Check that the deployment zip file structure (e.g., `deploymentpackage.zip/1p`) corresponds with the paths set in the pipeline.\n\n* Use ADO logs to verify the directory structure or data extraction issues.\n\n3.- **Use M365 OneBranch Release Support**:\n\n* When setting up the release pipeline in **M365 OneBranch**, input your desired `Ev2ArtifactsServiceRootPath` location during the scaffold pipeline creation.\n\n* Reference:\n\n* * `Ev2 Artifacts Service Root Path`: The relative folder for deployment files.\n\n4.- **Debug Parameter Mismatches**:\n\n* Confirm that all required deployment parameters are correctly assigned during pipeline creation.\n\n* Use troubleshooting steps outlined in [App Deployment General Troubleshooting](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/troubleshooting/application-deployment/App-Deployment-General-Troubleshooting).\n\nIf the issue persists, you may escalate it to the COSMIC team via the ICM path for more advanced troubleshooting.\n\n---\n\n**References**\n\n* [Create OneBranch Release Pipeline](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/onboarding/prepare-and-test-deployment/Create-OneBranch-release-pipeline)\n\n* [App Deployment General Troubleshooting](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/troubleshooting/application-deployment/App-Deployment-General-Troubleshooting)\n\n* [DevXpress CI/CD Pipeline Setup](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/onboarding/prepare-and-test-deployment/DevXpress-cosmic-service-CI-CD-pipeline-setup)"
    },
    modelB: {
      id: 'b29',
      model: 'Model B',
      response: "To address the issue of specifying the path for the `app-metadata.json` file in the release pipeline, particularly when migrating to the M365GPT pipeline, you can follow these steps and recommendations:\n\n---\n\n**Understanding the Issue**\n\nThe problem arises because the `app-metadata.json` file is located under a specific subpath (`deploymentpackage.zip/1p`) in the deployment package, but the release pipeline is configured to look for it at the root of the deployment package (`deploymentpackage.zip`). This discrepancy leads to a failure in the release pipeline.\n\n---\n\n**Common Causes**\n\n1.- **Path Misconfiguration**: The release pipeline is not configured to look for the `app-metadata.json` file in the correct subpath.\n\n2.- **Pipeline Migration Gaps**: During the migration to the M365GPT pipeline, the path configurations for artifacts may not have been updated to reflect the new structure.\n\n3.- **Artifact Structure Changes**: The new build pipeline may generate artifacts in a slightly different structure compared to the previous pipeline.\n\n---\n\n**Steps to Investigate**\n\n1.- **Verify Artifact Structure**: Inspect the `deploymentpackage.zip` file generated by the M365GPT build pipeline to confirm the exact location of the `app-metadata.json` file.\n\n2.- **Check Release Pipeline Logs**: Review the logs from the release pipeline to identify the exact path it is attempting to access.\n\n3.- **Validate YAML Configurations**: Ensure that the release pipeline YAML configuration includes the correct path for the `app-metadata.json` file.\n\n---\n\n**Mitigation Suggestions**\n\n**1.- Update the Release Pipeline to Specify the Correct Path**\n\nYou can modify the release pipeline YAML to explicitly specify the path to the `app-metadata.json` file. For example:\n\n```yaml\n\nvariables:\n\n AppMetadataPath: \'deploymentpackage.zip/1p/app-metadata.json\'\n\nsteps:\n\n- task: ExtractFiles@1\n\n inputs:\n\n archiveFilePatterns: \'$(Build.ArtifactStagingDirectory)/$(AppMetadataPath)\'\n\n destinationFolder: \'$(Build.ArtifactStagingDirectory)/extracted\'\n\n```\n\nThis ensures that the pipeline looks for the `app-metadata.json` file in the correct subpath.\n\n---\n\n**2.- Use Deployment Parameters to Dynamically Set Paths**\n\nIf the release pipeline needs to handle multiple namespaces or service trees, you can use parameters to dynamically set the path based on the target namespace. For example:\n\n```yaml\n\nparameters:\n\n - name: Namespace\n\n type: string\n\n default: \'1p\'\n\nvariables:\n\n AppMetadataPath: \'deploymentpackage.zip/$(Namespace)/app-metadata.json\'\n\nsteps:\n\n- task: ExtractFiles@1\n\n inputs:\n\n archiveFilePatterns: \'$(Build.ArtifactStagingDirectory)/$(AppMetadataPath)\'\n\n destinationFolder: \'$(Build.ArtifactStagingDirectory)/extracted\'\n\n```\n\nThis approach allows you to reuse the same release pipeline for different namespaces by specifying the `Namespace` parameter during deployment.\n\n---\n\n**3.- Adjust the Build Pipeline to Flatten the Artifact Structure**\n\nIf modifying the release pipeline is not feasible, you can adjust the build pipeline to ensure that the `app-metadata.json` file is placed at the root of the `deploymentpackage.zip`. This can be done by adding a step in the build pipeline to copy or move the file to the root directory.\n\nExample:\n\n```yaml\n\nsteps:\n\n- script: |\n\n mkdir -p $(Build.ArtifactStagingDirectory)/deploymentpackage\n\n cp $(Build.ArtifactStagingDirectory)/1p/app-metadata.json $(Build.ArtifactStagingDirectory)/deploymentpackage/\n\n displayName: \'Move app-metadata.json to root\'\n\n```\n\n---\n\n**4.- Validate Artifact Paths in the EV2 Portal**\n\nIf the release pipeline integrates with EV2 for deployment, ensure that the artifact paths are correctly specified in the EV2 rollout specifications. Misconfigured paths in EV2 can also lead to deployment failures.\n\n---\n\n**Best Practices**\n\n1.- **Artifact Path Consistency**: Ensure that the artifact structure is consistent across build and release pipelines to minimize configuration complexity.\n\n2.- **Pipeline Documentation**: Document the artifact paths and pipeline configurations to simplify future migrations or troubleshooting.\n\n3.- **Testing**: Test the updated pipeline configurations in a lower environment (e.g., Dev or Test) before deploying to production.\n\n---\n\n**Next Steps**\n\n1.- Implement one of the suggested mitigation strategies based on your pipeline requirements.\n\n2.- Test the updated pipeline to ensure that the `app-metadata.json` file is correctly located and the deployment succeeds.\n\n3.- If the issue persists, escalate to the M365GPT pipeline support team for further assistance.\n\n---\n\nBy following these steps, you should be able to resolve the issue and successfully deploy to multiple namespaces using the M365GPT pipeline.\n\n**Date:** 2025-09-16"
    }
  },
  {
    id: 'q30',
    query: "how to check What does the image in the ev2 output look like",
    modelA: {
      id: 'a30',
      model: 'Model A',
      response: "To check the EV2 output image within the deployment package, ensure that the expected file structure and metadata are correctly generated and packaged. Here are steps relevant to understand the image reference in the EV2 deployment artifacts:\n\n**Key Details on EV2 Output and Image Reference**\n\n1.- **Deployment Package Structure**:\n\n* The EV2 deployment package is a ZIP file named `deploymentpackage.zip` which contains:\n\n* * `app-resources.json`: Kubernetes resources with container image references (by SHA hash).\n\n* * `overrides.json` (optional): Per-ring or region overrides.\n\n* * `app-metadata.json`: Deployment metadata.\n\n* * A catalog file for checksum validation.\n\n2.- **Image Reference in EV2 Artifacts**:\n\n* During the build pipeline, container images are built and pushed to the ACR.\n\n* The `SHA256` digest of these images is injected into the EV2 collateral as part of the `Append SHA Hash` step in the pipeline YAML.\n\n3.- **Inspecting Image in EV2 Artifacts**:\n\n* Unzip the deployment package to locate `app-resources.json`.\n\n* Open `app-resources.json` to verify the container image used:\n\n ```\n\n {\n\n \"spec\": {\n\n \"containers\": [\n\n {\n\n \"image\": \"acrname.azurecr.io/repository/image@sha256:<hash>\",\n\n \"name\": \"container-name\"\n\n }\n\n ]\n\n }\n\n }\n\n ```\n\n4.- **View EV2 Deployment Logs**:\n\n* During actual deployment, use EV2 rollout logs to confirm whether the correct package and image are picked.\n\n* Using EV2 PowerShell or the release pipeline, capture insights for debugging.\n\n5.- **Common Issues**:\n\n* Missing SHA injection in `app-resources.json`.\n\n* Incorrect pipeline configuration for the image publishing step.\n\nFor additional details on generating and verifying EV2 compute artifacts, refer to the [Generate and Deploy EV2 Compute Artifacts](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/onboarding/prepare-and-test-deployment/Generate-and-deploy-ev2-compute-artifacts).\n\n---\n\n**References**\n\n* [Generate and Deploy EV2 Compute Artifacts](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/onboarding/prepare-and-test-deployment/Generate-and-deploy-ev2-compute-artifacts)"
    },
    modelB: {
      id: 'b30',
      model: 'Model B',
      response: "To check the image in the EV2 output, you can follow these steps based on the COSMIC documentation and EV2 deployment process:\n\n---\n\n**Understanding EV2 Output and Images**\n\nIn the EV2 deployment process, images are often referenced as part of the deployment artifacts. These images are typically container images (e.g., for controllers or agents) that are used in the COSMIC environment. The EV2 output includes logs and references to these images, which can be inspected to verify the deployment status or troubleshoot issues.\n\n---\n\n**Steps to Check Images in EV2 Output**\n\n1. **Access the EV2 Portal or Dashboard**:\n\n* The EV2 Portal or Dashboard is a web-based interface used for managing and monitoring deployments. It provides a detailed view of deployment stages, including the artifacts and images used.\n\n* Navigate to the EV2 Portal and locate the specific deployment you are interested in. You can track the deployment stages and artifacts through the portal [Data: Entities (2957); Relationships (5306)].\n\n2. **Inspect Deployment Logs**:\n\n* Deployment logs in EV2 often include references to the images being used. For example, during the rollout process, the logs may show the image tags or SHAs being deployed.\n\n* You can find these logs in the EV2 Monitoring Job or by navigating to the \"Ev2 RA - Deploy\" task in the MOBR pipeline. The logs will provide details about the EV2 artifact registration and rollout, including image information [Data: Sources (3428)].\n\n3. **Manual Image Copy and Verification**:\n\n* If you are working in a non-TORUS environment, you may need to manually copy images to the COSMIC ACR (Azure Container Registry). This process involves identifying the image tags and SHAs from the EV2 output or inventory and ensuring they are correctly copied to the target ACR.\n\n* For example, in TestTRS environments, you can use the `cosmictesttrsdevacr` registry to locate the latest images and verify their SHAs. This information can be cross-referenced with the EV2 output to ensure consistency [Data: Sources (3554)].\n\n4. **Use the EV2 Rollout Cosmic Release Map**:\n\n* The EV2 Rollout Cosmic Release Map is another tool that logs the status of deployments, including the images used. Queries on this map can help identify failed deployments and their associated images or error messages [Data: Entities (6305); Relationships (10570)].\n\n5. **Check Image Details in Inventory**:\n\n* For environments like TestTRS, you can access the COSMIC inventory to find image details. This involves navigating to the `Data Explorer > Cluster > PlatformInfraAgentsTemplates` container and searching for image names and SHAs. These details can then be matched with the EV2 output [Data: Sources (3554)].\n\n---\n\n**Visual Representation of EV2 Output**\n\nThe EV2 output often includes a visual representation of deployment stages, as shown in the EV2 Portal. This may include:\n\n* Deployment stages depicted according to infra stagemaps and propagation policies.\n\n* Logs showing the registration and rollout of artifacts, including images.\n\n* Snapshots of deployment progress, such as the one provided for infra train deployments in the EV2 portal [Data: Sources (3428)].\n\n---\n\n**Troubleshooting and Additional Notes**\n\n* If you encounter issues with image references in the EV2 output, ensure that the EV2 artifacts path is correctly specified in the pipeline. Incorrect paths can lead to deployment errors [Data: Entities (8253)].\n\n* For manual interventions like image copying, follow the relevant SOPs (e.g., Image Copy SOP) to resolve any discrepancies [Data: Sources (3554)].\n\nBy following these steps, you can effectively check and verify the images referenced in the EV2 output. If further assistance is needed, you can consult the EV2 documentation or reach out to the COSMIC support team.\n\n--- \n\n**References**\n\n* [JIT elevation](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/tools/cosmic-cli/securely-access-app-jit)\n\n* [COSMIC CLI (cc)](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/tools/cosmic-cli/access-clusters-with-cc)\n\n* [COSMIC Operation Portal (COP)](https://aka.ms/cop)\n\n**Date:** 2025-09-16"
    }
  },
  {
    id: 'q31',
    query: "what are the cc commands to check the status of cluster \n\ncosmic-test-s01-800-nam-westus-aks_test_GriffinContainer",
    modelA: {
      id: 'a31',
      model: 'Model A',
      response: "To check the status of a cluster, you can use the following `cc` commands with relevant JIT elevation:\n\n1.- **List Nodes in the Cluster**:\n\n ```\n\n cc get nodes\n\n ```\n\n This provides the list of nodes in the cluster, their statuses, and roles.\n\n2.- **Describe the Cluster Pods**:\n\n ```\n\n cc get pods -A -o wide\n\n ```\n\n This shows all pods across namespaces, details about their node assignments, and other statuses.\n\n3.- **Inspect Cluster Events**:\n\n ```\n\n cc get events -A\n\n ```\n\n This gives information about cluster-level issues, such as scheduling, image pull failures, or other errors.\n\n4.- **Check Cluster Configuration**:\n\n ```\n\n cc describe cluster cosmic-test-s01-800-nam-westus-aks_test_GriffinContainer\n\n ```\n\n This explains the cluster setup for troubleshooting.\n\n---\n\nYou may require Just-In-Time (JIT) elevation for roles such as Reader or Contributor. For more, visit [Access Clusters with CC](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/tools/cosmic-cli/access-clusters-with-cc).\n\n---\n\n**References**\n\n* [Install Telemetry on Cluster and Check Logs](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/troubleshooting/general/Install-telemetry-on-cluster-and-check-logs)\n\n* [Access Clusters with CC](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/tools/cosmic-cli/access-clusters-with-cc-gallatin)"
    },
    modelB: {
      id: 'b31',
      model: 'Model B',
      response: "To check the status of the cluster `cosmic-test-s01-800-nam-westus-aks_test_GriffinContainer` using the `cc` command-line tool, you can use the following commands. These commands allow you to gather information about the cluster, its nodes, and the workloads running within it.\n\n---\n\n1.- **Set the Cluster Context**\n\nBefore running any commands, you need to set the context to the specific cluster. Use the `cc set` command to target the cluster:\n\n```bash\n\ncc set -r test -s s01 -i 800 -a westus -n GriffinContainer\n\n```\n\nThis command sets the filter to the `cosmic-test-s01-800-nam-westus-aks` cluster and the `GriffinContainer` namespace.\n\n---\n\n2.- **Check Node Status**\n\nTo view the status of the nodes in the cluster, use the `cc get nodes` command:\n\n```bash\n\ncc get nodes\n\n```\n\nThis will list all the nodes in the cluster along with their statuses, such as whether they are `Ready` or experiencing issues.\n\n---\n\n3.- **Check Pod Status**\n\nTo check the status of the pods running in the `GriffinContainer` namespace, use the following command:\n\n```bash\n\ncc get pods -n GriffinContainer\n\n```\n\nThis will display the list of pods in the namespace, their current state (e.g., `Running`, `Pending`, `CrashLoopBackOff`), and other details.\n\n---\n\n4.- **Check Resource Utilization**\n\nTo monitor the resource utilization of nodes and pods, you can use the `cc top` commands:\n\n* **Node Resource Utilization:**\n\n  ```bash\n\n  cc top node\n\n  ```\n\n* **Pod Resource Utilization in the Namespace:**\n\n  ```bash\n\n  cc top pod -n GriffinContainer\n\n  ```\n\nThese commands provide insights into CPU and memory usage for nodes and pods.\n\n---\n\n5.- **Describe Cluster Components**\n\nTo get detailed information about specific components, such as nodes or pods, use the `cc describe` command:\n\n* **Describe a Node:**\n\n  ```bash\n\n  cc describe node <node-name>\n\n  ```\n\n* **Describe a Pod:**\n\n  ```bash\n\n  cc describe pod <pod-name> -n GriffinContainer\n\n  ```\n\nReplace `<node-name>` and `<pod-name>` with the actual names of the node or pod you want to inspect.\n\n---\n\n6.- **Check Deployment Status**\n\nTo check the status of deployments in the `GriffinContainer` namespace, use:\n\n```bash\n\ncc get deployments -n GriffinContainer\n\n```\n\nThis will list all deployments in the namespace and their current status, such as the number of replicas available and desired.\n\n---\n\n7.- **View Cluster Logs**\n\nIf you need to investigate issues, you can view logs for specific pods using:\n\n```bash\n\ncc logs <pod-name> -n GriffinContainer\n\n```\n\nReplace `<pod-name>` with the name of the pod whose logs you want to view.\n\n---\n\n### Additional Notes\n\n* If you encounter permission issues while running these commands, you may need to request **JIT elevation** to the appropriate role (e.g., `Reader`, `LogReader`, or `Contributor`). Refer to the [JIT elevation documentation](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/tools/cosmic-cli/securely-access-app-jit) for more details.\n\n* You can also use the [COSMIC Operation Portal (COP)](https://aka.ms/cop) to view cluster and namespace details through a web interface.\n\nBy using these commands, you can effectively monitor and troubleshoot the status of the `cosmic-test-s01-800-nam-westus-aks_test_GriffinContainer` cluster and its workloads.\n\n---\n\n### References\n\n* [COSMIC CLI (cc)](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/tools/cosmic-cli/access-clusters-with-cc)\n\n* [JIT Elevation](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/tools/cosmic-cli/securely-access-app-jit)\n\n* [COSMIC Operation Portal (COP)](https://aka.ms/cop)\n\n**Date:** 2025-09-16"
    }
  },
  {
    id: 'q32',
    query: "How can I investigate PDB violations",
    modelA: {
      id: 'a32',
      model: 'Model A',
      response: "**Investigation of Pod Disruption Budget (PDB) Violations**\n\n**Common Causes**:\n\n1.- **Incorrect PDB Configuration**:\n\n* Missing `maxUnavailable` or `minAvailable` settings, or improperly matching labels in the workload.\n\n2.- **Unplanned Disruptions**:\n\n* HostOS crashes or Azure infrastructure failures; PDBs only handle voluntary disruptions.\n\n3.- **Selector Mismatches**:\n\n* PDB selectors targeting incorrect or incomplete workloads.\n\n4.- **Low Pod Count**:\n\n* Minimum pods (`replicas`) too few to meet PDB constraints.\n\n5.- **Disrupted Deployments**:\n\n* Frequent deployments triggering evictions beyond set limits.\n\n6.- **Multi-Deployment Edge Cases**:\n\n* Shared PDBs across multiple deployments leading to validation errors.\n\n---\n\n**Steps to Investigate:**\n\n1.- **Access PDB Audit Dashboard**: Use the [PDBAudit Dashboard](https://cosmicmonitoring-b6a0cza8a4ghfnda.scus.grafana.azure.com/d/8ZC_65XVk/pdbaudit?orgId=1) to identify affected workloads and the nature of violations.\n\n2.- **Inspect PDB Configuration**:\n\n ```\n\n cc describe pdb <pdb-name> -n <namespace>\n\n ```\n\n Ensure selectors match relevant pods and `maxUnavailable` aligns with the pod count.\n\n3.- **Verify Pod Labels**:\n\n ```\n\n cc get pods -n <namespace> -L <key-for-label-matching-pdb>\n\n ```\n\n Confirm all expected pods have the correct labels.\n\n4.- **Check Cluster Events**:\n\n ```\n\n cc get events -n <namespace>\n\n ```\n\n Identify events such as evictions or node drains causing downtime.\n\n5.- **Analyze Recent Deployments**: Use deployment pipelines to check if recent updates have involuntarily disrupted pods.\n\n---\n\n**Mitigation Suggestions:**\n\n1.- Update PDB:\n\n* Configure `maxUnavailable` to `20%` of replicas to allow for disruptions:\n\n ```\n\n {\n\n \"spec\": {\n\n \"maxUnavailable\": \"20%\",\n\n \"selector\": {\n\n \"matchLabels\": { \"app\": \"<app-name>\" }\n\n }\n\n }\n\n }\n\n ```\n\n Higher values may apply for smaller workloads.\n\n2.- Correct Pod Labels: Add or correct labels used in the PDB selector to ensure all target pods are protected.\n\n3.- Increase Replica Count: Ensure at least 5 replicas (or adjust `maxUnavailable` percentage) for workloads with low pod counts.\n\n4.- Monitor for HostOS Failures: HostOS or node failures invalidate PDB protections. Escalate platform-related disruptions to [COSMIC911](https://aka.ms/cosmic911).\n\n5.- Frequent Deployments: Optimize deployment strategies or stagger updates to avoid exceeding PDB thresholds.\n\n---\n\n**References:**\n\n* [Configure Pod Disruption Budget](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/onboarding/set-up-service-configurations/config-pod-disruption-budget)\n\n* [QEI MICROSOFT.O365.PDBViolation](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/troubleshooting/QEI/%5BQEI-PR3.6.2%5DMICROSOFT.O365.Cosmic)\n\n---\n\n**Similar GitHub Issues and ICM Records:**\n\n* **[Issue#2393 - Understand Violation of PDB](https://github.com/substrate-platform/COSMIC/issues/2393)**\n\n* * Description: Network failures leading to perceived violations during HostOS crashes.\n\n* * Resolution: Emphasis on handling involuntary disruptions.\n\n* * Status: Closed.\n\n* **[Issue#5066 - Cosmic.Build enforcing PDB limits](https://github.com/substrate-platform/COSMIC/issues/5066)**\n\n* * Description: Challenges with PDB constraints on clusters with low replicas.\n\n* * Resolution: Scale changes or relax maxUnavailable percentage.\n\n* * Status: Closed.\n\n* **[ICM#683341719 - Node Pool Train and PDB Violation](https://portal.microsofticm.com/imp/v5/incidents/details/683341719)**\n\n* * Description: Node pool upgrade allegedly violated PDBs.\n\n* * Status: Mitigated.\n\n* **[ICM#673789491 - PDB violation on SDF clusters](https://portal.microsofticm.com/imp/v5/incidents/details/673789491)**\n\n* * Description: PDB violations during node evictions in two clusters.\n\n* * Status: Mitigated.\n\nhas context menuView prompts\n\nhas context menu"
    },
    modelB: {
      id: 'b32',
      model: 'Model B',
      response: "To investigate Pod Disruption Budget (PDB) violations in COSMIC, you can follow a structured approach to identify the root cause, assess the impact, and mitigate the issue. Below are the key steps, organized into sections for clarity:\n\n---\n\n**Understanding PDB Violations**\n\nA PDB violation occurs when the constraints defined in a Pod Disruption Budget are breached, leading to more pods being unavailable than the allowed threshold. PDBs are critical for ensuring service availability during disruptions like node reboots, upgrades, or scaling operations. Violations can result in service disruptions, pods entering `CrashLoopBackOff` states, or deployment failures [Data: Entities (283, 257, 6705)].\n\n---\n\n**Common Causes of PDB Violations**\n\n1.- **Node Reboots or Upgrades**: PDB violations often occur during nodepool upgrades or reboots, especially if pods are evicted ungracefully [Data: Entities (283); Relationships (6213, 17799)].\n\n2.- **Misconfigured PDBs**: Invalid configurations, such as setting both `minAvailable` and `maxUnavailable`, can lead to violations [Data: Entities (2081, 2082)].\n\n3.- **Insufficient Nodes**: Lack of available nodes for scheduling can cause pods to remain unscheduled, breaching the PDB [Data: Entities (283)].\n\n4.- **Unsafe Drains**: Drains performed without respecting PDBs, such as those triggered by the Remediator agent, can lead to violations [Data: Entities (10397)].\n\n5.- **Partner Service Issues**: Crashing pods in partner services can trigger PDB violations if the PDB is not properly configured [Data: Sources (4016)].\n\n---\n\n**Steps to Investigate PDB Violations**\n\n**1. Identify the Impacted Cluster and Namespace**\n\n* Use the `cc` CLI to set the context for the impacted cluster:\n\n ```bash\n\n cc set -r <ring> -s <silo> -i <siloinstance> -a <azure location>\n\n ```\n\n* List the pods in the affected namespace to check their states:\n\n ```bash\n\n cc get pods -n <namespace>\n\n ```\n\n* Describe the PDB to understand its configuration:\n\n ```bash\n\n cc describe pdb -n <namespace>\n\n ```\n\n This will provide details about the `minAvailable` and `maxUnavailable` settings and the current state of the PDB [Data: Sources (4016, 4015)].\n\n**2. Check for Nodepool Upgrades or Drains**\n\n* Determine if a nodepool upgrade was in progress during the violation:\n\n* * Check the upgrade logs or use the COSMIC Operation Portal (COP) to view nodepool upgrade activities.\n\n* * Investigate if the upgrade process respected PDBs or if there were any unsafe drains [Data: Sources (4016); Entities (10397)].\n\n**3. Analyze Pod States and Events**\n\n* Use the following commands to gather more information about the pods:\n\n ```bash\n\n cc logs <pod-name>\n\n cc describe pod <pod-name>\n\n ```\n\n* Look for patterns such as pods stuck in `Pending` or `ContainerCreating` states, which may indicate resource constraints or scheduling issues [Data: Sources (4016)].\n\n**4. Use Monitoring Dashboards**\n\n* Access the **PDBAudit Dashboard** or **S360 Dashboard** to track workloads with PDB violations. These dashboards provide insights into compliance rates and the state of PDBs across clusters [Data: Entities (5673, 11753)].\n\n* For live views, use the Grafana dashboard linked to your cluster [Data: Sources (4016)].\n\n**5. Investigate Configuration Issues**\n\n* Check if the PDB configuration is valid. Misconfigurations like setting both `minAvailable` and `maxUnavailable` can cause deployment failures. Correct the configuration and redeploy [Data: Entities (2081, 2082)].\n\n**6. Coordinate with Teams**\n\n* If the issue involves node reboots or dual stack rollouts, coordinate with the Atlas team to confirm the root cause and ensure proper rollout of fixes [Data: Relationships (353)].\n\n---\n\n**Mitigation Suggestions**\n\n1.- **Adjust PDB Configuration**: If the PDB is misconfigured, update it to align with the desired availability thresholds. Use the following command to apply changes:\n\n ```bash\n\n cc apply -f <pdb-config-file>\n\n ```\n\n2.- **Scale Down Pods Temporarily**: In severe cases, scale down non-critical pods to reduce the load and allow critical pods to recover:\n\n ```bash\n\n cc scale deployment <name> --replicas=<number>\n\n ```\n\n3.- **Increase Node Capacity**: If the issue is due to insufficient nodes, provision additional nodes or investigate IP allocation issues [Data: Reports (5)].\n\n4.- **Perform Safe Drains**: Ensure that any node drains respect PDBs to avoid ungraceful evictions [Data: Entities (10397)].\n\n---\n\n**Tools and Resources**\n\n* **COSMIC CLI (cc)**: Use the `cc` tool for cluster operations. Refer to the [COSMIC CLI documentation](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/tools/cosmic-cli/access-clusters-with-cc) for more details.\n\n* **COSMIC Operation Portal (COP)**: Use COP for managing PDBs, scaling deployments, and viewing cluster details [Data: Entities (5673, 11753)].\n\n* **JIT Elevation**: Some operations may require Just-In-Time (JIT) elevation to the Contributor role. Refer to the [JIT elevation guide](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/tools/cosmic-cli/securely-access-app-jit).\n\n---\n\nBy following these steps, you can systematically investigate and resolve PDB violations in COSMIC environments. If you encounter persistent issues, consider reaching out to the COSMIC support team for further assistance.\n\n**Date:** 2025-09-16"
    }
  },
  {
    id: 'q33',
    query: "what does \"System.InvalidOperationException: The requested Performance Counter is not a custom counter, it has to be initialized as ReadOnly\" mean when a pod is in crashloopbackoff",
    modelA: {
      id: 'a33',
      model: 'Model A',
      response: "Placeholder"
    },
    modelB: {
      id: 'b33',
      model: 'Model B',
      response: "The error message **\"System.InvalidOperationException: The requested Performance Counter is not a custom counter, it has to be initialized as ReadOnly\"** typically indicates an issue with how the application inside the container is attempting to access or configure performance counters. Performance counters are system-level metrics used to monitor resource usage, application performance, or other operational data. This error suggests that the application is trying to create or modify a performance counter that is not allowed to be modified because it is a system-defined (non-custom) counter, which must be accessed in a read-only mode.\n\nIn the context of a Kubernetes pod in a **CrashLoopBackOff** state, this error is likely a symptom of a misconfiguration or a runtime issue within the containerized application. Below is a detailed breakdown of the potential causes, steps to investigate, and mitigation strategies.\n\n---\n\n**Common Causes**\n\n1.- **Application Misconfiguration**:\n\n* The application may be attempting to create or write to a system-defined performance counter instead of accessing it in read-only mode.\n\n* This could be due to incorrect application settings, environment variables, or initialization logic.\n\n2.- **Missing Permissions**:\n\n* The containerized application may lack the necessary permissions to access performance counters, especially in restricted environments like Kubernetes.\n\n3.- **Dependency Failures**:\n\n* The application might rely on external libraries or dependencies that are not properly configured or compatible with the containerized environment.\n\n4.- **Platform-Specific Issues**:\n\n* Certain performance counters may not be available or accessible in containerized environments, especially on Linux-based containers running .NET applications, which often encounter compatibility issues with Windows-specific performance counters.\n\n5.- **Resource Constraints**:\n\n* Insufficient CPU or memory resources allocated to the pod could cause the application to fail during initialization, leading to this error.\n\n6.- **CrashLoopBackOff State**:\n\n* The repeated restarts of the pod may exacerbate the issue, as the application does not have enough time to initialize properly before being restarted.\n\n---\n\n**Steps to Investigate**\n\n1.- **Check Pod Logs**:\n\n* Use the following command to view the logs of the affected pod:\n\n ```bash\n\n cc logs <pod-name>\n\n ```\n\n* Look for additional error messages or stack traces that provide more context about the failure.\n\n2.- **Describe the Pod**:\n\n* Use the following command to inspect the pod\'s configuration and events:\n\n ```bash\n\n cc describe pod <pod-name>\n\n ```\n\n* Check for resource allocation issues, probe failures, or other warnings.\n\n3.- **Inspect Application Configuration**:\n\n* Verify the application\'s configuration files, environment variables, and startup scripts to ensure they are correctly set up for the containerized environment.\n\n4.- **Validate Resource Requests and Limits**:\n\n* Ensure the pod has sufficient CPU and memory resources allocated. Use the following command to check resource usage:\n\n ```bash\n\n cc top pod <pod-name>\n\n ```\n\n5.- **Check for Dependency Issues**:\n\n* If the application relies on external libraries or services, ensure they are accessible and properly configured.\n\n6.- **Review Platform Compatibility**:\n\n* If the application is running on a Linux-based container but was originally designed for Windows, verify that it is not attempting to access Windows-specific performance counters.\n\n---\n\n**Mitigation Strategies**\n\n1.- **Modify Application Code**:\n\n* Update the application to access system-defined performance counters in read-only mode. This may involve changing the initialization logic or configuration.\n\n2.- **Adjust Permissions**:\n\n* If the application requires elevated permissions to access performance counters, ensure the container\'s security context allows it. However, this should be done cautiously to avoid security risks.\n\n3.- **Increase Resource Allocation**:\n\n* If resource constraints are contributing to the issue, increase the CPU and memory requests/limits for the pod in the deployment manifest.\n\n4.- **Use Compatibility Libraries**:\n\n* For .NET applications, consider using libraries like [System.Diagnostics.PerformanceCounter](https://learn.microsoft.com/en-us/dotnet/api/system.diagnostics.performancecounter) that are compatible with the containerized environment.\n\n5.- **Debug with COSMIC Tools**:\n\n* Use the `cc cosmic-debug` command to debug the pod interactively:\n\n ```bash\n\n cc cosmic-debug pod <pod-name>\n\n ```\n\n6.- **Restart the Pod**:\n\n* After making configuration changes, delete the pod to allow Kubernetes to recreate it with the updated settings:\n\n ```bash\n\n cc delete pod <pod-name>\n\n ```\n\n7.- **Escalate to COSMIC Support**:\n\n* If the issue persists, escalate to the COSMIC support team with detailed logs and configuration information.\n\n---\n\n**References**\n\n* For more information on troubleshooting CrashLoopBackOff states, refer to the [CrashLoopBackOff TSG](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/tools/cosmic-cli/securely-access-app-jit).\n\n* Learn about COSMIC CLI commands: [COSMIC CLI Documentation](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/tools/cosmic-cli/access-clusters-with-cc).\n\nBy following these steps, you should be able to identify and resolve the root cause of the issue, allowing the pod to transition to a stable state. If further assistance is needed, consider using the COSMIC Operation Portal (COP) for additional diagnostics and monitoring.\n\n**Date:** 2025-09-16"
    }
  },
  {
    id: 'q34',
    query: "what is RNR ring in COSMIC",
    modelA: {
      id: 'a34',
      model: 'Model A',
      response: "The **RNR (Rollout and Ring)** ring in COSMIC refers to a configuration within the rollout management system. Rings, in general, are deployment stages in COSMIC used to structure and organize deployment pipelines ordered by levels of stability or risk. These rings often include development rings, testing/staging environments, and higher environments such as production.\n\nCurrently, RNR configurations and their usage in COSMIC deployment processes allow services to progress smoothly through staged environments in a controlled and monitored manner. For instance:\n\n* Rings like `dev` and `test` are used for building, debugging, and initial validation during deployments.\n\n* Progressive deployment to higher rings follows defined configurations, as highlighted in DevXpress procedures.\n\nFor more direct insights into promoting services through rings, refer to this [DevXpress-COSMIC Progressive Ring Addition](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/onboarding/prepare-and-test-deployment/DevXpress-cosmic-progressive-ring-addition).\n\n---\n\n**References**\n\n* [DevXpress Fast Deployment to COSMIC Dev Ring](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/onboarding/prepare-and-test-deployment/DevXpress-fast-deployment-to-cosmic-dev-ring-in-visual-studio)\n\n* [DevXpress-COSMIC Progressive Ring Addition](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/onboarding/prepare-and-test-deployment/DevXpress-cosmic-progressive-ring-addition)\n\n* [DevXpress COSMIC Inspect Window in Visual Studio](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/onboarding/prepare-and-test-deployment/DevXpress-cosmic-inspect-window-in-visual-studio)"
    },
    modelB: {
      id: 'b34',
      model: 'Model B',
      response: "The term \"RNR ring\" does not appear in the provided COSMIC documentation or knowledge graph. However, COSMIC does use the concept of \"rings\" extensively to manage and organize deployment environments, clusters, and resources. Rings in COSMIC are logical groupings that facilitate structured and controlled deployment processes, ensuring changes are tested and validated before reaching production environments [Data: Entities (5)].\n\nIf you meant a specific ring type or environment, such as \"NPE Ring,\" \"Production Ring,\" or \"COSMIC SDP Rings,\" these are well-documented and serve specific purposes within the COSMIC ecosystem. For example:\n\n* **NPE Ring**: A non-production environment used for testing and development [Data: Entities (4552)].\n\n* **Production Ring**: The final deployment stage where validated builds are released for general use [Data: Entities (11632)].\n\n* **COSMIC SDP Rings**: Structured deployment phases mapped to Kevlar SDP rings, facilitating sequential and controlled rollouts [Data: Entities (8746)].\n\nIf \"RNR ring\" is a new or specialized term, it might not yet be documented in the available resources. Please clarify or provide additional context, and I can assist further!\n\n**Date:** 2025-09-16"
    }
  },
  {
    id: 'q35',
    query: "We are currently testing our setup to go from application gateway to Azure Traffic Manager to Load Balancer and to the service instance.\n\nWhen I look into TrafficManager profile, the endpoint status is shown as degraded.\n\nLooking at the load balancer and the NSG, I think I see the rules to allow AzureTrafficManager and the application gateway IP to the external IP that is configured (13.93.203.35).\n\nEven with the rules to allow traffic to the given IP configured using the service CRD, I am not able to reach the External IP nor the status on Traffic manager changes.\n\nCould you help us debugging the issue?",
    modelA: {
      id: 'a35',
      model: 'Model A',
      response: "The issue where the Azure Traffic Manager profile endpoint status is shown as \"degraded\" and the external IP is not reachable could be related to configuration issues in the load balancer, network rules, or Traffic Manager health probes. Below are steps to troubleshoot and resolve the problem.\n\n---\n\n**Common Causes**\n\n1.- **Traffic Manager Probe Configuration**:\n\n* Health probe settings may be incorrect (protocol, port, path, or expected return codes).\n\n2.- **Ingress Network Configuration**:\n\n* Missing or misconfigured inbound NSG rules to allow traffic from Traffic Manager probes or Application Gateway public IP.\n\n3.- **Service Configuration**:\n\n* The Kubernetes `LoadBalancer` service might not expose the expected external IP or health-check paths corresponding to Traffic Manager probes.\n\n4.- **Load Balancer Source Range Restrictions**:\n\n* If `loadBalancerSourceRanges` is used, Traffic Manager probe IP ranges must be allowed.\n\n5.- **Endpoint DNS Resolution**:\n\n* DNS issues with resolving to the assigned external IPs or appropriate routing could impede connectivity.\n\n---\n\n**Steps to Investigate**\n\n1.- **Verify Traffic Manager Probe Health**:\n\n* Check probe configuration under Traffic Manager profile: protocol, port, path (`/health`, etc.), and status code range.\n\n* Ensure `toleratedNumberOfFailures` in configuration matches your setup.\n\n2.- **Allow Traffic Manager IP Ranges**:\n\n* Allowlist Azure Traffic Manager IP ranges via service annotation:\n\n ```\n\n service.beta.kubernetes.io/azure-allowed-service-tags: AzureTrafficManager\n\n ```\n\n* Alternatively, manually allowlist Traffic Manager probe IPs (download them [here](https://azuretrafficmanagerdata.blob.core.windows.net/probes/azure/probe-ip-ranges.json)).\n\n3.- **Check Load Balancer External IP Configuration**:\n\n* Verify the external IP via:\n\n ```\n\n cc get services -n <namespace>\n\n cc describe service <service-name> -n <namespace>\n\n ```\n\n* Validate annotations like `cosmic.office.net/atm-monitor-config` in the service manifest to configure ATM monitoring.\n\n4.- **Inspect Network Security Group (NSG) Rules**:\n\n* Ensure proper inbound NSG rules exist allowing traffic from:\n\n* * Azure Traffic Manager IP ranges.\n\n* * Application Gateway IP.\n\n5.- **Simulate Probe Requests**:\n\n* Perform a direct HTTP/HTTPS `curl` or probe simulation to verify connectivity:\n\n ```\n\n curl -I http://<external-ip>/health\n\n ```\n\n* Use PowerShell `Test-NetConnection` to check the endpoint availability:\n\n ```\n\n Test-NetConnection -ComputerName <external-ip> -Port <port>\n\n ```\n\n6.- **Inspect Cluster and Events**:\n\n* Use COSMIC CLI to check pods and cluster-level events:\n\n ```\n\n cc get events -n <namespace>\n\n ```\n\n7.- **DNS Resolution to External IP**:\n\n* Check external IP assignment and resolution with `nslookup <domain>` and validate DNS setup.\n\n---\n\n**Mitigation Suggestions**\n\n1.- Correct the health probe configuration in Azure Traffic Manager to match the exposed health-check path (`/health` or customized paths). Ensure the correct return codes are specified.\n\n2.- Add the annotation for Azure Traffic Manager service tags to the Kubernetes service or manually allowlist probe IP ranges in the `loadBalancerSourceRanges`.\n\n3.- Ensure the load balancer service has an external IP assigned and is reachable via the expected port.\n\n4.- Update NSG rules to allow traffic from Azure Traffic Manager IPs and Application Gateway public IP to the service\'s external endpoint.\n\n5.- If all configurations are correct and the issue persists, escalate the issue to COSMIC Networking via [COSMIC911](https://aka.ms/cosmic911).\n\n---\n\n**References**\n\n* [Allowlist Traffic Manager IP Ranges](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/troubleshooting/networking/Allowlist-Traffic-Manager-IP-ranges-in-loadbalancer-source)\n\n* [Debug Ingress DIA Connectivity Issue](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/troubleshooting/networking/Debug-Ingress-DIA-connectivity-issue)\n\n* [Set Up Service Routing](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/onboarding/set-up-service-configurations/Setup-service-routing)"
    },
    modelB: {
      id: 'b35',
      model: 'Model B',
      response: "Certainly! Debugging an issue involving Azure Traffic Manager (ATM), Load Balancer, and Network Security Groups (NSGs) in a COSMIC environment requires a systematic approach. Below, I outline the **common causes**, **steps to investigate**, and **mitigation suggestions** for your scenario.\n\n---\n\n**Common Causes**\n\n1.- **ATM Endpoint Configuration Issues**:\n\n* The endpoint monitor configuration in the Traffic Manager profile may be incorrect or incomplete, leading to a \"Degraded\" status.\n\n* Health probes from ATM may not be reaching the service due to missing allowlist rules for ATM probe IP ranges in the Load Balancer configuration.\n\n2.- **Load Balancer Misconfiguration**:\n\n* The Load Balancer may not have a properly assigned external IP or may be stuck in the \"Ensuring Load Balancer\" state due to misconfigured annotations or frontend IP settings.\n\n3.- **NSG Rule Issues**:\n\n* NSG rules may not be correctly configured to allow traffic from ATM probe IP ranges or the Application Gateway to the Load Balancer\'s external IP.\n\n4.- **Service or Pod Issues**:\n\n* The backend service or pods may not be running or reachable, causing health probes to fail.\n\n---\n\n**Steps to Investigate**\n\n**1. Validate Traffic Manager Endpoint Configuration**\n\n* Check the endpoint monitor configuration in the Traffic Manager profile. Ensure the monitoring path and protocol are correctly specified.\n\n* Use the following PowerShell command to test the endpoint monitor:\n\n ```powershell\n\n Invoke-WebRequest -Uri \"<monitoring-path-URL>\"\n\n ```\n\n* * If the response is not `200 OK`, the configuration may be incorrect. Update the configuration as per [this guide](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic/partners/onboarding/set-up-service-configurations/Config-partitions#configure-atm-monitoring-probes) [Data: Entities (3927, 9307); Sources (2401)].\n\n**2. Verify Load Balancer Configuration**\n\n* Use the `cc` tool to inspect the Load Balancer service:\n\n ```bash\n\n cc get services\n\n cc describe service <service-name>\n\n ```\n\n* Ensure the Load Balancer has an external IP assigned and is not stuck in the \"Ensuring Load Balancer\" state. If it is, check for misconfigured annotations or frontend IP settings [Data: Entities (7059, 7060); Relationships (12084, 12090)].\n\n**3. Check NSG Rules**\n\n* Verify that NSG rules allow traffic from ATM probe IP ranges and the Application Gateway to the Load Balancer\'s external IP. Use the following command to list NSG rules:\n\n ```bash\n\n az network nsg rule list --resource-group <resource-group> --nsg-name <nsg-name>\n\n ```\n\n* Ensure the ATM probe IP ranges are allowlisted. The current IP ranges can be downloaded from Azure\'s blob storage [Data: Entities (3865); Relationships (6967)].\n\n**4. Test Connectivity**\n\n* Use `Test-NetConnection` to verify connectivity to the Load Balancer\'s external IP and port:\n\n ```powershell\n\n Test-NetConnection -ComputerName <external-ip> -Port <port>\n\n ```\n\n* If the test fails, the issue may lie in the Load Balancer or NSG configuration [Data: Entities (6724); Sources (3030)].\n\n**5. Validate Backend Service and Pods**\n\n* Ensure the backend service and pods are running and reachable. Use the following commands:\n\n ```bash\n\n cc get pods\n\n cc describe pod <pod-name>\n\n ```\n\n* Check the pod logs for errors:\n\n ```bash\n\n cc logs <pod-name>\n\n ```\n\n* If the pods are not running, troubleshoot the deployment as per [this guide](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic/partners/troubleshooting/application-deployment/app-deployment-general-troubleshooting#deployment-failures) [Data: Entities (3927); Sources (2401)].\n\n---\n\n**Mitigation Suggestions**\n\n1.- **Fix ATM Endpoint Configuration**:\n\n* Update the endpoint monitor configuration in the Traffic Manager profile to ensure it matches the service\'s health probe settings. Follow [this guide](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic/partners/onboarding/set-up-service-configurations/Config-partitions#configure-atm-monitoring-probes) for details [Data: Entities (3927, 9307); Sources (2401)].\n\n2.- **Correct Load Balancer Configuration**:\n\n* If the Load Balancer is stuck in the \"Ensuring Load Balancer\" state, delete and recreate the service or correct the annotations and frontend IP configuration [Data: Entities (7059, 7060); Relationships (12084, 12090)].\n\n3.- **Update NSG Rules**:\n\n* Add rules to allow traffic from ATM probe IP ranges and the Application Gateway to the Load Balancer\'s external IP. Ensure the DIA port range is also allowlisted [Data: Entities (3865, 6724); Relationships (11384, 6967)].\n\n4.- **Ensure Backend Service Health**:\n\n* Restart or redeploy the backend service and pods if they are not running. Use the `cc` tool to monitor their status and logs [Data: Entities (3927); Sources (2401)].\n\n5.- **Contact COSMIC Networking**:\n\n* If the issue persists after following the above steps, escalate to the COSMIC Networking team for further assistance. You can reach them at [cosmic-networking@microsoft.com](mailto:cosmic-networking@microsoft.com) or raise a GitHub issue [here](https://github.com/substrate-platform/COSMIC/issues) [Data: Sources (2401)].\n\n---\n\n**References**\n\n* [JIT elevation](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/tools/cosmic-cli/securely-access-app-jit)\n\n* [COSMIC CLI (cc)](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/tools/cosmic-cli/access-clusters-with-cc)\n\n* [COSMIC Operation Portal (COP)](https://aka.ms/cop)\n\nBy following these steps, you should be able to identify and resolve the issue with the degraded Traffic Manager endpoint status. Let me know if you need further assistance!\n\n**Date:** 2025-09-16"
    }
  },
  {
    id: 'q36',
    query: "Our service will not available when a new service version is under deploying. This caused our service availability drop and cause API user compliance. I have checked the dashboard \"Deployment Monitoring Dashboard - COSMIC App Deployment - Dashboards - Grafana\", no obvious error occurred. How to prevent that from happening?",
    modelA: {
      id: 'a36',
      model: 'Model A',
      response: "To prevent service outages during deployment, it\'s important to adopt **zero-downtime deployment strategies**. Here are some key focus areas and best practices in COSMIC:\n\n---\n\n**Common Causes of Downtime During Deployment**\n\n1.- **Insufficient Replicas**: Replica count drops below availability due to improper termination/order of old pods.\n\n2.- **Probe Failures**: Poorly configured readiness or liveness probes lead to availability violations.\n\n3.- **Inappropriate Deployment Strategies**: Using \"Recreate\" deployment strategy instead of \"RollingUpdate.\"\n\n4.- **Application State Dependencies**: Database migrations or persistent states causing issues during deployment.\n\n5.- **Health Checking Misconfigurations**: Traffic Manager or load balancing endpoints not updated correctly.\n\n---\n\n**Steps to Investigate**\n\n1.- **Monitor Deployment Rollouts**:\n\n* Use `cc get deployments -n <namespace>` and `cc rollout status deployment.v1.apps/<deployment> -n <namespace>` to ensure pods are rolling out properly.\n\n2.- **Check Readiness Probes**:\n\n* Validate readiness probes in the deployment manifest to ensure they wait for the subsystems to be ready before accepting traffic.\n\n3.- **Traffic Redirection Failures**:\n\n* Investigate Azure Traffic Manager or load balancer if traffic hasn\'t been redirected correctly to available instances during deployment.\n\n4.- **Debug Pod Disruptions**:\n\n* Check for Pod Disruption Budget violations using:\n\n ```\n\n cc get poddisruptionbudgets -n <namespace>\n\n cc describe poddisruptionbudget <pdb-name> -n <namespace>\n\n ```\n\n5.- **Inspect Cluster Events or Rollout Failures**:\n\n* Check deployment logs and events to locate issues:\n\n ```\n\n cc get events -n <namespace>\n\n ```\n\n---\n\n**Mitigation Suggestions**\n\n1.- **Switch to RollingUpdate Strategy**:\n\n* Ensure that the Kubernetes `RollingUpdate` strategy (default for COSMIC) is used for your deployments.\n\n ```\n\n strategy:\n\n type: RollingUpdate\n\n rollingUpdate:\n\n maxUnavailable: 1\n\n maxSurge: 1\n\n ```\n\n2.- **Ensure Healthy Replica Count**:\n\n* Use `minAvailable` in Pod Disruption Budgets to guarantee that a minimum percentage of replicas are always available:\n\n ```\n\n minAvailable: 80%\n\n ```\n\n3.- **Health Probe Tuning**:\n\n* Use accurate readiness and liveness probes to validate service pod health without falsely reporting failures:\n\n* * Example readiness probe:\n\n ```\n\n readinessProbe:\n\n httpGet:\n\n path: /health\n\n port: 8080\n\n initialDelaySeconds: 5\n\n periodSeconds: 10\n\n ```\n\n4.- **Leverage Pre-Deployment Verification Pipelines**:\n\n* Simulate production-like environments or use lower rings during deployments for regressions.\n\n5.- **Blue-Green or Canary Deployment**:\n\n* Split your deployment to route traffic only when newer deployments cross validation without impacting currently running services.\n\n6.- **Scale Up Before Deployment**:\n\n* Temporarily scale up existing replicas to handle traffic during pod recreation.\n\n---\n\n**References**\n\n* [App Deployment General Troubleshooting](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/troubleshooting/application-deployment/App-Deployment-General-Troubleshooting)\n\n* [Configuring Probes in COSMIC](https://eng.ms/docs/experiences-devices/reference/platform-deployment#Config-liveness-readiness)\n\n* [Deployment Configurations](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/onboarding/set-up-service-configurations/Config-partitions)\n\nIf additional assistance is required, contact COSMIC support at [COSMIC911](https://aka.ms/cosmic911)."
    },
    modelB: {
      id: 'b36',
      model: 'Model B',
      response: "To address the issue of service unavailability during deployments, which impacts service availability and API user compliance, you can consider the following strategies. These approaches aim to ensure high availability and minimize downtime during the deployment of new service versions.\n\n---\n\n**Common Causes**\n\n1.- **Rolling Update Configuration**: If the deployment strategy is not configured correctly, such as insufficient overlap between old and new pods, it can lead to temporary unavailability.\n\n2.- **Pod Readiness Issues**: New pods may not pass readiness checks before the old ones are terminated, causing a gap in service availability.\n\n3.- **Resource Constraints**: Insufficient resources (CPU, memory, etc.) in the cluster can delay pod scheduling or readiness.\n\n4.- **Service Disruption During Scaling**: If Horizontal Pod Autoscalers (HPA) or manual scaling is not configured properly, it can lead to service interruptions during deployment.\n\n5.- **Load Balancer Configuration**: Misconfigured load balancers may route traffic to pods that are not yet ready.\n\n---\n\n**Steps to Investigate**\n\n1.- **Check Deployment Strategy**: Verify the deployment strategy in use. A rolling update strategy with appropriate `maxUnavailable` and `maxSurge` settings is recommended to ensure overlap between old and new pods.\n\n* Use the command: `cc get deployment <deployment-name> -o yaml` to inspect the deployment configuration.\n\n2.- **Inspect Readiness Probes**: Ensure that readiness probes are correctly configured for your pods. This ensures that traffic is only routed to pods that are fully ready.\n\n* Use: `cc describe pod <pod-name>` to check readiness probe configurations.\n\n3.- **Monitor Resource Utilization**: Use the Grafana dashboards or the `cc top pods` command to check if resource constraints are causing delays in pod readiness.\n\n4.- **Analyze Load Balancer Behavior**: Check if the load balancer is routing traffic to pods that are not ready. This can be done by inspecting logs or using the `cc logs` command for the affected pods.\n\n5.- **Review Deployment Logs**: Use the `cc logs <pod-name>` command to review logs for any errors during the deployment process.\n\n---\n\n**Mitigation Suggestions**\n\n1.- **Optimize Deployment Strategy**:\n\n* Configure the deployment to use a rolling update strategy with settings like:\n\n ```yaml\n\n strategy:\n\n type: RollingUpdate\n\n rollingUpdate:\n\n maxUnavailable: 25%\n\n maxSurge: 25%\n\n ```\n\n* This ensures that a portion of the old pods remains available while new pods are being deployed.\n\n2.- **Implement Readiness Probes**:\n\n* Add readiness probes to your pod specifications to ensure that only healthy pods receive traffic. For example:\n\n ```yaml\n\n readinessProbe:\n\n httpGet:\n\n path: /healthz\n\n port: 8080\n\n initialDelaySeconds: 5\n\n periodSeconds: 10\n\n ```\n\n3.- **Enable Pod Disruption Budgets (PDBs)**:\n\n* Use PDBs to ensure that a minimum number of pods remain available during deployments. For example:\n\n ```yaml\n\n apiVersion: policy/v1\n\n kind: PodDisruptionBudget\n\n metadata:\n\n name: my-app-pdb\n\n spec:\n\n minAvailable: 2\n\n selector:\n\n matchLabels:\n\n app: my-app\n\n ```\n\n* Use the `cc get poddisruptionbudgets` command to manage PDBs.\n\n4.- **Pre-Warm New Pods**:\n\n* Use a pre-warming mechanism to ensure that new pods are fully initialized and ready to handle traffic before terminating old pods.\n\n5.- **Leverage Blue-Green Deployments**:\n\n* If downtime is critical, consider using a blue-green deployment strategy. This involves deploying the new version alongside the old version and switching traffic only after the new version is fully validated.\n\n6.- **Monitor Deployment Health**:\n\n* Use dashboards like the **App Deployment DSR Dashboard** or **Platform Grafana Dashboard** to monitor deployment success rates and identify bottlenecks.\n\n* Access the App Deployment DSR Dashboard here: [aka.ms/grafana/cosmic/appdeploymentdsr](https://aka.ms/grafana/cosmic/appdeploymentdsr).\n\n---\n\n**Additional Recommendations**\n\n* **Use the COSMIC CLI for Debugging**: If issues persist, use the `cc troubleshoot` or `cc cosmic-debug` commands to investigate further.\n\n* **Scale Deployments Gradually**: Use the `cc scale deployment <name> --replicas=<number>` command to scale deployments incrementally and observe the impact.\n\n* **Engage the COSMIC Release Service Dashboard**: This dashboard provides insights into deployment operations and can help identify any underlying issues. Access it here: [aka.ms/release-service-dashboard](https://aka.ms/release-service-dashboard).\n\n---\n\nBy implementing these strategies, you can minimize service disruptions during deployments and maintain high availability for your API users. If the issue persists, consider escalating to the COSMIC support team or leveraging the COSMIC Operation Portal (COP) for additional insights.\n\n---\n\n**References**\n\n* [JIT elevation](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/tools/cosmic-cli/securely-access-app-jit)\n\n* [COSMIC CLI (cc)](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/tools/cosmic-cli/access-clusters-with-cc)\n\n* [COSMIC Operation Portal (COP)](https://aka.ms/cop)\n\n**Date:** 2025-09-16"
    }
  },
  {
    id: 'q37',
    query: "How to delete a partition",
    modelA: {
      id: 'a37',
      model: 'Model A',
      response: "To delete a partition in COSMIC, follow these steps:\n\n1.- **Use the Onboarding UI**:\n\n* Go to the [COSMIC Onboarding portal](https://o365exchange.visualstudio.com/O365%20Core/_apps/hub/cosmic.cosmic-tenant-hub.cosmic-onboarding).\n\n* Locate the \"Edit\" (pencil) button for your namespace\'s partitions.\n\n* Select the specific partition you want to delete and click \"Delete.\"\n\n2.- **Complete the Offboarding PR**:\n\n* The deletion action will create a pull request (PR) in the associated repository.\n\n* Ensure the PR is reviewed and merged.\n\n3.- **Log a GitHub Issue for Resource Cleanup**:\n\n* After the PR is merged, open a GitHub issue in the [COSMIC onboarding repository](https://github.com/substrate-platform/COSMIC/issues) and include details of the offboarding PR.\n\n* The COSMIC team will clean up any unused resources.\n\n4.- **Delete Service Deployments**:\n\n* Remove any service deployments from the deleted partitions to expedite resource cleanup and avoid lingering configurations.\n\nRefer to the steps in the [Offboard Your App](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/onboarding/Offboard-your-app).\n\n---\n\n**Notes**\n\n* The partition deletion process may cause downtime if handled improperly. Ensure that any dependent resources or services are stopped or migrated beforehand.\n\n* For assistance with any manual steps or failures, contact COSMIC at [COSMIC911](https://aka.ms/cosmic911).\n\n---\n\n**References**\n\n* [Offboard Your App](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/onboarding/Offboard-your-app)"
    },
    modelB: {
      id: 'b37',
      model: 'Model B',
      response: "To delete a partition in the COSMIC environment, you need to follow a structured offboarding process to ensure proper resource cleanup and maintain compliance. Below are the detailed steps for deleting a partition:\n\n---\n\n**Steps to Delete a Partition**\n\n1.- **Access the Onboarding UI**  \n\n* Navigate to the [COSMIC Onboarding UI](https://o365exchange.visualstudio.com/O365%20Core/_apps/hub/cosmic.cosmic-tenant-hub.cosmic-onboarding). This portal is used for managing partitions and creating pull requests (PRs) for partition deletions [Data: Entities (9600, 235); Relationships (17190)].\n\n2.- **Edit Partition Details**  \n\n* In the Onboarding UI, locate the partition you want to delete. Click the **Edit** button (pencil icon) in the Partition Details Pane.  \n\n* Select the ring-region combination for the partition and proceed to delete it [Data: Entities (9699); Relationships (17394)].\n\n3.- **Create a Pull Request (PR)**  \n\n* After deleting the partition in the UI, create a PR for the deletion. This PR ensures that the changes are tracked and reviewed.  \n\n* Ensure the PR is completed with all necessary changes [Data: Entities (9600); Relationships (17191)].\n\n4.- **Open a GitHub Issue**  \n\n* Once the PR is completed, open a GitHub issue in the [COSMIC Onboarding repository](https://github.com/substrate-platform/COSMIC/labels/sig%2Fonboarding). Provide details of the offboarding PR to ensure resources are cleaned up [Data: Entities (9600); Relationships (17192)].\n\n5.- **Delete Service Deployments**  \n\n* After the partition is deleted, remove any service deployments associated with the partition. This step speeds up resource cleanup and ensures no residual resources remain [Data: Entities (9600); Relationships (17189)].\n\n---\n\n**Important Considerations**\n\n* **Audit Trail**: The offboarding process is designed to maintain an audit trail for compliance purposes. This is critical for tracking resource deletions and ensuring no unexpected changes occur [Data: Entities (9600); Relationships (17189)].\n\n* **Resource Cleanup**: Ensure that all resources tied to the partition are cleaned up after deletion. This includes DNS configurations, Traffic Manager profiles, and namespace instances [Data: Entities (235); Relationships (7249, 7250)].\n\n* **Manual Cleanup**: While automated partition resource creation is supported, manual cleanup of pods and Kubernetes resources may be required if they are not mapped correctly [Data: Entities (235)].\n\n---\n\n**Troubleshooting Partition Deletion Issues**\n\nIf you encounter issues during the partition deletion process, such as a `PartitionNotFound` error or capacity validation failures, you may need to validate the partition name and ring-region combination in the GriffinD2 repository or COSMIC inventory. Use tools like the COSMIC Surge Dashboard or Partner NS Provisioning Status Dashboard in Grafana to monitor partition status [Data: Entities (3873, 1020); Relationships (1797, 1800)].\n\n---\n\n**Relevant Commands**\n\nCOSMIC CLI (`cc`) provides commands for managing partitions, but partition deletion is primarily handled through the Onboarding UI. If you need to verify partition details, you can use the following commands:\n\n* `cc pt get`  Retrieve partition details.\n\n* `cc pt show`  Display partition information.\n\n---\n\n**References**\n\n* [COSMIC CLI Documentation](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/tools/cosmic-cli/access-clusters-with-cc)\n\n* [COSMIC Operation Portal (COP)](https://aka.ms/cop)\n\n* [JIT Elevation Documentation](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/tools/cosmic-cli/securely-access-app-jit)\n\nLet me know if you need further assistance!\n\n**Date:** 2025-09-16"
    }
  },
  {
    id: 'q38',
    query: "ITAR vs Gallatin VS MultiTenant",
    modelA: {
      id: 'a38',
      model: 'Model A',
      response: "**Overview of ITAR, Gallatin, and MultiTenant in COSMIC**\n\n1.- **ITAR**:\n\n* Designed specifically for highly compliant and regulated environments such as **GCC (Government Community Cloud)**, **GCCH (Government Community Cloud High)**, and **DoD (Department of Defense)**.\n\n* Strict access control rules; partners must use escorts (like ITAR-specific roles) for namespace or cluster access.\n\n* Requires specific elevation and configurations for submitting deployments, as noted in issues like [GitHub#5800](https://github.com/substrate-platform/COSMIC/issues/5800).\n\n* Processes like manual pipeline deployments through scripts can be blocked ([GitHub#5900](https://github.com/substrate-platform/COSMIC/issues/5900)).\n\n2.- **Gallatin**:\n\n* A COSMIC deployment model for Microsoft\'s region in **China**.\n\n* Operates under a specialized Chinese compliance model, requiring CME (China Mainland Enterprises) smart cards and secure account provisioning, as detailed in the [Log Analytics Links and References](https://aka.ms/gallatinchnworkspace).\n\n* Incidents like [ICM#679353776](https://portal.microsofticm.com/imp/v5/incidents/details/679353776) highlighted issues tied to Gallatin configurations, such as incorrect target ring deployments.\n\n3.- **MultiTenant (MT)**:\n\n* Regular COSMIC platform used globally for most commercial cloud tenants.\n\n* Easier accessibility and broader deployment support compared to ITAR or Gallatin.\n\n* All regions fall under a shared multi-tenant model in contrast to ring-prescription rules of ITAR and Gallatin.\n\n---\n\n**Key Differences**\n\n| **Aspect** | **ITAR** | **Gallatin** | **MultiTenant** |\n\n| --- |  --- |  --- |  --- |\n\n| **Cloud Type** | Government (USGovCloud) | Chinese Sovereign Cloud | Public/Commercial Azure |\n\n| --- |  --- |  --- |  --- |\n\n| **Access** | Restricted (requires escorts/elevation) | CME cards, region-specific user setup | Public Azure (default COSMIC access) |\n\n| **Compliance** | High (DoD, GCC, GCCH regulations) | Compliance with Chinese regulations | Standard enterprise compliance |\n\n| **Deployment** | Pipeline restricted; manual blocked | Steps with secure CME setup | Standard EV2 pipelines |\n\n| **Incidents Notable** | [ICM#657278225](https://portal.microsofticm.com/imp/v5/incidents/details/657278225) - Missing permissions for extensions | [ICM#679353776](https://portal.microsofticm.com/imp/v5/incidents/details/679353776) - Deployment error resolution | Regular COSMIC deployment, broader availability. |\n\n---\n\n**References**\n\n* [Access Partner Namespaces with ITAR](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/tools/cosmic-cli/access-clusters-with-cc-itar-wl)\n\n* [Log Analytics Links and References](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/tools/Log-Analytics-Links-and-References)\n\n* [Incident ICM#657278225](https://portal.microsofticm.com/imp/v5/incidents/details/657278225)\n\n* [Setup Gallatin Account](https://aka.ms/gallatinchnworkspace)\n\nFeel free to explore COSMIC operational nuances or similar steps via [COSMIC911](https://aka.ms/cosmic911)."
    },
    modelB: {
      id: 'b38',
      model: 'Model B',
      response: "The COSMIC platform supports multiple deployment environments tailored to specific compliance, operational, and regional requirements. ITAR, Gallatin, and MultiTenant environments are distinct in their purpose, configuration, and operational constraints. Below is a detailed comparison of these environments:\n\n---\n\n**1.- ITAR (International Traffic in Arms Regulations)**\n\n**Purpose and Compliance**:  \n\nITAR environments are designed to meet stringent U.S. government regulations for handling sensitive data related to defense and arms. These environments are compliant with ITAR, GCC (Government Community Cloud), GCC High, and DoD standards, ensuring secure operations for U.S. government entities [Data: Entities (491, 5033, 10911)].\n\n**Key Features**:\n\n* **Security and Access**: ITAR environments require specialized access through ITAR Torus accounts and are managed by the ITAR Global Escort team, which provides 24/7 support for operations in these environments [Data: Entities (5033)].\n\n* **Deployment Process**: ITAR deployments rely on specific container images (e.g., kevlar-linux-tools) and require careful configuration to ensure compliance. Failures in image availability can block deployments entirely [Data: Entities (491)].\n\n* **Data Operations**: ITAR environments include clustered data warehouses (CIDW) for secure data analysis and operations, accessible only through approved tools like Kusto Desktop [Data: Entities (10911)].\n\n**Challenges**:\n\n* ITAR environments are highly restrictive, requiring elevated permissions and strict adherence to compliance protocols.\n\n* Deployment processes are slower due to the need for manual approvals and compliance checks.\n\n---\n\n**2.- Gallatin**\n\n**Purpose and Compliance**:  \n\nGallatin is a sovereign cloud environment specifically designed for operations in China, in partnership with 21Vianet. It ensures compliance with Chinese regulations and operates within the AzureChinaCloud environment (also known as Mooncake) [Data: Entities (341)].\n\n**Key Features**:\n\n* **Regional Focus**: Gallatin operates in China North 3 and China East 3 regions, with zone redundancy for resilience. It supports features like BYOIP (Bring Your Own IP) and requires specific procedures for onboarding and namespace configuration [Data: Entities (341)].\n\n* **Cluster Segregation**: Gallatin clusters are divided into Customer Content Clusters and Non-Customer Content Clusters to meet security requirements. Customer data is migrated to new clusters, while non-customer data remains in the old clusters [Data: Entities (7689, 7690)].\n\n* **Operational Processes**: Access to Gallatin requires a Torus debug account and smartcard, and certain operations necessitate role elevation (e.g., DotNetToolContributor) [Data: Entities (341)].\n\n**Challenges**:\n\n* Gallatin has experienced issues such as certificate verification problems, telemetry outages, and deployment failures due to EV2 rollout issues [Data: Entities (341)].\n\n* Visibility in the Central Operations Portal (COP) is limited, requiring reliance on alternative tools and documentation [Data: Entities (341)].\n\n---\n\n**3.- MultiTenant**\n\n**Purpose and Compliance**:  \n\nMultiTenant environments are designed to support multiple tenants across various regions and use cases. These environments are more generalized compared to ITAR and Gallatin, focusing on scalability and flexibility [Data: Entities (8100)].\n\n**Key Features**:\n\n* **Supported Rings**: MultiTenant environments include deployment rings like Gallatin and ITAR, but Airgap environments are not supported. Overrides can be applied to specific rings to ensure changes are propagated appropriately [Data: Entities (8100)].\n\n* **Configuration Parity**: MultiTenant clusters are often used as benchmarks for configuration parity with ITAR and Gallatin clusters, ensuring consistent performance and compliance across COSMIC infrastructure [Data: Relationships (2101, 2103)].\n\n* **Operational Flexibility**: These environments are less restrictive than ITAR and Gallatin, allowing for faster deployments and broader access.\n\n**Challenges**:\n\n* MultiTenant environments may not meet the stringent compliance requirements of ITAR or the regional constraints of Gallatin.\n\n* They are more prone to issues arising from shared resources and tenant conflicts.\n\n---\n\n**Comparison Summary**\n\n| Feature/Aspect         | ITAR                          | Gallatin                       | MultiTenant                  |\n\n|-------------------------|-------------------------------|--------------------------------|------------------------------|\n\n| **Purpose**            | U.S. government compliance    | China-specific operations      | General multi-tenant support|\n\n| **Compliance**         | ITAR, GCC, GCC High, DoD      | Chinese regulations            | Flexible, less restrictive  |\n\n| **Regions**            | U.S. government regions       | China North 3, China East 3    | Global                      |\n\n| **Access**             | ITAR Torus accounts, escorts  | Torus debug accounts, 21V team| Standard COSMIC access      |\n\n| **Deployment Speed**   | Slower due to compliance      | Moderate, region-specific      | Faster, less restrictive    |\n\n| **Challenges**         | Stringent protocols, delays   | Regional constraints, outages  | Shared resource conflicts   |\n\n---\n\n**Conclusion**\n\nEach environment serves a specific purpose within the COSMIC ecosystem. ITAR is ideal for U.S. government operations requiring strict compliance, Gallatin is tailored for sovereign operations in China, and MultiTenant environments provide flexibility for general use cases. Partners should choose the appropriate environment based on their compliance, regional, and operational needs.\n\n**Date:** 2025-09-16"
    }
  },
  {
    id: 'q39',
    query: "Is IPv6 required in GCC-H",
    modelA: {
      id: 'a39',
      model: 'Model A',
      response: "Yes, IPv6 is required for GCC-H environments in COSMIC to achieve dual-stack networking and maintain regulatory compliance. IPv6 setup is critical for enabling services to use both IPv4 and IPv6 addresses through Azure Traffic Manager (ATM) profiles, which support DNS resolution for both protocols.\n\nCOSMIC enforces dual-stack capabilities for Cluster CNAMEs with `A` (IPv4) and `AAAA` (IPv6) DNS records. This ensures services can be accessed via IPv6 over the same CNAME. However, Azure Firewall, used in GCCH, does not support IPv6-only network configurations, so any IPv6 rules must coexist with IPv4 rules.\n\n**Requirements**\n\n* Modify existing **LoadBalancer** services to support IPv4 and IPv6, or create separate services for each protocol.\n\n* Implement **PartitionCNAME** resources to ensure dual-stack DNS entries.\n\n**Recommendations**\n\nUse a strategy for dual-stack networking that aligns with GCC-H compliance rules while acknowledging Azure Firewall\'s restriction on IPv6-only traffic.\n\nReferences:\n\n* [Setup IPv6](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/onboarding/set-up-service-configurations/Setup-IPv6)"
    },
    modelB: {
      id: 'b39',
      model: 'Model B',
      response: "Yes, IPv6 is required in GCC-H for certain configurations and functionalities within the COSMIC platform. Below is a detailed explanation of its role and requirements:\n\n**Role of IPv6 in GCC-H**\n\nIPv6 is integral to modernizing network infrastructure and ensuring compatibility with dual-stack networking, which supports both IPv4 and IPv6 protocols. In the GCC-H environment, IPv6 is used to configure and expose services, assign addresses to nodes, pods, and services, and enable seamless integration with Azure Traffic Manager (ATM) profiles. These profiles support both IPv4 and IPv6 addresses, allowing services to be accessed using a single CNAME that resolves to both address types [Data: Entities (867, 740); Relationships (14575, 16925)].\n\n**Specific Requirements in GCC-H**\n\n1.- **Dual-Stack Networking**: GCC-H clusters are encouraged to adopt dual-stack networking, which allows both IPv4 and IPv6 connectivity. This configuration is set during cluster creation and is recommended for future-proofing network infrastructure [Data: Entities (9809); Relationships (17652)].\n\n2.- **Load Balancer Services**: Separate load balancer services must be created for IPv4 and IPv6 addresses due to Azure Kubernetes Service (AKS) limitations. This ensures that services can be accessed over both protocols [Data: Entities (867); Relationships (16924)].\n\n3.- **PartitionCNAME Resource**: To fully utilize IPv6, a `PartitionCNAME` resource must be deployed. This resource enables the creation of DNS records that support both IPv4 and IPv6, ensuring that services are accessible via dual-stack configurations [Data: Entities (867); Relationships (16923)].\n\n4.- **Compliance and Security**: IPv6 is also a security measure in GCC-H, ensuring compatibility with modern network security features. However, partners must avoid IPv6-only firewall rules, as Azure Firewall does not currently support IPv6 traffic. Instead, dual-stack configurations should be used to maintain compatibility and avoid deployment failures [Data: Entities (867, 740); Relationships (14574, 22884)].\n\n**Known Limitations and Considerations**\n\n* **Azure Firewall Limitation**: Azure Firewall does not support IPv6 traffic, which requires careful configuration of firewall rules to avoid IPv6-only setups. This limitation is particularly relevant in GCC-H, where compliance and security are critical [Data: Entities (867); Relationships (14574)].\n\n* **Cluster Compatibility**: Not all clusters in GCC-H may be dual-stack enabled. Deployments to single-stack IPv4 clusters will fail if IPv6 is explicitly required. To mitigate this, the `ipFamilyPolicy` can be set to `PreferDualStack`, allowing fallback to IPv4 in non-dual-stack clusters [Data: Sources (3491)].\n\n**Conclusion**\n\nWhile IPv6 is not universally required for all services in GCC-H, it is essential for enabling dual-stack networking, ensuring future compatibility, and meeting certain compliance and security requirements. Partners deploying services in GCC-H should carefully plan their network configurations to include IPv6 while accounting for Azure Firewall limitations and cluster capabilities.\n\nFor further guidance on IPv6 configurations in COSMIC, you can refer to the [COSMIC CLI documentation](https://eng.ms/docs/experiences-devices/m365-core/substrate-platform/cosmic-group/partners/tools/cosmic-cli/access-clusters-with-cc) or consult the [COSMIC Operation Portal (COP)](https://aka.ms/cop).\n\n**Date:** 2025-09-16"
    }
  },
  {
    id: 'q40',
    query: "What does \"unable to create azure resources\" mean for an azure private endpoint?",
    modelA: {
      id: 'a40',
      model: 'Model A',
      response: "The issue \"unable to create Azure resources\" related to private endpoints is typically caused by misconfigurations or permission-related problems in Azure. Below are some examples and common root causes seen in similar incidents, along with their resolutions:\n\n---\n\n**Possible Root Causes and Examples**\n\n1.- **Configuration Changes (e.g., Failover or Replica Region Additions):**\n\n* Example: [ICM#569853108](https://portal.microsofticm.com/imp/v5/incidents/details/569853108)\n\n* **Description**: New region additions or failovers in CosmosDB lead to the inability of private endpoints to reconcile with updated configurations, resulting in disrupted communications.\n\n* **Resolution**: Delete and recreate the affected private endpoints in all affected clusters to restore connectivity.\n\n2.- **Management Cluster Readiness Issues:**\n\n* Example: [ICM#610006252](https://portal.microsofticm.com/imp/v5/incidents/details/610006252)\n\n* **Description**: Non-ready management clusters fail to create private endpoints. Potential issues include conflicts in pods or missing permissions for private endpoint creation.\n\n* **Resolution**: Reassign the affected resources to a ready management cluster and investigate unresolved conflicts beforehand.\n\n3.- **Permission or Role Assignment Errors:**\n\n* Example: [ICM#589338841](https://portal.microsofticm.com/imp/v5/incidents/details/589338841)\n\n* **Description**: Elevated users may lack deletion or update rights for private endpoints. Attempts to operate on these resources fail due to insufficient permissions or improper roles.\n\n* **Resolution**: Work with the COSMIC Networking team to execute commands like `cc delete privateendpoint <endpoint-name>` or escalate access privileges.\n\n---\n\n**Steps to Investigate and Mitigate**\n\n1.- **Verify Permissions:**\n\n* Ensure the user attempting the operation has the necessary roles.\n\n* Example CC command:\n\n ```\n\n cc config view\n\n ```\n\n Check for your role\'s permissions in the output.\n\n2.- **Revalidate Private Endpoint Configuration:**\n\n* Example CC command:\n\n ```\n\n cc get privateendpoints -n <namespace>\n\n cc describe privateendpoint <endpoint-name> -n <namespace>\n\n ```\n\n3.- **Delete and Recreate Private Endpoints (if necessary):**\n\n* To delete:\n\n ```\n\n cc delete privateendpoint <endpoint-name> -n <namespace>\n\n ```\n\n* To recreate/reapply configuration:\n\n ```\n\n cc apply -f <privateendpoint-config-file>\n\n ```\n\n4.- **Check Logs for Errors:**\n\n* Review failure logs for additional context:\n\n ```\n\n cc logs <pod-name> -n <namespace> --since=1h\n\n ```\n\n5.- **Engage COSMIC Networking Team:**\n\n* For issues beyond partner capability, such as role escalation or infrastructure-level dependencies, open an ICM with the COSMIC Networking team with detailed logs and error descriptions.\n\n---\n\n**Mitigation Steps in the Above Examples**\n\n* **ICM#569853108**: Manually deleted and recreated all private endpoints across clusters to stabilize connectivity.\n\n* **ICM#610006252**: Reallocated resources from a non-ready management cluster to a functional one.\n\n* **ICM#589338841**: Collaborated with COSMIC Networking team to delete and recreate the impacted private endpoints.\n\n---\n\n**Related ICMs**\n\n* [ICM#569853108 - Private Endpoint issues with CosmosDB after failover](https://portal.microsofticm.com/imp/v5/incidents/details/569853108)\n\n* [ICM#610006252 - Management cluster readiness issues blocking private endpoints](https://portal.microsofticm.com/imp/v5/incidents/details/610006252)\n\n* [ICM#589338841 - Deletion and access issues with private endpoints](https://portal.microsofticm.com/imp/v5/incidents/details/589338841)\n\nFor further troubleshooting and support, visit [COSMIC911](https://aka.ms/cosmic911)."
    },
    modelB: {
      id: 'b40',
      model: 'Model B',
      response: "The error \"unable to create Azure resources\" in the context of an Azure Private Endpoint typically indicates a failure during the creation or configuration of the private endpoint or its associated resources. This issue can arise due to several reasons, including misconfigurations, missing prerequisites, or conflicts with existing resources. Below is a detailed explanation of potential causes, troubleshooting steps, and mitigation strategies.\n\n---\n\n### **Common Causes**\n\n1.- **Missing Resource Provider Registration**:\n\n* The `Microsoft.Network` resource provider must be registered in the subscription to create private endpoints. If this is not registered, the creation process will fail [Data: Entities (10803, 1002); Relationships (19876)].\n\n2.- **Invalid Resource References**:\n\n* If the private endpoint references a resource (e.g., a Network Security Group or Virtual Network) that does not exist or is incorrectly configured, the process will fail with an \"InvalidResourceReference\" error. This often occurs when the referenced resources are in a different region or are not properly associated with the private endpoint [Data: Entities (2046, 1934); Relationships (3540, 3541)].\n\n3.- **Permission Issues**:\n\n* The managed identity or user attempting to create the private endpoint may lack the necessary permissions, such as the ability to create private endpoint connections or modify associated resources. This can result in errors during the creation process [Data: Entities (7055, 1002)].\n\n4.- **Subnet or IP Address Conflicts**:\n\n* The subnet associated with the private endpoint may not have sufficient IP addresses available, or there may be conflicts with existing Network Security Group (NSG) or route table configurations [Data: Entities (10801); Reports (10)].\n\n5.- **DNS Configuration Problems**:\n\n* Proper DNS configuration is critical for private endpoints. If the DNS zone is not correctly linked to the virtual network or if there are issues with DNS resolution, the private endpoint may fail to function as expected [Data: Entities (3117, 10801)].\n\n6.- **Resource Conflicts**:\n\n* If a resource with the same name already exists in the specified location, or if there are concurrent deployments with conflicting configurations, the private endpoint creation may fail [Data: Entities (3249, 10451)].\n\n---\n\n### **Troubleshooting Steps**\n\n1.- **Verify Resource Provider Registration**:\n\n* Use the Azure CLI to check if the `Microsoft.Network` resource provider is registered:\n\n ```bash\n\n az provider show --namespace Microsoft.Network\n\n ```\n\n* If not registered, register it:\n\n ```bash\n\n az provider register --namespace Microsoft.Network\n\n ```\n\n2.- **Check Resource References**:\n\n* Ensure that all referenced resources (e.g., Virtual Network, Subnet, NSG) exist and are correctly configured in the same region as the private endpoint.\n\n3.- **Validate Permissions**:\n\n* Confirm that the user or managed identity has the necessary roles, such as `Private Endpoint Connection Approver` or equivalent, to create and manage private endpoints.\n\n4.- **Inspect Subnet and IP Configuration**:\n\n* Verify that the subnet has sufficient IP addresses available and that there are no conflicting NSG or route table rules:\n\n ```bash\n\n az network vnet subnet show --name <subnet-name> --vnet-name <vnet-name> --resource-group <resource-group-name>\n\n ```\n\n5.- **Review DNS Settings**:\n\n* Check the DNS zone configuration and ensure it is linked to the virtual network. Use the following command to list private DNS zones:\n\n ```bash\n\n az network private-dns zone list --resource-group <resource-group-name>\n\n ```\n\n6.- **Examine Logs and Errors**:\n\n* Use the `cc` CLI to describe the private endpoint and check for errors:\n\n ```bash\n\n cc describe privateendpoint <private-endpoint-name>\n\n ```\n\n---\n\n### **Mitigation Strategies**\n\n1.- **Recreate the Private Endpoint**:\n\n* If the issue persists, delete and recreate the private endpoint to ensure all configurations are applied correctly.\n\n2.- **Resolve Resource Conflicts**:\n\n* Use unique names for resources and avoid concurrent deployments that may cause conflicts.\n\n3.- **Engage the COSMIC Networking Team**:\n\n* For complex issues, such as DNS resolution failures or subnet conflicts, contact the COSMIC Networking Team for further assistance [Data: Reports (2177)].\n\n4.- **Disable Public Access**:\n\n* Once the private endpoint is successfully created, disable public network access for the associated resource to enhance security:\n\n ```powershell\n\n Update-AzKeyVault -VaultName <vault-name> -ResourceGroupName <resource-group-name> -PublicNetworkAccess \"Disabled\"\n\n ```\n\n---\n\n### **Conclusion**\n\nThe \"unable to create Azure resources\" error for a private endpoint is often a result of misconfigurations, missing prerequisites, or resource conflicts. By systematically verifying resource provider registration, permissions, DNS settings, and subnet configurations, you can identify and resolve the root cause of the issue. For persistent problems, leveraging COSMIC tools like the `cc` CLI and engaging the appropriate support teams can help ensure a successful resolution.\n\nFor more information on private endpoints and their configurations, refer to the [COSMIC Private Endpoint Documentation](https://aka.ms/cosmic-private-endpoint-dashboard).\n\n**Date:** 2025-09-16"
    }
  }
  
]